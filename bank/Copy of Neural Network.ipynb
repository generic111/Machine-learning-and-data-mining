{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d706c7bc",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a992e91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package versions: \n",
      "\n",
      "numpy 1.23.5\n",
      "pandas 1.5.3\n",
      "scikit-learn 1.2.1\n",
      "torch 2.0.0+cu117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ericx\\anaconda3\\envs\\QBUS2820\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import torch \n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import fbeta_score\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "print(f'Package versions: \\n')\n",
    "\n",
    "print(f'numpy {np.__version__}')\n",
    "print(f'pandas {pd.__version__}')\n",
    "print(f'scikit-learn {sklearn.__version__}')\n",
    "print(f'torch {torch.__version__}')\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from torch.utils.data import TensorDataset\n",
    "import optuna\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd0e9e5c",
   "metadata": {},
   "source": [
    "# Reading in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6c91c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "bank = pd.read_csv('clean_bank.csv')\n",
    "predictors = list(bank.columns[:-1])\n",
    "bank = bank[predictors]\n",
    "\n",
    "index_train_v, index_test = train_test_split(bank.index, train_size=0.7, random_state=7)\n",
    "\n",
    "\n",
    "train_v = bank.loc[index_train_v, :].copy()\n",
    "test = bank.loc[index_test, :].copy()\n",
    "\n",
    "index_train, index_valid = train_test_split(train_v.index, train_size=0.8, random_state=7)\n",
    "\n",
    "train = train_v.loc[index_train, :].copy()\n",
    "valid = train_v.loc[index_valid, :].copy()\n",
    "\n",
    "\n",
    "\n",
    "X_train = train.loc[:, train.columns!='y']\n",
    "X_valid = valid.loc[:, test.columns!='y']\n",
    "X_test = test.loc[:, test.columns!='y']\n",
    "\n",
    "# predictors = list(X_train.columns)\n",
    "\n",
    "y_train = train['y']\n",
    "y_valid = valid['y']\n",
    "y_test = test['y']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd02a9b0",
   "metadata": {},
   "source": [
    "# Encoding the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8eb6bc76",
   "metadata": {},
   "outputs": [],
   "source": [
    "from category_encoders.target_encoder import TargetEncoder\n",
    "from category_encoders.leave_one_out import LeaveOneOutEncoder\n",
    "from category_encoders.james_stein import JamesSteinEncoder\n",
    "from category_encoders.glmm import GLMMEncoder\n",
    "from category_encoders.cat_boost import CatBoostEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37827555",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "nominal = ['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'month', 'day_of_week', 'poutcome']\n",
    "\n",
    "for x in nominal:\n",
    "    # Target encoder\n",
    "    encoder = TargetEncoder().fit(train[x], y_train) # we must use the training set for this\n",
    "    train[x+'TE'] = encoder.transform(train[x])\n",
    "    valid[x+'TE'] = encoder.transform(valid[x])\n",
    "    test[x+'TE'] = encoder.transform(test[x])\n",
    "\n",
    "\n",
    "    # Leave one out encoder\n",
    "    encoder = LeaveOneOutEncoder().fit(train[x], y_train) \n",
    "    train[x+'LeaveOneOut'] = encoder.transform(train[x])\n",
    "    valid[x+'LeaveOneOut'] = encoder.transform(valid[x])\n",
    "    test[x+'LeaveOneOut'] = encoder.transform(test[x])\n",
    "\n",
    "    # GLMM encoder\n",
    "    encoder =  GLMMEncoder().fit(train[x], y_train)\n",
    "    train[x+'GLMM'] = encoder.transform(train[x])\n",
    "    valid[x+'GLMM'] = encoder.transform(valid[x])\n",
    "    test[x+'GLMM'] = encoder.transform(test[x])\n",
    "\n",
    "    # CatBoostEncoder\n",
    "    encoder = CatBoostEncoder().fit(train[x], y_train) \n",
    "    train[x+'CatBoost'] = encoder.transform(train[x])\n",
    "    valid[x+'CatBoost'] = encoder.transform(valid[x])\n",
    "    test[x+'CatBoost'] = encoder.transform(test[x])\n",
    "    \n",
    "    # One-hot encoder\n",
    "    dummies = pd.get_dummies(bank[x],  prefix = x)\n",
    "    train = train.join(dummies.loc[index_train, :])\n",
    "    valid = valid.join(dummies.loc[index_valid, :])\n",
    "    test = test.join(dummies.loc[index_test, :])\n",
    "    globals()['%s_OneHot' % x] = list(dummies.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af73b6b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = {\n",
    "        'unknown' : 0,\n",
    "        'basic4y' : 1, \n",
    "        'basic6y' : 2,\n",
    "        'basic9y' : 3, \n",
    "        'highSchool' : 4, \n",
    "        'professional' : 5, \n",
    "        'university' : 6\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "variable = 'education'\n",
    "\n",
    "train['educationOrdinal'] = train[variable].replace(keys).astype(int)\n",
    "valid['educationOrdinal'] = valid[variable].replace(keys).astype(int)\n",
    "test['educationOrdinal'] = test[variable].replace(keys).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4de9589f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.drop(['job','marital','education','default',\n",
    "                     'housing','loan','contact','month',\n",
    "                     'day_of_week','poutcome'], axis=1).copy()\n",
    "\n",
    "\n",
    "train = train.drop(['job','marital','education','default',\n",
    "                     'housing','loan','contact','month',\n",
    "                     'day_of_week','poutcome'], axis=1).copy()\n",
    "\n",
    "valid = valid.drop(['job','marital','education','default',\n",
    "                     'housing','loan','contact','month',\n",
    "                     'day_of_week','poutcome'], axis=1).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "066d3a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train\n",
    "X_test = test\n",
    "X_valid = valid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f819fb",
   "metadata": {},
   "source": [
    "# Neural network helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9c19f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(net, X):\n",
    "    \n",
    "    # Use GPU if available\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    \n",
    "    # Move data to device\n",
    "    X_g = X.to(device)\n",
    "    \n",
    "    # Put model on evaluation mode (it makes no difference but needed in some cases)\n",
    "    net.eval()\n",
    "    \n",
    "    # Disable gradient computation\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        # Predicted probabilities \n",
    "        # the .cpu().detach() part transfers the result to the cpu\n",
    "        output  = net(X_g).cpu().detach()\n",
    "    \n",
    "    return output # the output is a tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c06f18a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def train_net(model, input_size, trainloader, validset, trial=None, num_epochs = 5 , lr = 1e-3):\n",
    "    \n",
    "    # Get device\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    if trial == None:\n",
    "        # Instantiate model and move to device\n",
    "        net = model(input_size).to(device)\n",
    "    else:\n",
    "        net = model(input_size, trial).to(device)\n",
    "    \n",
    "    # Loss function\n",
    "    loss_fn = nn.BCELoss() # binary cross-entropy loss, assumes that the output of the network is a probability\n",
    "    \n",
    "    # Instantiate optimiser\n",
    "    # Adam is a variant of SGD that often works well for training neural networks\n",
    "    # https://pytorch.org/docs/stable/generated/torch.optim.Adam.html\n",
    "    optimiser = torch.optim.Adam(net.parameters(), lr = lr) \n",
    "    \n",
    "    # Addding a learning rate scheduler to improve training\n",
    "    # Adam + OneCycleLR is a good default for many problems\n",
    "    # Learn more: https://sgugger.github.io/the-1cycle-policy.html\n",
    "    scheduler = torch.optim.lr_scheduler.OneCycleLR(optimiser, max_lr = lr, \n",
    "                                                   steps_per_epoch=len(trainloader), epochs = num_epochs,\n",
    "                                                   three_phase=True)\n",
    "    # Number of training samples\n",
    "    num_samples = len(trainloader.dataset)\n",
    "    \n",
    "    # Initialise table to track training\n",
    "    table =  init_training_table(num_epochs)\n",
    "    \n",
    "    # Training loop\n",
    "    print('Running first epoch')\n",
    "    for epoch in range(num_epochs):\n",
    "        \n",
    "        # Make sure that the model is on training mode\n",
    "        net.train()\n",
    "        \n",
    "        # Initialise timer\n",
    "        epoch_start = time.time()\n",
    "        \n",
    "        # Initialise metric\n",
    "        train_loss = 0.0\n",
    "        \n",
    "        # Iterate over minibatches\n",
    "        for X, y in trainloader:\n",
    "\n",
    "            # Move minibatch to device\n",
    "            X_g = X.to(device)\n",
    "            y_g = y.to(device)\n",
    "\n",
    "            # Reset the gradient\n",
    "            optimiser.zero_grad()\n",
    "\n",
    "            # Compute predictions\n",
    "            output = net(X_g)\n",
    "\n",
    "            # Evaluate cost function\n",
    "            loss = loss_fn(output, y_g)\n",
    "\n",
    "            # Compute gradient \n",
    "            loss.backward()\n",
    "\n",
    "            # Update parameters\n",
    "            optimiser.step()\n",
    "            \n",
    "            # Update scheduler\n",
    "            scheduler.step()\n",
    "            \n",
    "            # Keep track of the training loss\n",
    "            l = loss.cpu().detach().numpy()\n",
    "            train_loss +=  l*(len(y)/num_samples)\n",
    "  \n",
    "        # Epoch length\n",
    "        duration = time.time() - epoch_start \n",
    "        \n",
    "        # Display metrics\n",
    "        if trial == None:\n",
    "            table.iloc[epoch, 1] = np.round(10*train_loss, 3)\n",
    "            table =  update_training_table(table, net, validset, epoch, duration)\n",
    "    \n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "17f290de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# auxiliary code\n",
    "\n",
    "from torch.nn import functional as F\n",
    "from sklearn.metrics import recall_score, average_precision_score\n",
    "\n",
    "def evaluate(net, validset):\n",
    "    \n",
    "    # Use GPU if available\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    \n",
    "    # Set model to evaluation mode (not necessary here but required in general)\n",
    "    net.eval()\n",
    "    \n",
    "    # Get input and target\n",
    "    X, y = validset[:]\n",
    "        \n",
    "    # Predicted probabilities \n",
    "    output = predict(net, X)\n",
    "        \n",
    "    # Validation loss\n",
    "    loss = F.binary_cross_entropy(output, y).item()\n",
    "    \n",
    "    # Convert output to numpy\n",
    "    y_prob = output.numpy()\n",
    "     \n",
    "    # Classification using the decision threshold\n",
    "    tau = 1/20\n",
    "    y_pred = (y_prob > tau).astype(int)\n",
    "    \n",
    "    # Validation metrics\n",
    "    recall = recall_score(y_valid, y_pred)\n",
    "    average_precision = average_precision_score(y_valid, y_prob)\n",
    "    \n",
    "    return loss, recall, average_precision \n",
    "\n",
    "\n",
    "from IPython.display import clear_output\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "def init_training_table(num_epochs):\n",
    "    table = pd.DataFrame(np.arange(1, num_epochs+1), columns = ['epoch'])\n",
    "    table['train loss'] = 0.0\n",
    "    table['valid loss'] = 0.0\n",
    "    table['valid recall'] = 0.0\n",
    "    table['valid average precision'] = 0.0\n",
    "    table['time'] = ''\n",
    "    return table\n",
    "\n",
    "def update_training_table(table, net, validset, epoch, duration):\n",
    "    \n",
    "    # Run evaluation function to get validation metrics\n",
    "    valid_loss, valid_recall, valid_ave_precision = evaluate(net, validset)\n",
    "        \n",
    "    # Update table\n",
    "    table.iloc[epoch, 2] = np.round(10*valid_loss, 3)\n",
    "    table.iloc[epoch, 3] = np.round(valid_recall, 3)\n",
    "    table.iloc[epoch, 4] = np.round(valid_ave_precision, 3)\n",
    "     \n",
    "    # Epoch length   \n",
    "    if duration > 3600:\n",
    "        table.iloc[epoch, 5] = time.strftime('%H:%M:%S', time.gmtime(duration))\n",
    "    else:\n",
    "        table.iloc[epoch, 5] = time.strftime('%M:%S', time.gmtime(duration))\n",
    "        \n",
    "    clear_output(wait=True)\n",
    "    display(HTML(table.iloc[:epoch+1, :].to_html(index=False)))\n",
    "    \n",
    "    return table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "202679fd",
   "metadata": {},
   "source": [
    "# Testing the different encodings on a simple neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "93e119a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "10d84b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def test_encodings(algo, variables):\n",
    "\n",
    "    results_df_dic = {}\n",
    "    for x in nominal:\n",
    "\n",
    "        rows = ['One-Hot encoding', 'Target encoder', 'Leave-one-out encoder', \n",
    "        'GLMM encoder', 'CatBoost encoder', 'ordinal encoder']\n",
    "\n",
    "        columns=['Cross-entropy', 'Error Rate', 'AUC', 'Sensitivity', 'Specificity', 'Precision', 'F1-score']\n",
    "\n",
    "        results = pd.DataFrame(0.0, columns=columns, index=rows)\n",
    "\n",
    "\n",
    "        y_prob = np.zeros((len(y_valid), len(rows)))\n",
    "        for i in range(len(rows)):\n",
    "            if i == 5 and x != 'education':\n",
    "                continue\n",
    "            feature = []\n",
    "            if i==0:\n",
    "                feature = variables + globals()['%s_OneHot' % x]\n",
    "            elif i==1: \n",
    "                feature = variables + [x+'TE'] \n",
    "            elif i==2:\n",
    "                feature = variables + [x+'LeaveOneOut']\n",
    "            elif i==3: \n",
    "                feature = variables + [x+'GLMM']\n",
    "            elif i==4: \n",
    "                feature = variables + [x+'CatBoost']  \n",
    "            if x == 'education':\n",
    "                if i==5:\n",
    "                    feature = variables + ['educationOrdinal']\n",
    "\n",
    "            X_train = train[feature].copy()\n",
    "            X_valid = valid[feature].copy()\n",
    "            \n",
    "            trainset  = TensorDataset(torch.from_numpy(X_train.to_numpy()).float(), torch.from_numpy(y_train).float())\n",
    "            validset  = TensorDataset(torch.from_numpy(X_valid.to_numpy()).float(), torch.from_numpy(y_valid).float())\n",
    "            testset = TensorDataset(torch.from_numpy(X_test.to_numpy()).float(), torch.from_numpy(y_valid).float())\n",
    "            \n",
    "            trainloader = DataLoader(trainset, batch_size = 1024, shuffle=True)\n",
    "            \n",
    "            model = algo\n",
    "            \n",
    "            model.train(X_train, y_train)\n",
    "\n",
    "            # validation set predictions\n",
    "\n",
    "            y_prob[:, i] = model.predict(X_valid)\n",
    "\n",
    "            lfp = 1\n",
    "            lfn = 19\n",
    "            tau = lfp/(lfp+lfn)\n",
    "\n",
    "            y_prob[:, i][y_prob[:,i] < 1e-5] = 1e-5 # Log-loss returns NaN if too close to zero or one\n",
    "            y_prob[:, i][y_prob[:,i] > 1- 1e-5] =  1- 1e-5\n",
    "\n",
    "            y_pred = (y_prob[:,i] > tau).astype(int)\n",
    "            # y_pred = model.predict(X_valid)\n",
    "\n",
    "            tn, fp, fn, tp = confusion_matrix(y_valid, y_pred).ravel() \n",
    "\n",
    "            results.iloc[i,0] =  log_loss(y_valid, y_prob[:,i])   # Cross entropy\n",
    "            results.iloc[i,1] =   1 - accuracy_score(y_valid, y_pred)   # Error rate\n",
    "            results.iloc[i,2] =  roc_auc_score(y_valid, y_prob[:,i])   # AUC\n",
    "            results.iloc[i,3] =  tp/(tp+fn)   # Sensitivity \n",
    "            results.iloc[i,4] =  tn/(tn+fp)   # Specificity\t\n",
    "            results.iloc[i,5] =  precision_score(y_valid, y_pred)   # Precision\n",
    "            results.iloc[i, 6] = f1_score(y_valid, y_pred)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        if x not in results_df_dic:\n",
    "            results_df_dic[x] = results\n",
    "    return results_df_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "391fb0d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        \n",
    "        self.feedforward = nn.Sequential(            \n",
    "            nn.Linear(input_size, 40),            \n",
    "            nn.ReLU(),                       \n",
    "            nn.Linear(40, 40),\n",
    "            nn.ReLU(),  \n",
    "            nn.Linear(40, 40),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(40, 1),\n",
    "            nn.Sigmoid()\n",
    "        )                        \n",
    "\n",
    "\n",
    "    def forward(self, X):        \n",
    "        return self.feedforward(X).flatten() # returns a flat array as desired"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f46865c",
   "metadata": {},
   "source": [
    "# Converting data to Dataset and Dataloader for pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dd45ed98",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "trainset  = TensorDataset(torch.from_numpy(X_train.copy().to_numpy()).float(), torch.from_numpy(y_train.to_numpy()).float())\n",
    "validset  = TensorDataset(torch.from_numpy(X_valid.copy().to_numpy()).float(), torch.from_numpy(y_valid.to_numpy()).float())\n",
    "testset = TensorDataset(torch.from_numpy(X_test.copy().to_numpy()).float(), torch.from_numpy(y_test.to_numpy()).float())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc93ed6",
   "metadata": {},
   "source": [
    "# Testing different encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "69d5aaba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, confusion_matrix, log_loss\n",
    "from torch.nn import functional as F\n",
    "from sklearn.metrics import recall_score, average_precision_score\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "319d974d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_encodings(variables):\n",
    "\n",
    "    results_df_dic = {}\n",
    "    for x in nominal:\n",
    "\n",
    "        rows = ['One-Hot encoding', 'Target encoder', 'Leave-one-out encoder', \n",
    "                'GLMM encoder', 'CatBoost encoder', 'ordinal encoder']\n",
    "\n",
    "        columns=['Cross-entropy', 'Error Rate', 'AUC', 'Sensitivity', 'Specificity', 'Precision', 'F1-score']\n",
    "\n",
    "        results = pd.DataFrame(0.0, columns=columns, index=rows)\n",
    "\n",
    "\n",
    "        y_prob = np.zeros((len(y_valid), len(rows)))\n",
    "        for i in range(len(rows)):\n",
    "            if i == 5 and x != 'education':\n",
    "                continue\n",
    "            feature = []\n",
    "            if i==0:\n",
    "                feature = variables + globals()['%s_OneHot' % x]\n",
    "            elif i==1: \n",
    "                feature = variables + [x+'TE'] \n",
    "            elif i==2:\n",
    "                feature = variables + [x+'LeaveOneOut']\n",
    "            elif i==3: \n",
    "                feature = variables + [x+'GLMM']\n",
    "            elif i==4: \n",
    "                feature = variables + [x+'CatBoost']  \n",
    "            if x == 'education':\n",
    "                if i==5:\n",
    "                    feature = variables + ['educationOrdinal']\n",
    "\n",
    "            X_train = train[feature]\n",
    "            X_valid = valid[feature]\n",
    "\n",
    "            trainset  = TensorDataset(torch.from_numpy(X_train.copy().to_numpy()).float(), torch.from_numpy(y_train.to_numpy()).float())\n",
    "            validset  = TensorDataset(torch.from_numpy(X_valid.copy().to_numpy()).float(), torch.from_numpy(y_valid.to_numpy()).float())\n",
    "            trainloader = DataLoader(trainset, batch_size = 1024, shuffle=True)\n",
    "\n",
    "            mlp = train_net(NeuralNetwork, len(X_train.columns), trainloader, validset, num_epochs = 10, lr = 3e-3)\n",
    "\n",
    "            X = validset[:][0]\n",
    "            y_prob[:, i] = predict(mlp, X).numpy()\n",
    "\n",
    "\n",
    "            lfp = 1\n",
    "            lfn = 19\n",
    "            tau = lfp/(lfp+lfn)\n",
    "\n",
    "            y_prob[:, i][y_prob[:,i] < 1e-5] = 1e-5 # Log-loss returns NaN if too close to zero or one\n",
    "            y_prob[:, i][y_prob[:,i] > 1- 1e-5] =  1- 1e-5\n",
    "\n",
    "            y_pred = (y_prob[:,i] > tau).astype(int)\n",
    "            # y_pred = model.predict(X_valid)\n",
    "\n",
    "            tn, fp, fn, tp = confusion_matrix(y_valid, y_pred).ravel() \n",
    "\n",
    "            results.iloc[i,0] =  log_loss(y_valid, y_prob[:,i])   # Cross entropy\n",
    "            results.iloc[i,1] =   1 - accuracy_score(y_valid, y_pred)   # Error rate\n",
    "            results.iloc[i,2] =  roc_auc_score(y_valid, y_prob[:,i])   # AUC\n",
    "            results.iloc[i,3] =  tp/(tp+fn)   # Sensitivity \n",
    "            results.iloc[i,4] =  tn/(tn+fp)   # Specificity\t\n",
    "            results.iloc[i,5] =  precision_score(y_valid, y_pred)   # Precision\n",
    "            results.iloc[i, 6] = f1_score(y_valid, y_pred)\n",
    "\n",
    "\n",
    "\n",
    "        if x not in results_df_dic:\n",
    "            results_df_dic[x] = results\n",
    "    return results_df_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "45f02987",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train loss</th>\n",
       "      <th>valid loss</th>\n",
       "      <th>valid recall</th>\n",
       "      <th>valid average precision</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4.873</td>\n",
       "      <td>4.406</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.297</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>16.874</td>\n",
       "      <td>36.754</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.417</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>70.242</td>\n",
       "      <td>119.239</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.252</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>119.484</td>\n",
       "      <td>121.883</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.220</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>120.587</td>\n",
       "      <td>121.982</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.218</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>120.651</td>\n",
       "      <td>121.984</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.218</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>120.651</td>\n",
       "      <td>121.985</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.218</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>120.652</td>\n",
       "      <td>121.985</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.218</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>120.652</td>\n",
       "      <td>121.985</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.218</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>120.652</td>\n",
       "      <td>121.985</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.218</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ericx\\anaconda3\\envs\\QBUS2820\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "features = ['age', 'pdays', 'previous', 'emp_var_rate', 'cons_price_idx', 'cons_conf_idx', 'euribor_3m', 'nr_employed']\n",
    "results_df_dic = test_encodings(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e40f3b2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "job\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cross-entropy</th>\n",
       "      <th>Error Rate</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>One-Hot encoding</th>\n",
       "      <td>0.33896</td>\n",
       "      <td>0.87582</td>\n",
       "      <td>0.72241</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.12418</td>\n",
       "      <td>0.22093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Leave-one-out encoder</th>\n",
       "      <td>10.08323</td>\n",
       "      <td>0.87582</td>\n",
       "      <td>0.50000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.12418</td>\n",
       "      <td>0.22093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Target encoder</th>\n",
       "      <td>1.42970</td>\n",
       "      <td>0.12418</td>\n",
       "      <td>0.50000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GLMM encoder</th>\n",
       "      <td>1.42970</td>\n",
       "      <td>0.12418</td>\n",
       "      <td>0.50000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CatBoost encoder</th>\n",
       "      <td>1.42970</td>\n",
       "      <td>0.12418</td>\n",
       "      <td>0.50000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ordinal encoder</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Cross-entropy  Error Rate      AUC  Sensitivity  \\\n",
       "One-Hot encoding             0.33896     0.87582  0.72241          1.0   \n",
       "Leave-one-out encoder       10.08323     0.87582  0.50000          1.0   \n",
       "Target encoder               1.42970     0.12418  0.50000          0.0   \n",
       "GLMM encoder                 1.42970     0.12418  0.50000          0.0   \n",
       "CatBoost encoder             1.42970     0.12418  0.50000          0.0   \n",
       "ordinal encoder              0.00000     0.00000  0.00000          0.0   \n",
       "\n",
       "                       Specificity  Precision  F1-score  \n",
       "One-Hot encoding               0.0    0.12418   0.22093  \n",
       "Leave-one-out encoder          0.0    0.12418   0.22093  \n",
       "Target encoder                 1.0    0.00000   0.00000  \n",
       "GLMM encoder                   1.0    0.00000   0.00000  \n",
       "CatBoost encoder               1.0    0.00000   0.00000  \n",
       "ordinal encoder                0.0    0.00000   0.00000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "marital\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cross-entropy</th>\n",
       "      <th>Error Rate</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CatBoost encoder</th>\n",
       "      <td>0.39038</td>\n",
       "      <td>0.87582</td>\n",
       "      <td>0.49801</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.12418</td>\n",
       "      <td>0.22093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>One-Hot encoding</th>\n",
       "      <td>1.42970</td>\n",
       "      <td>0.12418</td>\n",
       "      <td>0.50000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Target encoder</th>\n",
       "      <td>1.42970</td>\n",
       "      <td>0.12418</td>\n",
       "      <td>0.50000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Leave-one-out encoder</th>\n",
       "      <td>1.42970</td>\n",
       "      <td>0.12418</td>\n",
       "      <td>0.50000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GLMM encoder</th>\n",
       "      <td>1.42970</td>\n",
       "      <td>0.12418</td>\n",
       "      <td>0.50000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ordinal encoder</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Cross-entropy  Error Rate      AUC  Sensitivity  \\\n",
       "CatBoost encoder             0.39038     0.87582  0.49801          1.0   \n",
       "One-Hot encoding             1.42970     0.12418  0.50000          0.0   \n",
       "Target encoder               1.42970     0.12418  0.50000          0.0   \n",
       "Leave-one-out encoder        1.42970     0.12418  0.50000          0.0   \n",
       "GLMM encoder                 1.42970     0.12418  0.50000          0.0   \n",
       "ordinal encoder              0.00000     0.00000  0.00000          0.0   \n",
       "\n",
       "                       Specificity  Precision  F1-score  \n",
       "CatBoost encoder               0.0    0.12418   0.22093  \n",
       "One-Hot encoding               1.0    0.00000   0.00000  \n",
       "Target encoder                 1.0    0.00000   0.00000  \n",
       "Leave-one-out encoder          1.0    0.00000   0.00000  \n",
       "GLMM encoder                   1.0    0.00000   0.00000  \n",
       "ordinal encoder                0.0    0.00000   0.00000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "education\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cross-entropy</th>\n",
       "      <th>Error Rate</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ordinal encoder</th>\n",
       "      <td>1.20859</td>\n",
       "      <td>0.11147</td>\n",
       "      <td>0.59417</td>\n",
       "      <td>0.2031</td>\n",
       "      <td>0.98571</td>\n",
       "      <td>0.66837</td>\n",
       "      <td>0.31153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>One-Hot encoding</th>\n",
       "      <td>1.42970</td>\n",
       "      <td>0.12418</td>\n",
       "      <td>0.50000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Target encoder</th>\n",
       "      <td>1.42970</td>\n",
       "      <td>0.12418</td>\n",
       "      <td>0.50000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Leave-one-out encoder</th>\n",
       "      <td>1.42970</td>\n",
       "      <td>0.12418</td>\n",
       "      <td>0.50000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GLMM encoder</th>\n",
       "      <td>1.42970</td>\n",
       "      <td>0.12418</td>\n",
       "      <td>0.50000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CatBoost encoder</th>\n",
       "      <td>1.42970</td>\n",
       "      <td>0.12418</td>\n",
       "      <td>0.50000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Cross-entropy  Error Rate      AUC  Sensitivity  \\\n",
       "ordinal encoder              1.20859     0.11147  0.59417       0.2031   \n",
       "One-Hot encoding             1.42970     0.12418  0.50000       0.0000   \n",
       "Target encoder               1.42970     0.12418  0.50000       0.0000   \n",
       "Leave-one-out encoder        1.42970     0.12418  0.50000       0.0000   \n",
       "GLMM encoder                 1.42970     0.12418  0.50000       0.0000   \n",
       "CatBoost encoder             1.42970     0.12418  0.50000       0.0000   \n",
       "\n",
       "                       Specificity  Precision  F1-score  \n",
       "ordinal encoder            0.98571    0.66837   0.31153  \n",
       "One-Hot encoding           1.00000    0.00000   0.00000  \n",
       "Target encoder             1.00000    0.00000   0.00000  \n",
       "Leave-one-out encoder      1.00000    0.00000   0.00000  \n",
       "GLMM encoder               1.00000    0.00000   0.00000  \n",
       "CatBoost encoder           1.00000    0.00000   0.00000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "default\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cross-entropy</th>\n",
       "      <th>Error Rate</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>One-Hot encoding</th>\n",
       "      <td>10.08323</td>\n",
       "      <td>0.87582</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.12418</td>\n",
       "      <td>0.22093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Target encoder</th>\n",
       "      <td>1.42970</td>\n",
       "      <td>0.12418</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Leave-one-out encoder</th>\n",
       "      <td>1.42970</td>\n",
       "      <td>0.12418</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GLMM encoder</th>\n",
       "      <td>1.42970</td>\n",
       "      <td>0.12418</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CatBoost encoder</th>\n",
       "      <td>1.42970</td>\n",
       "      <td>0.12418</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ordinal encoder</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Cross-entropy  Error Rate  AUC  Sensitivity  \\\n",
       "One-Hot encoding            10.08323     0.87582  0.5          1.0   \n",
       "Target encoder               1.42970     0.12418  0.5          0.0   \n",
       "Leave-one-out encoder        1.42970     0.12418  0.5          0.0   \n",
       "GLMM encoder                 1.42970     0.12418  0.5          0.0   \n",
       "CatBoost encoder             1.42970     0.12418  0.5          0.0   \n",
       "ordinal encoder              0.00000     0.00000  0.0          0.0   \n",
       "\n",
       "                       Specificity  Precision  F1-score  \n",
       "One-Hot encoding               0.0    0.12418   0.22093  \n",
       "Target encoder                 1.0    0.00000   0.00000  \n",
       "Leave-one-out encoder          1.0    0.00000   0.00000  \n",
       "GLMM encoder                   1.0    0.00000   0.00000  \n",
       "CatBoost encoder               1.0    0.00000   0.00000  \n",
       "ordinal encoder                0.0    0.00000   0.00000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "housing\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cross-entropy</th>\n",
       "      <th>Error Rate</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GLMM encoder</th>\n",
       "      <td>1.16345</td>\n",
       "      <td>0.11147</td>\n",
       "      <td>0.59447</td>\n",
       "      <td>0.2031</td>\n",
       "      <td>0.98571</td>\n",
       "      <td>0.66837</td>\n",
       "      <td>0.31153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Target encoder</th>\n",
       "      <td>10.08323</td>\n",
       "      <td>0.87582</td>\n",
       "      <td>0.50000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.12418</td>\n",
       "      <td>0.22093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CatBoost encoder</th>\n",
       "      <td>10.08323</td>\n",
       "      <td>0.87582</td>\n",
       "      <td>0.50000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.12418</td>\n",
       "      <td>0.22093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>One-Hot encoding</th>\n",
       "      <td>1.42970</td>\n",
       "      <td>0.12418</td>\n",
       "      <td>0.50000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Leave-one-out encoder</th>\n",
       "      <td>1.42970</td>\n",
       "      <td>0.12418</td>\n",
       "      <td>0.50000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ordinal encoder</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Cross-entropy  Error Rate      AUC  Sensitivity  \\\n",
       "GLMM encoder                 1.16345     0.11147  0.59447       0.2031   \n",
       "Target encoder              10.08323     0.87582  0.50000       1.0000   \n",
       "CatBoost encoder            10.08323     0.87582  0.50000       1.0000   \n",
       "One-Hot encoding             1.42970     0.12418  0.50000       0.0000   \n",
       "Leave-one-out encoder        1.42970     0.12418  0.50000       0.0000   \n",
       "ordinal encoder              0.00000     0.00000  0.00000       0.0000   \n",
       "\n",
       "                       Specificity  Precision  F1-score  \n",
       "GLMM encoder               0.98571    0.66837   0.31153  \n",
       "Target encoder             0.00000    0.12418   0.22093  \n",
       "CatBoost encoder           0.00000    0.12418   0.22093  \n",
       "One-Hot encoding           1.00000    0.00000   0.00000  \n",
       "Leave-one-out encoder      1.00000    0.00000   0.00000  \n",
       "ordinal encoder            0.00000    0.00000   0.00000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loan\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cross-entropy</th>\n",
       "      <th>Error Rate</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>One-Hot encoding</th>\n",
       "      <td>0.34379</td>\n",
       "      <td>0.87582</td>\n",
       "      <td>0.59835</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.12418</td>\n",
       "      <td>0.22093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Target encoder</th>\n",
       "      <td>0.39588</td>\n",
       "      <td>0.87582</td>\n",
       "      <td>0.52490</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.12418</td>\n",
       "      <td>0.22093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GLMM encoder</th>\n",
       "      <td>10.08323</td>\n",
       "      <td>0.87582</td>\n",
       "      <td>0.50000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.12418</td>\n",
       "      <td>0.22093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Leave-one-out encoder</th>\n",
       "      <td>1.42970</td>\n",
       "      <td>0.12418</td>\n",
       "      <td>0.50000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CatBoost encoder</th>\n",
       "      <td>1.42970</td>\n",
       "      <td>0.12418</td>\n",
       "      <td>0.50000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ordinal encoder</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Cross-entropy  Error Rate      AUC  Sensitivity  \\\n",
       "One-Hot encoding             0.34379     0.87582  0.59835          1.0   \n",
       "Target encoder               0.39588     0.87582  0.52490          1.0   \n",
       "GLMM encoder                10.08323     0.87582  0.50000          1.0   \n",
       "Leave-one-out encoder        1.42970     0.12418  0.50000          0.0   \n",
       "CatBoost encoder             1.42970     0.12418  0.50000          0.0   \n",
       "ordinal encoder              0.00000     0.00000  0.00000          0.0   \n",
       "\n",
       "                       Specificity  Precision  F1-score  \n",
       "One-Hot encoding               0.0    0.12418   0.22093  \n",
       "Target encoder                 0.0    0.12418   0.22093  \n",
       "GLMM encoder                   0.0    0.12418   0.22093  \n",
       "Leave-one-out encoder          1.0    0.00000   0.00000  \n",
       "CatBoost encoder               1.0    0.00000   0.00000  \n",
       "ordinal encoder                0.0    0.00000   0.00000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contact\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cross-entropy</th>\n",
       "      <th>Error Rate</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>One-Hot encoding</th>\n",
       "      <td>10.08323</td>\n",
       "      <td>0.87582</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.12418</td>\n",
       "      <td>0.22093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Target encoder</th>\n",
       "      <td>10.08323</td>\n",
       "      <td>0.87582</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.12418</td>\n",
       "      <td>0.22093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GLMM encoder</th>\n",
       "      <td>10.08323</td>\n",
       "      <td>0.87582</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.12418</td>\n",
       "      <td>0.22093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Leave-one-out encoder</th>\n",
       "      <td>1.42970</td>\n",
       "      <td>0.12418</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CatBoost encoder</th>\n",
       "      <td>1.42970</td>\n",
       "      <td>0.12418</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ordinal encoder</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Cross-entropy  Error Rate  AUC  Sensitivity  \\\n",
       "One-Hot encoding            10.08323     0.87582  0.5          1.0   \n",
       "Target encoder              10.08323     0.87582  0.5          1.0   \n",
       "GLMM encoder                10.08323     0.87582  0.5          1.0   \n",
       "Leave-one-out encoder        1.42970     0.12418  0.5          0.0   \n",
       "CatBoost encoder             1.42970     0.12418  0.5          0.0   \n",
       "ordinal encoder              0.00000     0.00000  0.0          0.0   \n",
       "\n",
       "                       Specificity  Precision  F1-score  \n",
       "One-Hot encoding               0.0    0.12418   0.22093  \n",
       "Target encoder                 0.0    0.12418   0.22093  \n",
       "GLMM encoder                   0.0    0.12418   0.22093  \n",
       "Leave-one-out encoder          1.0    0.00000   0.00000  \n",
       "CatBoost encoder               1.0    0.00000   0.00000  \n",
       "ordinal encoder                0.0    0.00000   0.00000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "month\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cross-entropy</th>\n",
       "      <th>Error Rate</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>One-Hot encoding</th>\n",
       "      <td>0.34099</td>\n",
       "      <td>0.87582</td>\n",
       "      <td>0.69111</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.12418</td>\n",
       "      <td>0.22093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Target encoder</th>\n",
       "      <td>10.08323</td>\n",
       "      <td>0.87582</td>\n",
       "      <td>0.50000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.12418</td>\n",
       "      <td>0.22093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GLMM encoder</th>\n",
       "      <td>10.08323</td>\n",
       "      <td>0.87582</td>\n",
       "      <td>0.50000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.12418</td>\n",
       "      <td>0.22093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CatBoost encoder</th>\n",
       "      <td>10.08323</td>\n",
       "      <td>0.87582</td>\n",
       "      <td>0.50000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.12418</td>\n",
       "      <td>0.22093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Leave-one-out encoder</th>\n",
       "      <td>1.42970</td>\n",
       "      <td>0.12418</td>\n",
       "      <td>0.50000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ordinal encoder</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Cross-entropy  Error Rate      AUC  Sensitivity  \\\n",
       "One-Hot encoding             0.34099     0.87582  0.69111          1.0   \n",
       "Target encoder              10.08323     0.87582  0.50000          1.0   \n",
       "GLMM encoder                10.08323     0.87582  0.50000          1.0   \n",
       "CatBoost encoder            10.08323     0.87582  0.50000          1.0   \n",
       "Leave-one-out encoder        1.42970     0.12418  0.50000          0.0   \n",
       "ordinal encoder              0.00000     0.00000  0.00000          0.0   \n",
       "\n",
       "                       Specificity  Precision  F1-score  \n",
       "One-Hot encoding               0.0    0.12418   0.22093  \n",
       "Target encoder                 0.0    0.12418   0.22093  \n",
       "GLMM encoder                   0.0    0.12418   0.22093  \n",
       "CatBoost encoder               0.0    0.12418   0.22093  \n",
       "Leave-one-out encoder          1.0    0.00000   0.00000  \n",
       "ordinal encoder                0.0    0.00000   0.00000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day_of_week\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cross-entropy</th>\n",
       "      <th>Error Rate</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>One-Hot encoding</th>\n",
       "      <td>10.08323</td>\n",
       "      <td>0.87582</td>\n",
       "      <td>0.50000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.12418</td>\n",
       "      <td>0.22093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Target encoder</th>\n",
       "      <td>0.34156</td>\n",
       "      <td>0.87582</td>\n",
       "      <td>0.71712</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.12418</td>\n",
       "      <td>0.22093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Leave-one-out encoder</th>\n",
       "      <td>10.08323</td>\n",
       "      <td>0.87582</td>\n",
       "      <td>0.50000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.12418</td>\n",
       "      <td>0.22093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CatBoost encoder</th>\n",
       "      <td>10.08323</td>\n",
       "      <td>0.87582</td>\n",
       "      <td>0.50000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.12418</td>\n",
       "      <td>0.22093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GLMM encoder</th>\n",
       "      <td>1.42970</td>\n",
       "      <td>0.12418</td>\n",
       "      <td>0.50000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ordinal encoder</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Cross-entropy  Error Rate      AUC  Sensitivity  \\\n",
       "One-Hot encoding            10.08323     0.87582  0.50000          1.0   \n",
       "Target encoder               0.34156     0.87582  0.71712          1.0   \n",
       "Leave-one-out encoder       10.08323     0.87582  0.50000          1.0   \n",
       "CatBoost encoder            10.08323     0.87582  0.50000          1.0   \n",
       "GLMM encoder                 1.42970     0.12418  0.50000          0.0   \n",
       "ordinal encoder              0.00000     0.00000  0.00000          0.0   \n",
       "\n",
       "                       Specificity  Precision  F1-score  \n",
       "One-Hot encoding               0.0    0.12418   0.22093  \n",
       "Target encoder                 0.0    0.12418   0.22093  \n",
       "Leave-one-out encoder          0.0    0.12418   0.22093  \n",
       "CatBoost encoder               0.0    0.12418   0.22093  \n",
       "GLMM encoder                   1.0    0.00000   0.00000  \n",
       "ordinal encoder                0.0    0.00000   0.00000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "poutcome\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cross-entropy</th>\n",
       "      <th>Error Rate</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>One-Hot encoding</th>\n",
       "      <td>10.08323</td>\n",
       "      <td>0.87582</td>\n",
       "      <td>0.50000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.12418</td>\n",
       "      <td>0.22093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Target encoder</th>\n",
       "      <td>0.40237</td>\n",
       "      <td>0.87582</td>\n",
       "      <td>0.57168</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.12418</td>\n",
       "      <td>0.22093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Leave-one-out encoder</th>\n",
       "      <td>10.08323</td>\n",
       "      <td>0.87582</td>\n",
       "      <td>0.50000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.12418</td>\n",
       "      <td>0.22093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GLMM encoder</th>\n",
       "      <td>0.34270</td>\n",
       "      <td>0.87582</td>\n",
       "      <td>0.59041</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.12418</td>\n",
       "      <td>0.22093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CatBoost encoder</th>\n",
       "      <td>1.42970</td>\n",
       "      <td>0.12418</td>\n",
       "      <td>0.50000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ordinal encoder</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Cross-entropy  Error Rate      AUC  Sensitivity  \\\n",
       "One-Hot encoding            10.08323     0.87582  0.50000          1.0   \n",
       "Target encoder               0.40237     0.87582  0.57168          1.0   \n",
       "Leave-one-out encoder       10.08323     0.87582  0.50000          1.0   \n",
       "GLMM encoder                 0.34270     0.87582  0.59041          1.0   \n",
       "CatBoost encoder             1.42970     0.12418  0.50000          0.0   \n",
       "ordinal encoder              0.00000     0.00000  0.00000          0.0   \n",
       "\n",
       "                       Specificity  Precision  F1-score  \n",
       "One-Hot encoding               0.0    0.12418   0.22093  \n",
       "Target encoder                 0.0    0.12418   0.22093  \n",
       "Leave-one-out encoder          0.0    0.12418   0.22093  \n",
       "GLMM encoder                   0.0    0.12418   0.22093  \n",
       "CatBoost encoder               1.0    0.00000   0.00000  \n",
       "ordinal encoder                0.0    0.00000   0.00000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for key in results_df_dic:\n",
    "    print(key)\n",
    "    display(results_df_dic[key].sort_values(by=['F1-score'], ascending = [0]).round(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f168070f",
   "metadata": {},
   "source": [
    "## Summary on which encodings to use\n",
    "\n",
    "\n",
    "- **job**: One-Hot encoding\t\n",
    "- **martial**: One-Hot encoding\t\n",
    "- **education**: One-Hot encoding\n",
    "- **default**: One-Hot encoding\n",
    "- **housing**: One-Hot encoding\t\n",
    "- **loan**: One-Hot encoding\t\n",
    "- **contact**: GLMM encoder\n",
    "- **month**: One-Hot encoding\t\n",
    "- **day_of_week**: GLMM encoder\n",
    "- **poutcome**: One-Hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "792c7807",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_encodings_for_nn = {'OneHot': ['job', 'marital', 'education', 'default', 'housing', 'loan', 'month', 'poutcome'], 'GLMM': ['contact', 'day_of_week']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f81917e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_feature_encodings(encoding_dic):\n",
    "    best_features = []\n",
    "    for i in encoding_dic:\n",
    "        for j in encoding_dic[i]:\n",
    "            if i == 'OneHot':\n",
    "                best_features = best_features + globals()['%s_OneHot' % j]\n",
    "            else:\n",
    "                best_features = best_features + [j + i]\n",
    "    return best_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aceb89a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bd6e810e",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_features = get_feature_encodings(best_encodings_for_nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "80ff50a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train loss</th>\n",
       "      <th>valid loss</th>\n",
       "      <th>valid recall</th>\n",
       "      <th>valid average precision</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>26.901</td>\n",
       "      <td>5.830</td>\n",
       "      <td>0.203</td>\n",
       "      <td>0.431</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>8.316</td>\n",
       "      <td>9.460</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.427</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>7.620</td>\n",
       "      <td>4.483</td>\n",
       "      <td>0.203</td>\n",
       "      <td>0.427</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4.069</td>\n",
       "      <td>3.542</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.424</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>3.669</td>\n",
       "      <td>3.524</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.358</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>3.473</td>\n",
       "      <td>3.434</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.370</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>3.404</td>\n",
       "      <td>3.448</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.375</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>3.401</td>\n",
       "      <td>3.423</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.378</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>3.380</td>\n",
       "      <td>3.399</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.379</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>3.380</td>\n",
       "      <td>3.400</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.385</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>3.375</td>\n",
       "      <td>3.390</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.394</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>3.368</td>\n",
       "      <td>3.396</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.408</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>3.368</td>\n",
       "      <td>3.427</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.419</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>3.422</td>\n",
       "      <td>3.475</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.415</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>3.374</td>\n",
       "      <td>3.463</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.432</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>3.402</td>\n",
       "      <td>3.436</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.434</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>3.369</td>\n",
       "      <td>3.352</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.434</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>3.340</td>\n",
       "      <td>3.343</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.435</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>3.326</td>\n",
       "      <td>3.361</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.436</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>3.332</td>\n",
       "      <td>3.340</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.436</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>3.321</td>\n",
       "      <td>3.489</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.433</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>3.324</td>\n",
       "      <td>3.286</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.435</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>3.329</td>\n",
       "      <td>3.267</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.436</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>3.340</td>\n",
       "      <td>3.244</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.435</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>3.492</td>\n",
       "      <td>4.932</td>\n",
       "      <td>0.203</td>\n",
       "      <td>0.438</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>7.480</td>\n",
       "      <td>6.292</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.434</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>4.078</td>\n",
       "      <td>3.347</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.426</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>3.360</td>\n",
       "      <td>3.383</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.431</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>3.336</td>\n",
       "      <td>3.423</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.431</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>3.314</td>\n",
       "      <td>3.316</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.429</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>3.291</td>\n",
       "      <td>3.332</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.427</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>3.274</td>\n",
       "      <td>3.280</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.428</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>3.267</td>\n",
       "      <td>3.280</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.428</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>3.253</td>\n",
       "      <td>3.304</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.429</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>3.249</td>\n",
       "      <td>3.258</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.428</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>3.260</td>\n",
       "      <td>3.241</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.428</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>3.248</td>\n",
       "      <td>3.426</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.427</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>3.268</td>\n",
       "      <td>3.331</td>\n",
       "      <td>0.859</td>\n",
       "      <td>0.430</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>3.225</td>\n",
       "      <td>3.209</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.429</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>3.192</td>\n",
       "      <td>3.209</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.429</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>3.187</td>\n",
       "      <td>3.213</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.429</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>3.175</td>\n",
       "      <td>3.188</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.429</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>3.170</td>\n",
       "      <td>3.180</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.430</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>3.148</td>\n",
       "      <td>3.194</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.429</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>3.157</td>\n",
       "      <td>3.165</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.430</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>3.134</td>\n",
       "      <td>3.161</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.430</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>3.121</td>\n",
       "      <td>3.168</td>\n",
       "      <td>0.958</td>\n",
       "      <td>0.430</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>3.118</td>\n",
       "      <td>3.155</td>\n",
       "      <td>0.984</td>\n",
       "      <td>0.431</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>3.118</td>\n",
       "      <td>3.149</td>\n",
       "      <td>0.989</td>\n",
       "      <td>0.431</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>3.111</td>\n",
       "      <td>3.164</td>\n",
       "      <td>0.905</td>\n",
       "      <td>0.431</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>3.110</td>\n",
       "      <td>3.152</td>\n",
       "      <td>0.930</td>\n",
       "      <td>0.431</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>3.105</td>\n",
       "      <td>3.144</td>\n",
       "      <td>0.971</td>\n",
       "      <td>0.431</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>3.101</td>\n",
       "      <td>3.146</td>\n",
       "      <td>0.932</td>\n",
       "      <td>0.431</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>3.104</td>\n",
       "      <td>3.143</td>\n",
       "      <td>0.941</td>\n",
       "      <td>0.431</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>3.100</td>\n",
       "      <td>3.147</td>\n",
       "      <td>0.913</td>\n",
       "      <td>0.431</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>3.098</td>\n",
       "      <td>3.150</td>\n",
       "      <td>0.901</td>\n",
       "      <td>0.431</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>3.102</td>\n",
       "      <td>3.137</td>\n",
       "      <td>0.971</td>\n",
       "      <td>0.431</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>3.095</td>\n",
       "      <td>3.137</td>\n",
       "      <td>0.971</td>\n",
       "      <td>0.431</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>3.095</td>\n",
       "      <td>3.136</td>\n",
       "      <td>0.980</td>\n",
       "      <td>0.431</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>3.095</td>\n",
       "      <td>3.137</td>\n",
       "      <td>0.960</td>\n",
       "      <td>0.431</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61</td>\n",
       "      <td>3.094</td>\n",
       "      <td>3.137</td>\n",
       "      <td>0.947</td>\n",
       "      <td>0.431</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62</td>\n",
       "      <td>3.094</td>\n",
       "      <td>3.136</td>\n",
       "      <td>0.984</td>\n",
       "      <td>0.431</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>63</td>\n",
       "      <td>3.095</td>\n",
       "      <td>3.139</td>\n",
       "      <td>0.926</td>\n",
       "      <td>0.431</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>3.093</td>\n",
       "      <td>3.134</td>\n",
       "      <td>0.969</td>\n",
       "      <td>0.431</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65</td>\n",
       "      <td>3.094</td>\n",
       "      <td>3.134</td>\n",
       "      <td>0.984</td>\n",
       "      <td>0.431</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66</td>\n",
       "      <td>3.095</td>\n",
       "      <td>3.145</td>\n",
       "      <td>0.898</td>\n",
       "      <td>0.432</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>67</td>\n",
       "      <td>3.094</td>\n",
       "      <td>3.133</td>\n",
       "      <td>0.971</td>\n",
       "      <td>0.431</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68</td>\n",
       "      <td>3.093</td>\n",
       "      <td>3.134</td>\n",
       "      <td>0.950</td>\n",
       "      <td>0.431</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69</td>\n",
       "      <td>3.090</td>\n",
       "      <td>3.133</td>\n",
       "      <td>0.960</td>\n",
       "      <td>0.431</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>3.090</td>\n",
       "      <td>3.133</td>\n",
       "      <td>0.955</td>\n",
       "      <td>0.431</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>71</td>\n",
       "      <td>3.091</td>\n",
       "      <td>3.132</td>\n",
       "      <td>0.960</td>\n",
       "      <td>0.431</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72</td>\n",
       "      <td>3.090</td>\n",
       "      <td>3.132</td>\n",
       "      <td>0.957</td>\n",
       "      <td>0.432</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>73</td>\n",
       "      <td>3.089</td>\n",
       "      <td>3.134</td>\n",
       "      <td>0.930</td>\n",
       "      <td>0.432</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>74</td>\n",
       "      <td>3.088</td>\n",
       "      <td>3.131</td>\n",
       "      <td>0.971</td>\n",
       "      <td>0.431</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>3.088</td>\n",
       "      <td>3.132</td>\n",
       "      <td>0.935</td>\n",
       "      <td>0.432</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>76</td>\n",
       "      <td>3.088</td>\n",
       "      <td>3.131</td>\n",
       "      <td>0.960</td>\n",
       "      <td>0.432</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>77</td>\n",
       "      <td>3.089</td>\n",
       "      <td>3.133</td>\n",
       "      <td>0.926</td>\n",
       "      <td>0.432</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78</td>\n",
       "      <td>3.087</td>\n",
       "      <td>3.130</td>\n",
       "      <td>0.960</td>\n",
       "      <td>0.432</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>79</td>\n",
       "      <td>3.087</td>\n",
       "      <td>3.132</td>\n",
       "      <td>0.932</td>\n",
       "      <td>0.432</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>3.087</td>\n",
       "      <td>3.130</td>\n",
       "      <td>0.947</td>\n",
       "      <td>0.432</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>81</td>\n",
       "      <td>3.089</td>\n",
       "      <td>3.131</td>\n",
       "      <td>0.935</td>\n",
       "      <td>0.432</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>82</td>\n",
       "      <td>3.086</td>\n",
       "      <td>3.131</td>\n",
       "      <td>0.932</td>\n",
       "      <td>0.432</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>83</td>\n",
       "      <td>3.086</td>\n",
       "      <td>3.130</td>\n",
       "      <td>0.949</td>\n",
       "      <td>0.432</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>84</td>\n",
       "      <td>3.086</td>\n",
       "      <td>3.130</td>\n",
       "      <td>0.944</td>\n",
       "      <td>0.432</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85</td>\n",
       "      <td>3.086</td>\n",
       "      <td>3.131</td>\n",
       "      <td>0.930</td>\n",
       "      <td>0.432</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>86</td>\n",
       "      <td>3.086</td>\n",
       "      <td>3.129</td>\n",
       "      <td>0.946</td>\n",
       "      <td>0.432</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>87</td>\n",
       "      <td>3.086</td>\n",
       "      <td>3.131</td>\n",
       "      <td>0.929</td>\n",
       "      <td>0.432</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>88</td>\n",
       "      <td>3.086</td>\n",
       "      <td>3.129</td>\n",
       "      <td>0.946</td>\n",
       "      <td>0.432</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>89</td>\n",
       "      <td>3.085</td>\n",
       "      <td>3.130</td>\n",
       "      <td>0.932</td>\n",
       "      <td>0.432</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>3.085</td>\n",
       "      <td>3.129</td>\n",
       "      <td>0.950</td>\n",
       "      <td>0.432</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>91</td>\n",
       "      <td>3.085</td>\n",
       "      <td>3.130</td>\n",
       "      <td>0.932</td>\n",
       "      <td>0.432</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>92</td>\n",
       "      <td>3.085</td>\n",
       "      <td>3.130</td>\n",
       "      <td>0.932</td>\n",
       "      <td>0.432</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>93</td>\n",
       "      <td>3.085</td>\n",
       "      <td>3.129</td>\n",
       "      <td>0.933</td>\n",
       "      <td>0.432</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>94</td>\n",
       "      <td>3.085</td>\n",
       "      <td>3.129</td>\n",
       "      <td>0.933</td>\n",
       "      <td>0.432</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95</td>\n",
       "      <td>3.085</td>\n",
       "      <td>3.129</td>\n",
       "      <td>0.933</td>\n",
       "      <td>0.432</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>3.085</td>\n",
       "      <td>3.130</td>\n",
       "      <td>0.933</td>\n",
       "      <td>0.432</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>97</td>\n",
       "      <td>3.085</td>\n",
       "      <td>3.129</td>\n",
       "      <td>0.933</td>\n",
       "      <td>0.432</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98</td>\n",
       "      <td>3.085</td>\n",
       "      <td>3.129</td>\n",
       "      <td>0.935</td>\n",
       "      <td>0.432</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>99</td>\n",
       "      <td>3.085</td>\n",
       "      <td>3.129</td>\n",
       "      <td>0.935</td>\n",
       "      <td>0.432</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>3.085</td>\n",
       "      <td>3.129</td>\n",
       "      <td>0.935</td>\n",
       "      <td>0.432</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cross-entropy</th>\n",
       "      <th>Error Rate</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>Precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Neural network</th>\n",
       "      <td>0.31292</td>\n",
       "      <td>0.70524</td>\n",
       "      <td>0.76552</td>\n",
       "      <td>0.93488</td>\n",
       "      <td>0.204</td>\n",
       "      <td>0.14276</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Cross-entropy  Error Rate      AUC  Sensitivity  Specificity  \\\n",
       "Neural network        0.31292     0.70524  0.76552      0.93488        0.204   \n",
       "\n",
       "                Precision  \n",
       "Neural network    0.14276  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "features = ['age', 'pdays', 'previous', 'emp_var_rate', 'cons_price_idx', 'cons_conf_idx', 'euribor_3m', 'nr_employed']\n",
    "feature_for_nn = best_features + features\n",
    "\n",
    "def get_model_performance(feature_list, algo_name):\n",
    "\n",
    "    X_train = train[feature_list]\n",
    "    X_valid = valid[feature_list]\n",
    "    y_prob = np.zeros(len(y_valid))\n",
    "    \n",
    "    trainset  = TensorDataset(torch.from_numpy(X_train.copy().to_numpy()).float(), torch.from_numpy(y_train.to_numpy()).float())\n",
    "    validset  = TensorDataset(torch.from_numpy(X_valid.copy().to_numpy()).float(), torch.from_numpy(y_valid.to_numpy()).float())\n",
    "    trainloader = DataLoader(trainset, batch_size = 1024, shuffle=True)\n",
    "\n",
    "    mlp = train_net(NeuralNetwork, len(feature_for_nn), trainloader, validset, num_epochs = 100, lr = 3e-3)\n",
    "\n",
    "    X = validset[:][0]\n",
    "    y_prob = predict(mlp, X).numpy()\n",
    "\n",
    "    lfp = 1\n",
    "    lfn = 19\n",
    "    tau = lfp/(lfp+lfn)\n",
    "\n",
    "    y_prob[y_prob < 1e-5] = 1e-5 # Log-loss returns NaN if too close to zero or one\n",
    "    y_prob[y_prob > 1- 1e-5] =  1- 1e-5\n",
    "\n",
    "    y_pred = (y_prob > tau).astype(int)\n",
    "    # y_pred = model.predict(X_valid)\n",
    "\n",
    "    tn, fp, fn, tp = confusion_matrix(y_valid, y_pred).ravel() \n",
    "\n",
    "    columns=['Cross-entropy', 'Error Rate', 'AUC', 'Sensitivity', 'Specificity', 'Precision']\n",
    "\n",
    "    results = pd.DataFrame(0.0, columns=columns, index=[algo_name])\n",
    "\n",
    "    results.iloc[:,0] =  log_loss(y_valid, y_prob)   # Cross entropy\n",
    "    results.iloc[:,1] =   1 - accuracy_score(y_valid, y_pred)   # Error rate\n",
    "    results.iloc[:,2] =  roc_auc_score(y_valid, y_prob)   # AUC\n",
    "    results.iloc[:,3] =  tp/(tp+fn)   # Sensitivity \n",
    "    results.iloc[:,4] =  tn/(tn+fp)   # Specificity\t\n",
    "    results.iloc[:,5] =  precision_score(y_valid, y_pred)   # Precision\n",
    "    return results, mlp\n",
    "\n",
    "\n",
    "results, fitted_model = get_model_performance(feature_for_nn, \"Neural network\")\n",
    "\n",
    "display(results.sort_values(by=['AUC'], ascending = [0]).round(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead85f66",
   "metadata": {},
   "source": [
    "# Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e593d18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ffa77554",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cm(labels, predictions):\n",
    "    cm = confusion_matrix(labels, predictions)\n",
    "    plt.figure(figsize=(5,5))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\")\n",
    "    plt.title('Confusion matrix')\n",
    "    plt.ylabel('Actual label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "    print('(True Negatives): ', cm[0][0])\n",
    "    print('(False Positives): ', cm[0][1])\n",
    "    print('(False Negatives): ', cm[1][0])\n",
    "    print('(True Positives): ', cm[1][1])\n",
    "    print('Total subscribed Transactions: ', np.sum(cm[1]))\n",
    "    \n",
    "    print('total loss from loss matrix:', cm[1][0] * 19 + cm[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a74e7838",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(True Negatives):  928\n",
      "(False Positives):  3621\n",
      "(False Negatives):  42\n",
      "(True Positives):  603\n",
      "Total subscribed Transactions:  645\n",
      "total loss from loss matrix: 4419\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 500x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def display_confusion_mat(feature_list):\n",
    "    X_valid = valid[feature_list]\n",
    "    validset  = TensorDataset(torch.from_numpy(X_valid.copy().to_numpy()).float(), torch.from_numpy(y_valid.to_numpy()).float())\n",
    "\n",
    "    lfp = 1\n",
    "    lfn = 19\n",
    "    tau = lfp/(lfp+lfn)\n",
    "\n",
    "    # y_pred = decision_tree.predict(X_valid[feature_for_dt])\n",
    "\n",
    "    y_prob = predict(fitted_model, validset[:][0]).numpy()\n",
    "\n",
    "    y_prob[y_prob < 1e-5] = 1e-5 # Log-loss returns NaN if too close to zero or one\n",
    "    y_prob[y_prob > 1- 1e-5] =  1- 1e-5\n",
    "\n",
    "    y_pred = (y_prob > tau).astype(int)\n",
    "    # y_pred = decision_tree.predict(valid[feature_for_dt])\n",
    "\n",
    "    plot_cm(y_valid, y_pred)\n",
    "display_confusion_mat(feature_for_nn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a8b9ef8",
   "metadata": {},
   "source": [
    "# Using optuna to optimize number of layers and neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "eb8d37a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetworkBuilder(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, trial):\n",
    "        super(NeuralNetworkBuilder, self).__init__()\n",
    "        \n",
    "        self.modules = []\n",
    "        self.neurons = []\n",
    "        \n",
    "        hidden_layers = trial.suggest_int('num_layers', 1, 5)\n",
    "        \n",
    "        for i in range(hidden_layers):\n",
    "            activation_func = trial.suggest_categorical(f'activation_func_{i}', ['relu', 'leakyrelu', 'tanh', 'sigmoid'])\n",
    "            \n",
    "            if activation_func == \"relu\":\n",
    "                self.activation_func = nn.ReLU()\n",
    "            elif activation_func == \"leakyrelu\":\n",
    "                self.activation_func = nn.LeakyReLU()\n",
    "            elif activation_func == \"tanh\":\n",
    "                self.activation_func = nn.Tanh()\n",
    "            elif activation_func == \"sigmoid\":\n",
    "                self.activation_func = nn.Sigmoid()\n",
    "                \n",
    "            neurons = trial.suggest_int(f'num_neurons_{i}', 1, 40)\n",
    "            self.neurons.append(neurons)\n",
    "            \n",
    "            if i == 0:\n",
    "                self.modules.append(nn.Linear(input_size, neurons))\n",
    "                \n",
    "            else:\n",
    "                self.modules.append(nn.Linear(self.neurons[i - 1], neurons))\n",
    "            self.modules.append(self.activation_func)\n",
    "        \n",
    "        self.modules.append(nn.Linear(self.neurons[-1], 1))\n",
    "        self.modules.append(nn.Sigmoid())\n",
    "        \n",
    "        self.feedforward = nn.Sequential(*self.modules)                        \n",
    "\n",
    "\n",
    "    def forward(self, X):        \n",
    "        return self.feedforward(X).flatten() # returns a flat array as desired"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "23f563f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:43:55,881]\u001b[0m A new study created in memory with name: no-name-75c66edb-9f72-4fc8-b534-e9fadfade73f\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:43:59,922]\u001b[0m Trial 0 finished with value: 0.0 and parameters: {'num_layers': 2, 'activation_func_0': 'relu', 'num_neurons_0': 7, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 1}. Best is trial 0 with value: 0.0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:44:04,319]\u001b[0m Trial 1 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'relu', 'num_neurons_0': 13, 'activation_func_1': 'sigmoid', 'num_neurons_1': 6, 'activation_func_2': 'sigmoid', 'num_neurons_2': 8, 'activation_func_3': 'sigmoid', 'num_neurons_3': 7, 'activation_func_4': 'tanh', 'num_neurons_4': 13}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:44:08,264]\u001b[0m Trial 2 finished with value: 0.0 and parameters: {'num_layers': 1, 'activation_func_0': 'relu', 'num_neurons_0': 2}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:44:12,575]\u001b[0m Trial 3 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 22, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 36, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 2, 'activation_func_3': 'sigmoid', 'num_neurons_3': 15, 'activation_func_4': 'sigmoid', 'num_neurons_4': 3}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:44:17,021]\u001b[0m Trial 4 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'sigmoid', 'num_neurons_0': 29, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 5, 'activation_func_2': 'relu', 'num_neurons_2': 13, 'activation_func_3': 'sigmoid', 'num_neurons_3': 19, 'activation_func_4': 'tanh', 'num_neurons_4': 31}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:44:21,153]\u001b[0m Trial 5 finished with value: 0.22092824113718101 and parameters: {'num_layers': 3, 'activation_func_0': 'relu', 'num_neurons_0': 2, 'activation_func_1': 'sigmoid', 'num_neurons_1': 10, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 12}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:44:24,957]\u001b[0m Trial 6 finished with value: 0.0 and parameters: {'num_layers': 1, 'activation_func_0': 'relu', 'num_neurons_0': 33}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:44:28,830]\u001b[0m Trial 7 finished with value: 0.22092824113718101 and parameters: {'num_layers': 1, 'activation_func_0': 'sigmoid', 'num_neurons_0': 13}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:44:32,799]\u001b[0m Trial 8 finished with value: 0.22092824113718101 and parameters: {'num_layers': 1, 'activation_func_0': 'sigmoid', 'num_neurons_0': 1}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:44:36,985]\u001b[0m Trial 9 finished with value: 0.22092824113718101 and parameters: {'num_layers': 3, 'activation_func_0': 'relu', 'num_neurons_0': 38, 'activation_func_1': 'tanh', 'num_neurons_1': 39, 'activation_func_2': 'relu', 'num_neurons_2': 12}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:44:41,396]\u001b[0m Trial 10 finished with value: 0.22092824113718101 and parameters: {'num_layers': 4, 'activation_func_0': 'tanh', 'num_neurons_0': 16, 'activation_func_1': 'relu', 'num_neurons_1': 21, 'activation_func_2': 'sigmoid', 'num_neurons_2': 39, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 2}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:44:45,997]\u001b[0m Trial 11 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 23, 'activation_func_1': 'sigmoid', 'num_neurons_1': 37, 'activation_func_2': 'tanh', 'num_neurons_2': 1, 'activation_func_3': 'sigmoid', 'num_neurons_3': 10, 'activation_func_4': 'sigmoid', 'num_neurons_4': 2}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:44:50,462]\u001b[0m Trial 12 finished with value: 0.22092824113718101 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 20, 'activation_func_1': 'sigmoid', 'num_neurons_1': 26, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 1, 'activation_func_3': 'relu', 'num_neurons_3': 39}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:44:54,708]\u001b[0m Trial 13 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 12, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 14, 'activation_func_2': 'sigmoid', 'num_neurons_2': 26, 'activation_func_3': 'tanh', 'num_neurons_3': 13, 'activation_func_4': 'sigmoid', 'num_neurons_4': 6}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:44:58,850]\u001b[0m Trial 14 finished with value: 0.22092824113718101 and parameters: {'num_layers': 4, 'activation_func_0': 'tanh', 'num_neurons_0': 25, 'activation_func_1': 'tanh', 'num_neurons_1': 29, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 6, 'activation_func_3': 'sigmoid', 'num_neurons_3': 27}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:45:03,188]\u001b[0m Trial 15 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 19, 'activation_func_1': 'relu', 'num_neurons_1': 16, 'activation_func_2': 'sigmoid', 'num_neurons_2': 25, 'activation_func_3': 'sigmoid', 'num_neurons_3': 1, 'activation_func_4': 'leakyrelu', 'num_neurons_4': 14}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:45:07,756]\u001b[0m Trial 16 finished with value: 0.22092824113718101 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 9, 'activation_func_1': 'sigmoid', 'num_neurons_1': 32, 'activation_func_2': 'tanh', 'num_neurons_2': 8, 'activation_func_3': 'sigmoid', 'num_neurons_3': 13}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:45:12,214]\u001b[0m Trial 17 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'tanh', 'num_neurons_0': 27, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 20, 'activation_func_2': 'sigmoid', 'num_neurons_2': 19, 'activation_func_3': 'relu', 'num_neurons_3': 24, 'activation_func_4': 'relu', 'num_neurons_4': 15}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:45:16,420]\u001b[0m Trial 18 finished with value: 0.22092824113718101 and parameters: {'num_layers': 3, 'activation_func_0': 'relu', 'num_neurons_0': 16, 'activation_func_1': 'sigmoid', 'num_neurons_1': 8, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 6}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:45:20,770]\u001b[0m Trial 19 finished with value: 0.22092824113718101 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 31, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 24, 'activation_func_2': 'sigmoid', 'num_neurons_2': 17, 'activation_func_3': 'tanh', 'num_neurons_3': 8}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:45:25,623]\u001b[0m Trial 20 finished with value: 0.0 and parameters: {'num_layers': 2, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 7, 'activation_func_1': 'relu', 'num_neurons_1': 14}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:45:30,665]\u001b[0m Trial 21 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'sigmoid', 'num_neurons_0': 29, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 1, 'activation_func_2': 'relu', 'num_neurons_2': 12, 'activation_func_3': 'sigmoid', 'num_neurons_3': 19, 'activation_func_4': 'tanh', 'num_neurons_4': 35}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:45:35,160]\u001b[0m Trial 22 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'sigmoid', 'num_neurons_0': 36, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 6, 'activation_func_2': 'relu', 'num_neurons_2': 7, 'activation_func_3': 'sigmoid', 'num_neurons_3': 19, 'activation_func_4': 'tanh', 'num_neurons_4': 30}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:45:39,914]\u001b[0m Trial 23 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'sigmoid', 'num_neurons_0': 26, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 5, 'activation_func_2': 'relu', 'num_neurons_2': 15, 'activation_func_3': 'sigmoid', 'num_neurons_3': 17, 'activation_func_4': 'tanh', 'num_neurons_4': 25}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:45:44,347]\u001b[0m Trial 24 finished with value: 0.22092824113718101 and parameters: {'num_layers': 4, 'activation_func_0': 'sigmoid', 'num_neurons_0': 23, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 34, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 1, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 30}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:45:48,711]\u001b[0m Trial 25 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'sigmoid', 'num_neurons_0': 17, 'activation_func_1': 'tanh', 'num_neurons_1': 10, 'activation_func_2': 'relu', 'num_neurons_2': 23, 'activation_func_3': 'sigmoid', 'num_neurons_3': 6, 'activation_func_4': 'tanh', 'num_neurons_4': 11}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:45:53,177]\u001b[0m Trial 26 finished with value: 0.22092824113718101 and parameters: {'num_layers': 4, 'activation_func_0': 'relu', 'num_neurons_0': 34, 'activation_func_1': 'sigmoid', 'num_neurons_1': 4, 'activation_func_2': 'tanh', 'num_neurons_2': 31, 'activation_func_3': 'sigmoid', 'num_neurons_3': 15}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:45:57,556]\u001b[0m Trial 27 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'tanh', 'num_neurons_0': 22, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 16, 'activation_func_2': 'sigmoid', 'num_neurons_2': 10, 'activation_func_3': 'sigmoid', 'num_neurons_3': 23, 'activation_func_4': 'sigmoid', 'num_neurons_4': 22}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:46:01,991]\u001b[0m Trial 28 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 29, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 11, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 4, 'activation_func_3': 'tanh', 'num_neurons_3': 6, 'activation_func_4': 'tanh', 'num_neurons_4': 37}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:46:06,095]\u001b[0m Trial 29 finished with value: 0.22092824113718101 and parameters: {'num_layers': 3, 'activation_func_0': 'relu', 'num_neurons_0': 12, 'activation_func_1': 'sigmoid', 'num_neurons_1': 20, 'activation_func_2': 'relu', 'num_neurons_2': 15}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:46:10,182]\u001b[0m Trial 30 finished with value: 0.22092824113718101 and parameters: {'num_layers': 2, 'activation_func_0': 'sigmoid', 'num_neurons_0': 40, 'activation_func_1': 'relu', 'num_neurons_1': 29}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:46:14,196]\u001b[0m Trial 31 finished with value: 0.22092824113718101 and parameters: {'num_layers': 3, 'activation_func_0': 'relu', 'num_neurons_0': 3, 'activation_func_1': 'sigmoid', 'num_neurons_1': 9, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 12}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:46:18,285]\u001b[0m Trial 32 finished with value: 0.22092824113718101 and parameters: {'num_layers': 3, 'activation_func_0': 'relu', 'num_neurons_0': 5, 'activation_func_1': 'sigmoid', 'num_neurons_1': 4, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 9}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:46:22,358]\u001b[0m Trial 33 finished with value: 0.22092824113718101 and parameters: {'num_layers': 2, 'activation_func_0': 'relu', 'num_neurons_0': 10, 'activation_func_1': 'sigmoid', 'num_neurons_1': 12}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:46:26,927]\u001b[0m Trial 34 finished with value: 0.22092824113718101 and parameters: {'num_layers': 4, 'activation_func_0': 'relu', 'num_neurons_0': 5, 'activation_func_1': 'sigmoid', 'num_neurons_1': 2, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 4, 'activation_func_3': 'relu', 'num_neurons_3': 10}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:46:31,294]\u001b[0m Trial 35 finished with value: 0.22092824113718101 and parameters: {'num_layers': 3, 'activation_func_0': 'relu', 'num_neurons_0': 18, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 7, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 15}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:46:35,821]\u001b[0m Trial 36 finished with value: 0.22092824113718101 and parameters: {'num_layers': 4, 'activation_func_0': 'relu', 'num_neurons_0': 31, 'activation_func_1': 'tanh', 'num_neurons_1': 40, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 4, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 33}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:46:40,129]\u001b[0m Trial 37 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'relu', 'num_neurons_0': 14, 'activation_func_1': 'sigmoid', 'num_neurons_1': 3, 'activation_func_2': 'relu', 'num_neurons_2': 11, 'activation_func_3': 'sigmoid', 'num_neurons_3': 15, 'activation_func_4': 'relu', 'num_neurons_4': 7}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:46:44,261]\u001b[0m Trial 38 finished with value: 0.22092824113718101 and parameters: {'num_layers': 3, 'activation_func_0': 'sigmoid', 'num_neurons_0': 9, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 17, 'activation_func_2': 'sigmoid', 'num_neurons_2': 20}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:46:48,250]\u001b[0m Trial 39 finished with value: 0.22092824113718101 and parameters: {'num_layers': 2, 'activation_func_0': 'relu', 'num_neurons_0': 2, 'activation_func_1': 'tanh', 'num_neurons_1': 36}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:46:52,359]\u001b[0m Trial 40 finished with value: 0.22092824113718101 and parameters: {'num_layers': 4, 'activation_func_0': 'tanh', 'num_neurons_0': 22, 'activation_func_1': 'sigmoid', 'num_neurons_1': 7, 'activation_func_2': 'relu', 'num_neurons_2': 13, 'activation_func_3': 'sigmoid', 'num_neurons_3': 20}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:46:56,359]\u001b[0m Trial 41 finished with value: 0.22092824113718101 and parameters: {'num_layers': 1, 'activation_func_0': 'sigmoid', 'num_neurons_0': 13}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:47:00,412]\u001b[0m Trial 42 finished with value: 0.22092824113718101 and parameters: {'num_layers': 1, 'activation_func_0': 'sigmoid', 'num_neurons_0': 14}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:47:04,325]\u001b[0m Trial 43 finished with value: 0.22092824113718101 and parameters: {'num_layers': 1, 'activation_func_0': 'sigmoid', 'num_neurons_0': 20}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:47:08,608]\u001b[0m Trial 44 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 24, 'activation_func_1': 'relu', 'num_neurons_1': 23, 'activation_func_2': 'tanh', 'num_neurons_2': 9, 'activation_func_3': 'sigmoid', 'num_neurons_3': 23, 'activation_func_4': 'leakyrelu', 'num_neurons_4': 1}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:47:12,476]\u001b[0m Trial 45 finished with value: 0.22092824113718101 and parameters: {'num_layers': 1, 'activation_func_0': 'sigmoid', 'num_neurons_0': 7}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:47:16,489]\u001b[0m Trial 46 finished with value: 0.0 and parameters: {'num_layers': 2, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 15, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 13}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:47:20,861]\u001b[0m Trial 47 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'tanh', 'num_neurons_0': 11, 'activation_func_1': 'sigmoid', 'num_neurons_1': 1, 'activation_func_2': 'sigmoid', 'num_neurons_2': 37, 'activation_func_3': 'sigmoid', 'num_neurons_3': 4, 'activation_func_4': 'sigmoid', 'num_neurons_4': 18}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:47:25,201]\u001b[0m Trial 48 finished with value: 0.22092824113718101 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 27, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 29, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 3, 'activation_func_3': 'relu', 'num_neurons_3': 11}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:47:29,726]\u001b[0m Trial 49 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'sigmoid', 'num_neurons_0': 1, 'activation_func_1': 'tanh', 'num_neurons_1': 9, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 17, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 17, 'activation_func_4': 'tanh', 'num_neurons_4': 27}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:47:33,864]\u001b[0m Trial 50 finished with value: 0.22092824113718101 and parameters: {'num_layers': 2, 'activation_func_0': 'relu', 'num_neurons_0': 20, 'activation_func_1': 'sigmoid', 'num_neurons_1': 18}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:47:38,149]\u001b[0m Trial 51 finished with value: 0.22092824113718101 and parameters: {'num_layers': 1, 'activation_func_0': 'sigmoid', 'num_neurons_0': 4}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:47:42,212]\u001b[0m Trial 52 finished with value: 0.22092824113718101 and parameters: {'num_layers': 1, 'activation_func_0': 'sigmoid', 'num_neurons_0': 1}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:47:46,132]\u001b[0m Trial 53 finished with value: 0.22092824113718101 and parameters: {'num_layers': 1, 'activation_func_0': 'sigmoid', 'num_neurons_0': 8}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:47:50,081]\u001b[0m Trial 54 finished with value: 0.22092824113718101 and parameters: {'num_layers': 1, 'activation_func_0': 'sigmoid', 'num_neurons_0': 3}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:47:54,388]\u001b[0m Trial 55 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 6, 'activation_func_1': 'relu', 'num_neurons_1': 32, 'activation_func_2': 'sigmoid', 'num_neurons_2': 6, 'activation_func_3': 'tanh', 'num_neurons_3': 14, 'activation_func_4': 'tanh', 'num_neurons_4': 9}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:47:58,506]\u001b[0m Trial 56 finished with value: 0.22092824113718101 and parameters: {'num_layers': 2, 'activation_func_0': 'sigmoid', 'num_neurons_0': 18, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 26}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:48:03,352]\u001b[0m Trial 57 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 34, 'activation_func_1': 'sigmoid', 'num_neurons_1': 15, 'activation_func_2': 'tanh', 'num_neurons_2': 1, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 7, 'activation_func_4': 'sigmoid', 'num_neurons_4': 33}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:48:07,502]\u001b[0m Trial 58 finished with value: 0.22092824113718101 and parameters: {'num_layers': 4, 'activation_func_0': 'tanh', 'num_neurons_0': 25, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 6, 'activation_func_2': 'relu', 'num_neurons_2': 14, 'activation_func_3': 'sigmoid', 'num_neurons_3': 3}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:48:11,826]\u001b[0m Trial 59 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'relu', 'num_neurons_0': 16, 'activation_func_1': 'sigmoid', 'num_neurons_1': 11, 'activation_func_2': 'sigmoid', 'num_neurons_2': 22, 'activation_func_3': 'sigmoid', 'num_neurons_3': 26, 'activation_func_4': 'tanh', 'num_neurons_4': 20}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:48:15,722]\u001b[0m Trial 60 finished with value: 0.22092824113718101 and parameters: {'num_layers': 1, 'activation_func_0': 'sigmoid', 'num_neurons_0': 28}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:48:20,016]\u001b[0m Trial 61 finished with value: 0.22092824113718101 and parameters: {'num_layers': 3, 'activation_func_0': 'relu', 'num_neurons_0': 38, 'activation_func_1': 'tanh', 'num_neurons_1': 38, 'activation_func_2': 'relu', 'num_neurons_2': 18}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:48:24,153]\u001b[0m Trial 62 finished with value: 0.22092824113718101 and parameters: {'num_layers': 3, 'activation_func_0': 'relu', 'num_neurons_0': 31, 'activation_func_1': 'tanh', 'num_neurons_1': 40, 'activation_func_2': 'relu', 'num_neurons_2': 8}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:48:28,309]\u001b[0m Trial 63 finished with value: 0.22092824113718101 and parameters: {'num_layers': 3, 'activation_func_0': 'relu', 'num_neurons_0': 40, 'activation_func_1': 'tanh', 'num_neurons_1': 37, 'activation_func_2': 'relu', 'num_neurons_2': 11}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:48:32,573]\u001b[0m Trial 64 finished with value: 0.22092824113718101 and parameters: {'num_layers': 4, 'activation_func_0': 'relu', 'num_neurons_0': 36, 'activation_func_1': 'tanh', 'num_neurons_1': 34, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 6, 'activation_func_3': 'relu', 'num_neurons_3': 17}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:48:36,780]\u001b[0m Trial 65 finished with value: 0.22092824113718101 and parameters: {'num_layers': 3, 'activation_func_0': 'relu', 'num_neurons_0': 32, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 35, 'activation_func_2': 'sigmoid', 'num_neurons_2': 29}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:48:41,176]\u001b[0m Trial 66 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 21, 'activation_func_1': 'relu', 'num_neurons_1': 38, 'activation_func_2': 'relu', 'num_neurons_2': 13, 'activation_func_3': 'sigmoid', 'num_neurons_3': 40, 'activation_func_4': 'relu', 'num_neurons_4': 5}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:48:45,687]\u001b[0m Trial 67 finished with value: 0.22092824113718101 and parameters: {'num_layers': 2, 'activation_func_0': 'sigmoid', 'num_neurons_0': 11, 'activation_func_1': 'tanh', 'num_neurons_1': 31}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:48:49,978]\u001b[0m Trial 68 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'relu', 'num_neurons_0': 3, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 22, 'activation_func_2': 'tanh', 'num_neurons_2': 10, 'activation_func_3': 'tanh', 'num_neurons_3': 12, 'activation_func_4': 'leakyrelu', 'num_neurons_4': 39}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:48:53,998]\u001b[0m Trial 69 finished with value: 0.22092824113718101 and parameters: {'num_layers': 3, 'activation_func_0': 'sigmoid', 'num_neurons_0': 37, 'activation_func_1': 'sigmoid', 'num_neurons_1': 5, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 7}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:48:58,060]\u001b[0m Trial 70 finished with value: 0.22092824113718101 and parameters: {'num_layers': 4, 'activation_func_0': 'relu', 'num_neurons_0': 6, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 26, 'activation_func_2': 'relu', 'num_neurons_2': 17, 'activation_func_3': 'sigmoid', 'num_neurons_3': 35}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:49:02,617]\u001b[0m Trial 71 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'tanh', 'num_neurons_0': 17, 'activation_func_1': 'relu', 'num_neurons_1': 8, 'activation_func_2': 'sigmoid', 'num_neurons_2': 40, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 3, 'activation_func_4': 'sigmoid', 'num_neurons_4': 13}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:49:07,005]\u001b[0m Trial 72 finished with value: 0.22092824113718101 and parameters: {'num_layers': 4, 'activation_func_0': 'tanh', 'num_neurons_0': 13, 'activation_func_1': 'relu', 'num_neurons_1': 3, 'activation_func_2': 'sigmoid', 'num_neurons_2': 33, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 1}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:49:11,265]\u001b[0m Trial 73 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'tanh', 'num_neurons_0': 9, 'activation_func_1': 'relu', 'num_neurons_1': 18, 'activation_func_2': 'sigmoid', 'num_neurons_2': 25, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 5, 'activation_func_4': 'tanh', 'num_neurons_4': 17}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:49:15,572]\u001b[0m Trial 74 finished with value: 0.22092824113718101 and parameters: {'num_layers': 4, 'activation_func_0': 'tanh', 'num_neurons_0': 15, 'activation_func_1': 'relu', 'num_neurons_1': 28, 'activation_func_2': 'sigmoid', 'num_neurons_2': 28, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 10}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:49:20,110]\u001b[0m Trial 75 finished with value: 0.22092824113718101 and parameters: {'num_layers': 3, 'activation_func_0': 'tanh', 'num_neurons_0': 23, 'activation_func_1': 'sigmoid', 'num_neurons_1': 10, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 22}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:49:24,785]\u001b[0m Trial 76 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 18, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 39, 'activation_func_2': 'sigmoid', 'num_neurons_2': 3, 'activation_func_3': 'sigmoid', 'num_neurons_3': 8, 'activation_func_4': 'tanh', 'num_neurons_4': 23}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:49:29,221]\u001b[0m Trial 77 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'sigmoid', 'num_neurons_0': 30, 'activation_func_1': 'relu', 'num_neurons_1': 21, 'activation_func_2': 'relu', 'num_neurons_2': 15, 'activation_func_3': 'relu', 'num_neurons_3': 9, 'activation_func_4': 'sigmoid', 'num_neurons_4': 30}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:49:33,411]\u001b[0m Trial 78 finished with value: 0.22092824113718101 and parameters: {'num_layers': 4, 'activation_func_0': 'relu', 'num_neurons_0': 12, 'activation_func_1': 'sigmoid', 'num_neurons_1': 31, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 8, 'activation_func_3': 'sigmoid', 'num_neurons_3': 21}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:49:37,413]\u001b[0m Trial 79 finished with value: 0.22092824113718101 and parameters: {'num_layers': 3, 'activation_func_0': 'sigmoid', 'num_neurons_0': 34, 'activation_func_1': 'tanh', 'num_neurons_1': 14, 'activation_func_2': 'relu', 'num_neurons_2': 34}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:49:41,400]\u001b[0m Trial 80 finished with value: 0.22092824113718101 and parameters: {'num_layers': 2, 'activation_func_0': 'relu', 'num_neurons_0': 19, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 6}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:49:45,650]\u001b[0m Trial 81 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 26, 'activation_func_1': 'sigmoid', 'num_neurons_1': 34, 'activation_func_2': 'tanh', 'num_neurons_2': 1, 'activation_func_3': 'sigmoid', 'num_neurons_3': 1, 'activation_func_4': 'sigmoid', 'num_neurons_4': 2}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:49:49,924]\u001b[0m Trial 82 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 22, 'activation_func_1': 'sigmoid', 'num_neurons_1': 37, 'activation_func_2': 'tanh', 'num_neurons_2': 2, 'activation_func_3': 'sigmoid', 'num_neurons_3': 13, 'activation_func_4': 'sigmoid', 'num_neurons_4': 4}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:49:54,425]\u001b[0m Trial 83 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 24, 'activation_func_1': 'sigmoid', 'num_neurons_1': 35, 'activation_func_2': 'tanh', 'num_neurons_2': 4, 'activation_func_3': 'sigmoid', 'num_neurons_3': 16, 'activation_func_4': 'sigmoid', 'num_neurons_4': 10}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:49:58,798]\u001b[0m Trial 84 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 16, 'activation_func_1': 'sigmoid', 'num_neurons_1': 33, 'activation_func_2': 'tanh', 'num_neurons_2': 5, 'activation_func_3': 'sigmoid', 'num_neurons_3': 12, 'activation_func_4': 'sigmoid', 'num_neurons_4': 1}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:50:02,681]\u001b[0m Trial 85 finished with value: 0.22092824113718101 and parameters: {'num_layers': 1, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 21}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:50:07,132]\u001b[0m Trial 86 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'sigmoid', 'num_neurons_0': 19, 'activation_func_1': 'sigmoid', 'num_neurons_1': 40, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 12, 'activation_func_3': 'tanh', 'num_neurons_3': 8, 'activation_func_4': 'sigmoid', 'num_neurons_4': 7}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:50:11,591]\u001b[0m Trial 87 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'tanh', 'num_neurons_0': 2, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 4, 'activation_func_2': 'sigmoid', 'num_neurons_2': 9, 'activation_func_3': 'sigmoid', 'num_neurons_3': 18, 'activation_func_4': 'relu', 'num_neurons_4': 4}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:50:15,828]\u001b[0m Trial 88 finished with value: 0.22092824113718101 and parameters: {'num_layers': 4, 'activation_func_0': 'relu', 'num_neurons_0': 10, 'activation_func_1': 'sigmoid', 'num_neurons_1': 1, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 16, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 6}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:50:19,998]\u001b[0m Trial 89 finished with value: 0.22092824113718101 and parameters: {'num_layers': 4, 'activation_func_0': 'sigmoid', 'num_neurons_0': 28, 'activation_func_1': 'relu', 'num_neurons_1': 8, 'activation_func_2': 'tanh', 'num_neurons_2': 19, 'activation_func_3': 'sigmoid', 'num_neurons_3': 3}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:50:24,096]\u001b[0m Trial 90 finished with value: 0.22092824113718101 and parameters: {'num_layers': 1, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 4}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:50:28,354]\u001b[0m Trial 91 finished with value: 0.22092824113718101 and parameters: {'num_layers': 3, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 23, 'activation_func_1': 'sigmoid', 'num_neurons_1': 20, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 2}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:50:32,620]\u001b[0m Trial 92 finished with value: 0.22092824113718101 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 14, 'activation_func_1': 'sigmoid', 'num_neurons_1': 26, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 5, 'activation_func_3': 'relu', 'num_neurons_3': 28}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:50:37,101]\u001b[0m Trial 93 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 17, 'activation_func_1': 'sigmoid', 'num_neurons_1': 24, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 2, 'activation_func_3': 'relu', 'num_neurons_3': 22, 'activation_func_4': 'leakyrelu', 'num_neurons_4': 8}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:50:41,859]\u001b[0m Trial 94 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 20, 'activation_func_1': 'sigmoid', 'num_neurons_1': 36, 'activation_func_2': 'relu', 'num_neurons_2': 7, 'activation_func_3': 'relu', 'num_neurons_3': 20, 'activation_func_4': 'tanh', 'num_neurons_4': 12}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:50:46,077]\u001b[0m Trial 95 finished with value: 0.22092824113718101 and parameters: {'num_layers': 3, 'activation_func_0': 'relu', 'num_neurons_0': 26, 'activation_func_1': 'tanh', 'num_neurons_1': 19, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 11}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:50:50,334]\u001b[0m Trial 96 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'sigmoid', 'num_neurons_0': 25, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 38, 'activation_func_2': 'sigmoid', 'num_neurons_2': 13, 'activation_func_3': 'relu', 'num_neurons_3': 14, 'activation_func_4': 'sigmoid', 'num_neurons_4': 16}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:50:54,316]\u001b[0m Trial 97 finished with value: 0.22092824113718101 and parameters: {'num_layers': 2, 'activation_func_0': 'relu', 'num_neurons_0': 19, 'activation_func_1': 'sigmoid', 'num_neurons_1': 28}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:50:58,345]\u001b[0m Trial 98 finished with value: 0.22092824113718101 and parameters: {'num_layers': 1, 'activation_func_0': 'sigmoid', 'num_neurons_0': 15}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:51:02,576]\u001b[0m Trial 99 finished with value: 0.22092824113718101 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 22, 'activation_func_1': 'sigmoid', 'num_neurons_1': 24, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 5, 'activation_func_3': 'sigmoid', 'num_neurons_3': 25}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:51:06,890]\u001b[0m Trial 100 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'tanh', 'num_neurons_0': 39, 'activation_func_1': 'tanh', 'num_neurons_1': 15, 'activation_func_2': 'relu', 'num_neurons_2': 3, 'activation_func_3': 'sigmoid', 'num_neurons_3': 40, 'activation_func_4': 'leakyrelu', 'num_neurons_4': 4}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:51:11,495]\u001b[0m Trial 101 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 12, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 11, 'activation_func_2': 'sigmoid', 'num_neurons_2': 40, 'activation_func_3': 'tanh', 'num_neurons_3': 9, 'activation_func_4': 'sigmoid', 'num_neurons_4': 6}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:51:16,160]\u001b[0m Trial 102 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 13, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 9, 'activation_func_2': 'sigmoid', 'num_neurons_2': 38, 'activation_func_3': 'tanh', 'num_neurons_3': 15, 'activation_func_4': 'sigmoid', 'num_neurons_4': 14}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:51:20,551]\u001b[0m Trial 103 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 11, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 13, 'activation_func_2': 'sigmoid', 'num_neurons_2': 1, 'activation_func_3': 'tanh', 'num_neurons_3': 11, 'activation_func_4': 'tanh', 'num_neurons_4': 2}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:51:24,881]\u001b[0m Trial 104 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'relu', 'num_neurons_0': 1, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 7, 'activation_func_2': 'sigmoid', 'num_neurons_2': 10, 'activation_func_3': 'tanh', 'num_neurons_3': 19, 'activation_func_4': 'sigmoid', 'num_neurons_4': 10}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:51:29,141]\u001b[0m Trial 105 finished with value: 0.22092824113718101 and parameters: {'num_layers': 3, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 8, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 5, 'activation_func_2': 'relu', 'num_neurons_2': 14}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:51:33,570]\u001b[0m Trial 106 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'sigmoid', 'num_neurons_0': 17, 'activation_func_1': 'relu', 'num_neurons_1': 16, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 33, 'activation_func_3': 'sigmoid', 'num_neurons_3': 13, 'activation_func_4': 'tanh', 'num_neurons_4': 5}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:51:37,818]\u001b[0m Trial 107 finished with value: 0.22092824113718101 and parameters: {'num_layers': 4, 'activation_func_0': 'relu', 'num_neurons_0': 14, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 12, 'activation_func_2': 'sigmoid', 'num_neurons_2': 25, 'activation_func_3': 'relu', 'num_neurons_3': 33}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:51:42,073]\u001b[0m Trial 108 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'sigmoid', 'num_neurons_0': 15, 'activation_func_1': 'sigmoid', 'num_neurons_1': 36, 'activation_func_2': 'tanh', 'num_neurons_2': 30, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 5, 'activation_func_4': 'relu', 'num_neurons_4': 3}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:51:46,145]\u001b[0m Trial 109 finished with value: 0.22092824113718101 and parameters: {'num_layers': 2, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 16, 'activation_func_1': 'tanh', 'num_neurons_1': 10}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:51:50,055]\u001b[0m Trial 110 finished with value: 0.22092824113718101 and parameters: {'num_layers': 1, 'activation_func_0': 'tanh', 'num_neurons_0': 10}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:51:54,226]\u001b[0m Trial 111 finished with value: 0.22092824113718101 and parameters: {'num_layers': 4, 'activation_func_0': 'tanh', 'num_neurons_0': 24, 'activation_func_1': 'tanh', 'num_neurons_1': 39, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 7, 'activation_func_3': 'sigmoid', 'num_neurons_3': 38}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:51:58,363]\u001b[0m Trial 112 finished with value: 0.22092824113718101 and parameters: {'num_layers': 4, 'activation_func_0': 'tanh', 'num_neurons_0': 21, 'activation_func_1': 'tanh', 'num_neurons_1': 29, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 8, 'activation_func_3': 'sigmoid', 'num_neurons_3': 18}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:52:02,467]\u001b[0m Trial 113 finished with value: 0.22092824113718101 and parameters: {'num_layers': 3, 'activation_func_0': 'tanh', 'num_neurons_0': 25, 'activation_func_1': 'tanh', 'num_neurons_1': 25, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 10}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:52:06,615]\u001b[0m Trial 114 finished with value: 0.22092824113718101 and parameters: {'num_layers': 4, 'activation_func_0': 'tanh', 'num_neurons_0': 27, 'activation_func_1': 'tanh', 'num_neurons_1': 27, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 27, 'activation_func_3': 'sigmoid', 'num_neurons_3': 30}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:52:11,044]\u001b[0m Trial 115 finished with value: 0.22092824113718101 and parameters: {'num_layers': 4, 'activation_func_0': 'relu', 'num_neurons_0': 23, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 23, 'activation_func_2': 'relu', 'num_neurons_2': 6, 'activation_func_3': 'sigmoid', 'num_neurons_3': 16}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:52:15,365]\u001b[0m Trial 116 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'sigmoid', 'num_neurons_0': 30, 'activation_func_1': 'sigmoid', 'num_neurons_1': 31, 'activation_func_2': 'sigmoid', 'num_neurons_2': 3, 'activation_func_3': 'tanh', 'num_neurons_3': 11, 'activation_func_4': 'tanh', 'num_neurons_4': 8}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:52:19,462]\u001b[0m Trial 117 finished with value: 0.22092824113718101 and parameters: {'num_layers': 3, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 35, 'activation_func_1': 'relu', 'num_neurons_1': 37, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 4}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:52:23,702]\u001b[0m Trial 118 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'relu', 'num_neurons_0': 20, 'activation_func_1': 'sigmoid', 'num_neurons_1': 32, 'activation_func_2': 'relu', 'num_neurons_2': 1, 'activation_func_3': 'sigmoid', 'num_neurons_3': 36, 'activation_func_4': 'sigmoid', 'num_neurons_4': 27}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:52:27,863]\u001b[0m Trial 119 finished with value: 0.22092824113718101 and parameters: {'num_layers': 4, 'activation_func_0': 'sigmoid', 'num_neurons_0': 12, 'activation_func_1': 'tanh', 'num_neurons_1': 2, 'activation_func_2': 'sigmoid', 'num_neurons_2': 14, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 7}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:52:32,143]\u001b[0m Trial 120 finished with value: 0.22092824113718101 and parameters: {'num_layers': 3, 'activation_func_0': 'tanh', 'num_neurons_0': 4, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 21, 'activation_func_2': 'tanh', 'num_neurons_2': 12}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:52:36,578]\u001b[0m Trial 121 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 2, 'activation_func_1': 'relu', 'num_neurons_1': 13, 'activation_func_2': 'sigmoid', 'num_neurons_2': 26, 'activation_func_3': 'sigmoid', 'num_neurons_3': 5, 'activation_func_4': 'leakyrelu', 'num_neurons_4': 19}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:52:40,787]\u001b[0m Trial 122 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 19, 'activation_func_1': 'relu', 'num_neurons_1': 18, 'activation_func_2': 'sigmoid', 'num_neurons_2': 21, 'activation_func_3': 'sigmoid', 'num_neurons_3': 1, 'activation_func_4': 'leakyrelu', 'num_neurons_4': 15}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:52:45,227]\u001b[0m Trial 123 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 18, 'activation_func_1': 'relu', 'num_neurons_1': 17, 'activation_func_2': 'sigmoid', 'num_neurons_2': 24, 'activation_func_3': 'sigmoid', 'num_neurons_3': 3, 'activation_func_4': 'leakyrelu', 'num_neurons_4': 12}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:52:49,657]\u001b[0m Trial 124 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 22, 'activation_func_1': 'relu', 'num_neurons_1': 39, 'activation_func_2': 'sigmoid', 'num_neurons_2': 36, 'activation_func_3': 'sigmoid', 'num_neurons_3': 2, 'activation_func_4': 'tanh', 'num_neurons_4': 23}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:52:53,924]\u001b[0m Trial 125 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 21, 'activation_func_1': 'sigmoid', 'num_neurons_1': 19, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 18, 'activation_func_3': 'sigmoid', 'num_neurons_3': 10, 'activation_func_4': 'leakyrelu', 'num_neurons_4': 6}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:52:57,754]\u001b[0m Trial 126 finished with value: 0.0 and parameters: {'num_layers': 1, 'activation_func_0': 'relu', 'num_neurons_0': 32}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:53:01,973]\u001b[0m Trial 127 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'sigmoid', 'num_neurons_0': 23, 'activation_func_1': 'relu', 'num_neurons_1': 35, 'activation_func_2': 'relu', 'num_neurons_2': 2, 'activation_func_3': 'sigmoid', 'num_neurons_3': 4, 'activation_func_4': 'tanh', 'num_neurons_4': 1}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:53:06,306]\u001b[0m Trial 128 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 17, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 15, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 4, 'activation_func_3': 'relu', 'num_neurons_3': 14, 'activation_func_4': 'sigmoid', 'num_neurons_4': 34}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:53:10,727]\u001b[0m Trial 129 finished with value: 0.22092824113718101 and parameters: {'num_layers': 4, 'activation_func_0': 'relu', 'num_neurons_0': 13, 'activation_func_1': 'sigmoid', 'num_neurons_1': 30, 'activation_func_2': 'sigmoid', 'num_neurons_2': 8, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 7}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:53:15,171]\u001b[0m Trial 130 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'tanh', 'num_neurons_0': 28, 'activation_func_1': 'tanh', 'num_neurons_1': 22, 'activation_func_2': 'tanh', 'num_neurons_2': 23, 'activation_func_3': 'sigmoid', 'num_neurons_3': 31, 'activation_func_4': 'relu', 'num_neurons_4': 21}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:53:19,561]\u001b[0m Trial 131 finished with value: 0.22092824113718101 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 8, 'activation_func_1': 'sigmoid', 'num_neurons_1': 6, 'activation_func_2': 'tanh', 'num_neurons_2': 12, 'activation_func_3': 'sigmoid', 'num_neurons_3': 12}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:53:23,856]\u001b[0m Trial 132 finished with value: 0.22092824113718101 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 9, 'activation_func_1': 'sigmoid', 'num_neurons_1': 33, 'activation_func_2': 'tanh', 'num_neurons_2': 31, 'activation_func_3': 'sigmoid', 'num_neurons_3': 16}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:53:28,149]\u001b[0m Trial 133 finished with value: 0.22092824113718101 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 5, 'activation_func_1': 'sigmoid', 'num_neurons_1': 30, 'activation_func_2': 'tanh', 'num_neurons_2': 9, 'activation_func_3': 'sigmoid', 'num_neurons_3': 13}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:53:32,341]\u001b[0m Trial 134 finished with value: 0.22092824113718101 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 14, 'activation_func_1': 'sigmoid', 'num_neurons_1': 33, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 16, 'activation_func_3': 'sigmoid', 'num_neurons_3': 24}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:53:36,382]\u001b[0m Trial 135 finished with value: 0.22092824113718101 and parameters: {'num_layers': 3, 'activation_func_0': 'sigmoid', 'num_neurons_0': 11, 'activation_func_1': 'sigmoid', 'num_neurons_1': 36, 'activation_func_2': 'relu', 'num_neurons_2': 7}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:53:40,804]\u001b[0m Trial 136 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 20, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 28, 'activation_func_2': 'tanh', 'num_neurons_2': 6, 'activation_func_3': 'tanh', 'num_neurons_3': 27, 'activation_func_4': 'tanh', 'num_neurons_4': 36}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:53:45,125]\u001b[0m Trial 137 finished with value: 0.22092824113718101 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 1, 'activation_func_1': 'relu', 'num_neurons_1': 7, 'activation_func_2': 'sigmoid', 'num_neurons_2': 11, 'activation_func_3': 'sigmoid', 'num_neurons_3': 15}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:53:49,448]\u001b[0m Trial 138 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'relu', 'num_neurons_0': 3, 'activation_func_1': 'sigmoid', 'num_neurons_1': 12, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 5, 'activation_func_3': 'relu', 'num_neurons_3': 22, 'activation_func_4': 'sigmoid', 'num_neurons_4': 31}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:53:53,421]\u001b[0m Trial 139 finished with value: 0.22092824113718101 and parameters: {'num_layers': 1, 'activation_func_0': 'sigmoid', 'num_neurons_0': 6}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:53:57,658]\u001b[0m Trial 140 finished with value: 0.22092824113718101 and parameters: {'num_layers': 3, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 16, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 4, 'activation_func_2': 'sigmoid', 'num_neurons_2': 20}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:54:01,960]\u001b[0m Trial 141 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'tanh', 'num_neurons_0': 22, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 8, 'activation_func_2': 'sigmoid', 'num_neurons_2': 13, 'activation_func_3': 'relu', 'num_neurons_3': 9, 'activation_func_4': 'relu', 'num_neurons_4': 17}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:54:06,339]\u001b[0m Trial 142 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'tanh', 'num_neurons_0': 24, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 14, 'activation_func_2': 'sigmoid', 'num_neurons_2': 9, 'activation_func_3': 'relu', 'num_neurons_3': 24, 'activation_func_4': 'relu', 'num_neurons_4': 14}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:54:10,796]\u001b[0m Trial 143 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'tanh', 'num_neurons_0': 26, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 20, 'activation_func_2': 'sigmoid', 'num_neurons_2': 3, 'activation_func_3': 'relu', 'num_neurons_3': 18, 'activation_func_4': 'relu', 'num_neurons_4': 11}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:54:14,999]\u001b[0m Trial 144 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'tanh', 'num_neurons_0': 27, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 38, 'activation_func_2': 'relu', 'num_neurons_2': 15, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 22, 'activation_func_4': 'tanh', 'num_neurons_4': 40}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:54:19,166]\u001b[0m Trial 145 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'tanh', 'num_neurons_0': 13, 'activation_func_1': 'tanh', 'num_neurons_1': 17, 'activation_func_2': 'sigmoid', 'num_neurons_2': 2, 'activation_func_3': 'sigmoid', 'num_neurons_3': 2, 'activation_func_4': 'sigmoid', 'num_neurons_4': 18}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:54:23,306]\u001b[0m Trial 146 finished with value: 0.22092824113718101 and parameters: {'num_layers': 4, 'activation_func_0': 'relu', 'num_neurons_0': 25, 'activation_func_1': 'sigmoid', 'num_neurons_1': 16, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 11, 'activation_func_3': 'relu', 'num_neurons_3': 27}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:54:27,535]\u001b[0m Trial 147 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'sigmoid', 'num_neurons_0': 27, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 5, 'activation_func_2': 'tanh', 'num_neurons_2': 18, 'activation_func_3': 'tanh', 'num_neurons_3': 21, 'activation_func_4': 'relu', 'num_neurons_4': 9}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:54:31,563]\u001b[0m Trial 148 finished with value: 0.0 and parameters: {'num_layers': 1, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 24}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:54:35,679]\u001b[0m Trial 149 finished with value: 0.22092824113718101 and parameters: {'num_layers': 2, 'activation_func_0': 'tanh', 'num_neurons_0': 29, 'activation_func_1': 'sigmoid', 'num_neurons_1': 3}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:54:40,146]\u001b[0m Trial 150 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'relu', 'num_neurons_0': 10, 'activation_func_1': 'relu', 'num_neurons_1': 27, 'activation_func_2': 'sigmoid', 'num_neurons_2': 1, 'activation_func_3': 'sigmoid', 'num_neurons_3': 10, 'activation_func_4': 'leakyrelu', 'num_neurons_4': 13}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:54:44,244]\u001b[0m Trial 151 finished with value: 0.22092824113718101 and parameters: {'num_layers': 3, 'activation_func_0': 'relu', 'num_neurons_0': 15, 'activation_func_1': 'sigmoid', 'num_neurons_1': 9, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 10}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:54:48,342]\u001b[0m Trial 152 finished with value: 0.22092824113718101 and parameters: {'num_layers': 3, 'activation_func_0': 'relu', 'num_neurons_0': 18, 'activation_func_1': 'sigmoid', 'num_neurons_1': 6, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 6}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:54:52,413]\u001b[0m Trial 153 finished with value: 0.22092824113718101 and parameters: {'num_layers': 3, 'activation_func_0': 'relu', 'num_neurons_0': 19, 'activation_func_1': 'sigmoid', 'num_neurons_1': 7, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 3}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:54:56,496]\u001b[0m Trial 154 finished with value: 0.22092824113718101 and parameters: {'num_layers': 3, 'activation_func_0': 'relu', 'num_neurons_0': 12, 'activation_func_1': 'sigmoid', 'num_neurons_1': 8, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 7}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:55:00,717]\u001b[0m Trial 155 finished with value: 0.22092824113718101 and parameters: {'num_layers': 3, 'activation_func_0': 'sigmoid', 'num_neurons_0': 14, 'activation_func_1': 'tanh', 'num_neurons_1': 10, 'activation_func_2': 'relu', 'num_neurons_2': 28}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:55:04,716]\u001b[0m Trial 156 finished with value: 0.22092824113718101 and parameters: {'num_layers': 3, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 15, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 40, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 5}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:55:08,800]\u001b[0m Trial 157 finished with value: 0.22092824113718101 and parameters: {'num_layers': 4, 'activation_func_0': 'relu', 'num_neurons_0': 21, 'activation_func_1': 'sigmoid', 'num_neurons_1': 25, 'activation_func_2': 'sigmoid', 'num_neurons_2': 21, 'activation_func_3': 'sigmoid', 'num_neurons_3': 19}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:55:13,031]\u001b[0m Trial 158 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 17, 'activation_func_1': 'relu', 'num_neurons_1': 37, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 9, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 11, 'activation_func_4': 'sigmoid', 'num_neurons_4': 3}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:55:17,387]\u001b[0m Trial 159 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'sigmoid', 'num_neurons_0': 16, 'activation_func_1': 'sigmoid', 'num_neurons_1': 22, 'activation_func_2': 'tanh', 'num_neurons_2': 8, 'activation_func_3': 'relu', 'num_neurons_3': 29, 'activation_func_4': 'tanh', 'num_neurons_4': 26}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:55:21,500]\u001b[0m Trial 160 finished with value: 0.22092824113718101 and parameters: {'num_layers': 4, 'activation_func_0': 'tanh', 'num_neurons_0': 23, 'activation_func_1': 'tanh', 'num_neurons_1': 34, 'activation_func_2': 'relu', 'num_neurons_2': 14, 'activation_func_3': 'sigmoid', 'num_neurons_3': 17}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:55:25,679]\u001b[0m Trial 161 finished with value: 0.22092824113718101 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 30, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 24, 'activation_func_2': 'sigmoid', 'num_neurons_2': 19, 'activation_func_3': 'tanh', 'num_neurons_3': 6}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:55:29,838]\u001b[0m Trial 162 finished with value: 0.22092824113718101 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 29, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 23, 'activation_func_2': 'sigmoid', 'num_neurons_2': 16, 'activation_func_3': 'tanh', 'num_neurons_3': 12}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:55:33,977]\u001b[0m Trial 163 finished with value: 0.22092824113718101 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 28, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 20, 'activation_func_2': 'sigmoid', 'num_neurons_2': 22, 'activation_func_3': 'tanh', 'num_neurons_3': 9}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:55:38,002]\u001b[0m Trial 164 finished with value: 0.22092824113718101 and parameters: {'num_layers': 3, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 26, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 27, 'activation_func_2': 'sigmoid', 'num_neurons_2': 19}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:55:42,254]\u001b[0m Trial 165 finished with value: 0.22092824113718101 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 38, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 25, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 20, 'activation_func_3': 'tanh', 'num_neurons_3': 8}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:55:46,562]\u001b[0m Trial 166 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'relu', 'num_neurons_0': 33, 'activation_func_1': 'sigmoid', 'num_neurons_1': 39, 'activation_func_2': 'sigmoid', 'num_neurons_2': 13, 'activation_func_3': 'sigmoid', 'num_neurons_3': 4, 'activation_func_4': 'sigmoid', 'num_neurons_4': 7}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:55:50,719]\u001b[0m Trial 167 finished with value: 0.22092824113718101 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 31, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 19, 'activation_func_2': 'sigmoid', 'num_neurons_2': 17, 'activation_func_3': 'tanh', 'num_neurons_3': 13}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:55:55,039]\u001b[0m Trial 168 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'sigmoid', 'num_neurons_0': 11, 'activation_func_1': 'relu', 'num_neurons_1': 30, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 2, 'activation_func_3': 'sigmoid', 'num_neurons_3': 14, 'activation_func_4': 'leakyrelu', 'num_neurons_4': 15}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:55:59,269]\u001b[0m Trial 169 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'tanh', 'num_neurons_0': 22, 'activation_func_1': 'sigmoid', 'num_neurons_1': 5, 'activation_func_2': 'tanh', 'num_neurons_2': 4, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 8, 'activation_func_4': 'relu', 'num_neurons_4': 29}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:56:03,083]\u001b[0m Trial 170 finished with value: 0.22092824113718101 and parameters: {'num_layers': 1, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 1}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:56:07,117]\u001b[0m Trial 171 finished with value: 0.22092824113718101 and parameters: {'num_layers': 2, 'activation_func_0': 'sigmoid', 'num_neurons_0': 29, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 1}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:56:11,444]\u001b[0m Trial 172 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'sigmoid', 'num_neurons_0': 30, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 11, 'activation_func_2': 'relu', 'num_neurons_2': 12, 'activation_func_3': 'sigmoid', 'num_neurons_3': 19, 'activation_func_4': 'tanh', 'num_neurons_4': 36}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:56:15,751]\u001b[0m Trial 173 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'sigmoid', 'num_neurons_0': 29, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 2, 'activation_func_2': 'relu', 'num_neurons_2': 15, 'activation_func_3': 'sigmoid', 'num_neurons_3': 20, 'activation_func_4': 'tanh', 'num_neurons_4': 33}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:56:20,103]\u001b[0m Trial 174 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'sigmoid', 'num_neurons_0': 35, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 9, 'activation_func_2': 'relu', 'num_neurons_2': 10, 'activation_func_3': 'sigmoid', 'num_neurons_3': 35, 'activation_func_4': 'tanh', 'num_neurons_4': 37}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:56:24,361]\u001b[0m Trial 175 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'relu', 'num_neurons_0': 32, 'activation_func_1': 'tanh', 'num_neurons_1': 14, 'activation_func_2': 'relu', 'num_neurons_2': 12, 'activation_func_3': 'sigmoid', 'num_neurons_3': 16, 'activation_func_4': 'tanh', 'num_neurons_4': 2}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:56:28,539]\u001b[0m Trial 176 finished with value: 0.22092824113718101 and parameters: {'num_layers': 4, 'activation_func_0': 'sigmoid', 'num_neurons_0': 28, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 3, 'activation_func_2': 'relu', 'num_neurons_2': 31, 'activation_func_3': 'sigmoid', 'num_neurons_3': 2}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:56:32,909]\u001b[0m Trial 177 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 13, 'activation_func_1': 'sigmoid', 'num_neurons_1': 21, 'activation_func_2': 'sigmoid', 'num_neurons_2': 11, 'activation_func_3': 'relu', 'num_neurons_3': 38, 'activation_func_4': 'sigmoid', 'num_neurons_4': 5}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:56:37,072]\u001b[0m Trial 178 finished with value: 0.22092824113718101 and parameters: {'num_layers': 3, 'activation_func_0': 'tanh', 'num_neurons_0': 25, 'activation_func_1': 'relu', 'num_neurons_1': 6, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 36}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:56:41,291]\u001b[0m Trial 179 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'relu', 'num_neurons_0': 20, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 4, 'activation_func_2': 'sigmoid', 'num_neurons_2': 18, 'activation_func_3': 'sigmoid', 'num_neurons_3': 23, 'activation_func_4': 'tanh', 'num_neurons_4': 38}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:56:45,449]\u001b[0m Trial 180 finished with value: 0.22092824113718101 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 27, 'activation_func_1': 'sigmoid', 'num_neurons_1': 26, 'activation_func_2': 'tanh', 'num_neurons_2': 1, 'activation_func_3': 'sigmoid', 'num_neurons_3': 17}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:56:49,746]\u001b[0m Trial 181 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'sigmoid', 'num_neurons_0': 37, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 6, 'activation_func_2': 'relu', 'num_neurons_2': 7, 'activation_func_3': 'sigmoid', 'num_neurons_3': 7, 'activation_func_4': 'tanh', 'num_neurons_4': 29}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:56:54,260]\u001b[0m Trial 182 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'sigmoid', 'num_neurons_0': 39, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 37, 'activation_func_2': 'relu', 'num_neurons_2': 8, 'activation_func_3': 'sigmoid', 'num_neurons_3': 20, 'activation_func_4': 'tanh', 'num_neurons_4': 32}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:56:58,554]\u001b[0m Trial 183 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'sigmoid', 'num_neurons_0': 2, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 23, 'activation_func_2': 'relu', 'num_neurons_2': 23, 'activation_func_3': 'sigmoid', 'num_neurons_3': 18, 'activation_func_4': 'tanh', 'num_neurons_4': 35}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:57:02,771]\u001b[0m Trial 184 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'sigmoid', 'num_neurons_0': 40, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 5, 'activation_func_2': 'relu', 'num_neurons_2': 6, 'activation_func_3': 'sigmoid', 'num_neurons_3': 4, 'activation_func_4': 'sigmoid', 'num_neurons_4': 20}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:57:07,048]\u001b[0m Trial 185 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'sigmoid', 'num_neurons_0': 37, 'activation_func_1': 'tanh', 'num_neurons_1': 8, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 4, 'activation_func_3': 'tanh', 'num_neurons_3': 21, 'activation_func_4': 'tanh', 'num_neurons_4': 25}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:57:11,294]\u001b[0m Trial 186 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 38, 'activation_func_1': 'sigmoid', 'num_neurons_1': 32, 'activation_func_2': 'relu', 'num_neurons_2': 13, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 25, 'activation_func_4': 'sigmoid', 'num_neurons_4': 3}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:57:15,329]\u001b[0m Trial 187 finished with value: 0.22092824113718101 and parameters: {'num_layers': 3, 'activation_func_0': 'relu', 'num_neurons_0': 33, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 7, 'activation_func_2': 'sigmoid', 'num_neurons_2': 5}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:57:19,573]\u001b[0m Trial 188 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'tanh', 'num_neurons_0': 22, 'activation_func_1': 'sigmoid', 'num_neurons_1': 16, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 39, 'activation_func_3': 'relu', 'num_neurons_3': 10, 'activation_func_4': 'leakyrelu', 'num_neurons_4': 30}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:57:23,767]\u001b[0m Trial 189 finished with value: 0.22092824113718101 and parameters: {'num_layers': 4, 'activation_func_0': 'sigmoid', 'num_neurons_0': 3, 'activation_func_1': 'relu', 'num_neurons_1': 18, 'activation_func_2': 'sigmoid', 'num_neurons_2': 9, 'activation_func_3': 'sigmoid', 'num_neurons_3': 15}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:57:27,965]\u001b[0m Trial 190 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 31, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 2, 'activation_func_2': 'tanh', 'num_neurons_2': 8, 'activation_func_3': 'sigmoid', 'num_neurons_3': 33, 'activation_func_4': 'tanh', 'num_neurons_4': 10}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:57:32,211]\u001b[0m Trial 191 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'sigmoid', 'num_neurons_0': 26, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 5, 'activation_func_2': 'relu', 'num_neurons_2': 16, 'activation_func_3': 'sigmoid', 'num_neurons_3': 17, 'activation_func_4': 'tanh', 'num_neurons_4': 28}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:57:36,412]\u001b[0m Trial 192 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'sigmoid', 'num_neurons_0': 7, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 29, 'activation_func_2': 'relu', 'num_neurons_2': 17, 'activation_func_3': 'sigmoid', 'num_neurons_3': 19, 'activation_func_4': 'tanh', 'num_neurons_4': 23}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:57:40,693]\u001b[0m Trial 193 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'sigmoid', 'num_neurons_0': 12, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 7, 'activation_func_2': 'relu', 'num_neurons_2': 15, 'activation_func_3': 'sigmoid', 'num_neurons_3': 14, 'activation_func_4': 'tanh', 'num_neurons_4': 24}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:57:44,900]\u001b[0m Trial 194 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'sigmoid', 'num_neurons_0': 25, 'activation_func_1': 'tanh', 'num_neurons_1': 4, 'activation_func_2': 'relu', 'num_neurons_2': 17, 'activation_func_3': 'sigmoid', 'num_neurons_3': 16, 'activation_func_4': 'sigmoid', 'num_neurons_4': 33}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:57:48,998]\u001b[0m Trial 195 finished with value: 0.22092824113718101 and parameters: {'num_layers': 3, 'activation_func_0': 'relu', 'num_neurons_0': 24, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 10, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 12}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:57:52,844]\u001b[0m Trial 196 finished with value: 0.22092824113718101 and parameters: {'num_layers': 1, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 9}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:57:57,102]\u001b[0m Trial 197 finished with value: 0.22092824113718101 and parameters: {'num_layers': 4, 'activation_func_0': 'tanh', 'num_neurons_0': 18, 'activation_func_1': 'sigmoid', 'num_neurons_1': 38, 'activation_func_2': 'sigmoid', 'num_neurons_2': 14, 'activation_func_3': 'relu', 'num_neurons_3': 18}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:58:01,356]\u001b[0m Trial 198 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'sigmoid', 'num_neurons_0': 36, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 35, 'activation_func_2': 'relu', 'num_neurons_2': 10, 'activation_func_3': 'sigmoid', 'num_neurons_3': 1, 'activation_func_4': 'tanh', 'num_neurons_4': 16}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:58:05,703]\u001b[0m Trial 199 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 28, 'activation_func_1': 'sigmoid', 'num_neurons_1': 3, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 1, 'activation_func_3': 'tanh', 'num_neurons_3': 12, 'activation_func_4': 'relu', 'num_neurons_4': 31}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:58:09,974]\u001b[0m Trial 200 finished with value: 0.22092824113718101 and parameters: {'num_layers': 4, 'activation_func_0': 'relu', 'num_neurons_0': 27, 'activation_func_1': 'relu', 'num_neurons_1': 8, 'activation_func_2': 'sigmoid', 'num_neurons_2': 13, 'activation_func_3': 'sigmoid', 'num_neurons_3': 15}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:58:14,115]\u001b[0m Trial 201 finished with value: 0.22092824113718101 and parameters: {'num_layers': 4, 'activation_func_0': 'sigmoid', 'num_neurons_0': 23, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 35, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 2, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 26}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:58:18,213]\u001b[0m Trial 202 finished with value: 0.22092824113718101 and parameters: {'num_layers': 4, 'activation_func_0': 'sigmoid', 'num_neurons_0': 21, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 36, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 33, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 30}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:58:22,436]\u001b[0m Trial 203 finished with value: 0.22092824113718101 and parameters: {'num_layers': 4, 'activation_func_0': 'sigmoid', 'num_neurons_0': 23, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 34, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 1, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 28}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:58:26,641]\u001b[0m Trial 204 finished with value: 0.22092824113718101 and parameters: {'num_layers': 4, 'activation_func_0': 'sigmoid', 'num_neurons_0': 19, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 32, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 3, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 6}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:58:30,861]\u001b[0m Trial 205 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'sigmoid', 'num_neurons_0': 25, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 22, 'activation_func_2': 'tanh', 'num_neurons_2': 7, 'activation_func_3': 'sigmoid', 'num_neurons_3': 32, 'activation_func_4': 'sigmoid', 'num_neurons_4': 21}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:58:34,913]\u001b[0m Trial 206 finished with value: 0.22092824113718101 and parameters: {'num_layers': 3, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 14, 'activation_func_1': 'tanh', 'num_neurons_1': 33, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 2}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:58:39,026]\u001b[0m Trial 207 finished with value: 0.22092824113718101 and parameters: {'num_layers': 4, 'activation_func_0': 'tanh', 'num_neurons_0': 24, 'activation_func_1': 'sigmoid', 'num_neurons_1': 24, 'activation_func_2': 'sigmoid', 'num_neurons_2': 14, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 19}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:58:43,308]\u001b[0m Trial 208 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'relu', 'num_neurons_0': 26, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 12, 'activation_func_2': 'relu', 'num_neurons_2': 11, 'activation_func_3': 'relu', 'num_neurons_3': 13, 'activation_func_4': 'leakyrelu', 'num_neurons_4': 12}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:58:47,544]\u001b[0m Trial 209 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'sigmoid', 'num_neurons_0': 13, 'activation_func_1': 'sigmoid', 'num_neurons_1': 38, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 6, 'activation_func_3': 'tanh', 'num_neurons_3': 24, 'activation_func_4': 'tanh', 'num_neurons_4': 1}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:58:51,438]\u001b[0m Trial 210 finished with value: 0.0 and parameters: {'num_layers': 1, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 20}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:58:55,547]\u001b[0m Trial 211 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'sigmoid', 'num_neurons_0': 17, 'activation_func_1': 'tanh', 'num_neurons_1': 11, 'activation_func_2': 'relu', 'num_neurons_2': 25, 'activation_func_3': 'sigmoid', 'num_neurons_3': 7, 'activation_func_4': 'tanh', 'num_neurons_4': 15}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:58:59,806]\u001b[0m Trial 212 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'sigmoid', 'num_neurons_0': 2, 'activation_func_1': 'tanh', 'num_neurons_1': 9, 'activation_func_2': 'relu', 'num_neurons_2': 26, 'activation_func_3': 'sigmoid', 'num_neurons_3': 5, 'activation_func_4': 'tanh', 'num_neurons_4': 13}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:59:04,002]\u001b[0m Trial 213 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'sigmoid', 'num_neurons_0': 16, 'activation_func_1': 'tanh', 'num_neurons_1': 6, 'activation_func_2': 'relu', 'num_neurons_2': 24, 'activation_func_3': 'sigmoid', 'num_neurons_3': 3, 'activation_func_4': 'tanh', 'num_neurons_4': 5}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:59:08,242]\u001b[0m Trial 214 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'sigmoid', 'num_neurons_0': 15, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 13, 'activation_func_2': 'relu', 'num_neurons_2': 19, 'activation_func_3': 'sigmoid', 'num_neurons_3': 9, 'activation_func_4': 'sigmoid', 'num_neurons_4': 7}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:59:12,457]\u001b[0m Trial 215 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'sigmoid', 'num_neurons_0': 16, 'activation_func_1': 'tanh', 'num_neurons_1': 7, 'activation_func_2': 'sigmoid', 'num_neurons_2': 24, 'activation_func_3': 'sigmoid', 'num_neurons_3': 37, 'activation_func_4': 'tanh', 'num_neurons_4': 9}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:59:16,532]\u001b[0m Trial 216 finished with value: 0.22092824113718101 and parameters: {'num_layers': 3, 'activation_func_0': 'tanh', 'num_neurons_0': 18, 'activation_func_1': 'relu', 'num_neurons_1': 10, 'activation_func_2': 'tanh', 'num_neurons_2': 27}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:59:20,742]\u001b[0m Trial 217 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 21, 'activation_func_1': 'tanh', 'num_neurons_1': 36, 'activation_func_2': 'relu', 'num_neurons_2': 15, 'activation_func_3': 'sigmoid', 'num_neurons_3': 11, 'activation_func_4': 'relu', 'num_neurons_4': 26}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:59:24,902]\u001b[0m Trial 218 finished with value: 0.22092824113718101 and parameters: {'num_layers': 4, 'activation_func_0': 'relu', 'num_neurons_0': 17, 'activation_func_1': 'sigmoid', 'num_neurons_1': 28, 'activation_func_2': 'sigmoid', 'num_neurons_2': 21, 'activation_func_3': 'sigmoid', 'num_neurons_3': 20}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:59:29,073]\u001b[0m Trial 219 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 22, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 15, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 1, 'activation_func_3': 'relu', 'num_neurons_3': 8, 'activation_func_4': 'leakyrelu', 'num_neurons_4': 14}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:59:33,321]\u001b[0m Trial 220 finished with value: 0.22092824113718101 and parameters: {'num_layers': 4, 'activation_func_0': 'sigmoid', 'num_neurons_0': 30, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 40, 'activation_func_2': 'relu', 'num_neurons_2': 22, 'activation_func_3': 'tanh', 'num_neurons_3': 1}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:59:37,472]\u001b[0m Trial 221 finished with value: 0.22092824113718101 and parameters: {'num_layers': 4, 'activation_func_0': 'relu', 'num_neurons_0': 36, 'activation_func_1': 'sigmoid', 'num_neurons_1': 4, 'activation_func_2': 'tanh', 'num_neurons_2': 26, 'activation_func_3': 'sigmoid', 'num_neurons_3': 17}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:59:41,638]\u001b[0m Trial 222 finished with value: 0.22092824113718101 and parameters: {'num_layers': 4, 'activation_func_0': 'relu', 'num_neurons_0': 34, 'activation_func_1': 'sigmoid', 'num_neurons_1': 5, 'activation_func_2': 'tanh', 'num_neurons_2': 36, 'activation_func_3': 'sigmoid', 'num_neurons_3': 15}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:59:45,870]\u001b[0m Trial 223 finished with value: 0.22092824113718101 and parameters: {'num_layers': 4, 'activation_func_0': 'relu', 'num_neurons_0': 35, 'activation_func_1': 'sigmoid', 'num_neurons_1': 26, 'activation_func_2': 'tanh', 'num_neurons_2': 23, 'activation_func_3': 'sigmoid', 'num_neurons_3': 13}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:59:49,891]\u001b[0m Trial 224 finished with value: 0.22092824113718101 and parameters: {'num_layers': 2, 'activation_func_0': 'relu', 'num_neurons_0': 36, 'activation_func_1': 'sigmoid', 'num_neurons_1': 19}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:59:54,068]\u001b[0m Trial 225 finished with value: 0.22092824113718101 and parameters: {'num_layers': 4, 'activation_func_0': 'relu', 'num_neurons_0': 19, 'activation_func_1': 'sigmoid', 'num_neurons_1': 4, 'activation_func_2': 'tanh', 'num_neurons_2': 3, 'activation_func_3': 'sigmoid', 'num_neurons_3': 40}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 15:59:58,383]\u001b[0m Trial 226 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'tanh', 'num_neurons_0': 1, 'activation_func_1': 'relu', 'num_neurons_1': 5, 'activation_func_2': 'sigmoid', 'num_neurons_2': 35, 'activation_func_3': 'sigmoid', 'num_neurons_3': 16, 'activation_func_4': 'sigmoid', 'num_neurons_4': 11}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:00:02,596]\u001b[0m Trial 227 finished with value: 0.22092824113718101 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 38, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 3, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 2, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 6}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:00:06,729]\u001b[0m Trial 228 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'sigmoid', 'num_neurons_0': 15, 'activation_func_1': 'sigmoid', 'num_neurons_1': 34, 'activation_func_2': 'sigmoid', 'num_neurons_2': 31, 'activation_func_3': 'sigmoid', 'num_neurons_3': 22, 'activation_func_4': 'tanh', 'num_neurons_4': 18}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:00:11,045]\u001b[0m Trial 229 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'relu', 'num_neurons_0': 34, 'activation_func_1': 'tanh', 'num_neurons_1': 17, 'activation_func_2': 'tanh', 'num_neurons_2': 29, 'activation_func_3': 'sigmoid', 'num_neurons_3': 21, 'activation_func_4': 'tanh', 'num_neurons_4': 4}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:00:15,211]\u001b[0m Trial 230 finished with value: 0.22092824113718101 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 32, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 7, 'activation_func_2': 'relu', 'num_neurons_2': 12, 'activation_func_3': 'relu', 'num_neurons_3': 18}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:00:19,606]\u001b[0m Trial 231 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'tanh', 'num_neurons_0': 23, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 1, 'activation_func_2': 'sigmoid', 'num_neurons_2': 11, 'activation_func_3': 'sigmoid', 'num_neurons_3': 2, 'activation_func_4': 'sigmoid', 'num_neurons_4': 17}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:00:23,825]\u001b[0m Trial 232 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'tanh', 'num_neurons_0': 22, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 31, 'activation_func_2': 'sigmoid', 'num_neurons_2': 10, 'activation_func_3': 'sigmoid', 'num_neurons_3': 14, 'activation_func_4': 'sigmoid', 'num_neurons_4': 22}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:00:28,085]\u001b[0m Trial 233 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'tanh', 'num_neurons_0': 39, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 16, 'activation_func_2': 'sigmoid', 'num_neurons_2': 9, 'activation_func_3': 'sigmoid', 'num_neurons_3': 25, 'activation_func_4': 'sigmoid', 'num_neurons_4': 19}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:00:32,107]\u001b[0m Trial 234 finished with value: 0.22092824113718101 and parameters: {'num_layers': 3, 'activation_func_0': 'tanh', 'num_neurons_0': 29, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 6, 'activation_func_2': 'sigmoid', 'num_neurons_2': 8}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:00:36,440]\u001b[0m Trial 235 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'sigmoid', 'num_neurons_0': 20, 'activation_func_1': 'sigmoid', 'num_neurons_1': 37, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 7, 'activation_func_3': 'sigmoid', 'num_neurons_3': 23, 'activation_func_4': 'sigmoid', 'num_neurons_4': 27}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:00:40,758]\u001b[0m Trial 236 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'tanh', 'num_neurons_0': 27, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 21, 'activation_func_2': 'sigmoid', 'num_neurons_2': 12, 'activation_func_3': 'tanh', 'num_neurons_3': 27, 'activation_func_4': 'relu', 'num_neurons_4': 6}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:00:45,107]\u001b[0m Trial 237 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 23, 'activation_func_1': 'sigmoid', 'num_neurons_1': 14, 'activation_func_2': 'relu', 'num_neurons_2': 14, 'activation_func_3': 'sigmoid', 'num_neurons_3': 26, 'activation_func_4': 'sigmoid', 'num_neurons_4': 2}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:00:49,152]\u001b[0m Trial 238 finished with value: 0.22092824113718101 and parameters: {'num_layers': 3, 'activation_func_0': 'sigmoid', 'num_neurons_0': 24, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 17, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 13}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:00:53,473]\u001b[0m Trial 239 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'relu', 'num_neurons_0': 5, 'activation_func_1': 'relu', 'num_neurons_1': 9, 'activation_func_2': 'sigmoid', 'num_neurons_2': 38, 'activation_func_3': 'sigmoid', 'num_neurons_3': 12, 'activation_func_4': 'tanh', 'num_neurons_4': 11}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:00:57,438]\u001b[0m Trial 240 finished with value: 0.22092824113718101 and parameters: {'num_layers': 1, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 21}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:01:02,017]\u001b[0m Trial 241 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 31, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 12, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 5, 'activation_func_3': 'tanh', 'num_neurons_3': 6, 'activation_func_4': 'tanh', 'num_neurons_4': 38}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:01:06,406]\u001b[0m Trial 242 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 29, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 11, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 6, 'activation_func_3': 'tanh', 'num_neurons_3': 7, 'activation_func_4': 'tanh', 'num_neurons_4': 35}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:01:10,628]\u001b[0m Trial 243 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 28, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 6, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 4, 'activation_func_3': 'tanh', 'num_neurons_3': 19, 'activation_func_4': 'tanh', 'num_neurons_4': 40}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:01:14,962]\u001b[0m Trial 244 finished with value: 0.22092824113718101 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 14, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 11, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 1, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 5}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:01:19,291]\u001b[0m Trial 245 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'sigmoid', 'num_neurons_0': 27, 'activation_func_1': 'tanh', 'num_neurons_1': 10, 'activation_func_2': 'relu', 'num_neurons_2': 8, 'activation_func_3': 'tanh', 'num_neurons_3': 8, 'activation_func_4': 'leakyrelu', 'num_neurons_4': 34}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:01:23,713]\u001b[0m Trial 246 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'tanh', 'num_neurons_0': 37, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 18, 'activation_func_2': 'tanh', 'num_neurons_2': 2, 'activation_func_3': 'sigmoid', 'num_neurons_3': 17, 'activation_func_4': 'tanh', 'num_neurons_4': 16}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:01:28,371]\u001b[0m Trial 247 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 30, 'activation_func_1': 'sigmoid', 'num_neurons_1': 39, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 3, 'activation_func_3': 'relu', 'num_neurons_3': 16, 'activation_func_4': 'sigmoid', 'num_neurons_4': 3}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:01:32,620]\u001b[0m Trial 248 finished with value: 0.22092824113718101 and parameters: {'num_layers': 4, 'activation_func_0': 'relu', 'num_neurons_0': 11, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 25, 'activation_func_2': 'sigmoid', 'num_neurons_2': 25, 'activation_func_3': 'sigmoid', 'num_neurons_3': 4}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:01:36,944]\u001b[0m Trial 249 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'sigmoid', 'num_neurons_0': 12, 'activation_func_1': 'sigmoid', 'num_neurons_1': 8, 'activation_func_2': 'relu', 'num_neurons_2': 16, 'activation_func_3': 'sigmoid', 'num_neurons_3': 20, 'activation_func_4': 'tanh', 'num_neurons_4': 37}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:01:41,485]\u001b[0m Trial 250 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 10, 'activation_func_1': 'tanh', 'num_neurons_1': 23, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 7, 'activation_func_3': 'tanh', 'num_neurons_3': 34, 'activation_func_4': 'relu', 'num_neurons_4': 13}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:01:45,737]\u001b[0m Trial 251 finished with value: 0.22092824113718101 and parameters: {'num_layers': 4, 'activation_func_0': 'sigmoid', 'num_neurons_0': 14, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 15, 'activation_func_2': 'sigmoid', 'num_neurons_2': 32, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 29}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:01:49,965]\u001b[0m Trial 252 finished with value: 0.22092824113718101 and parameters: {'num_layers': 3, 'activation_func_0': 'tanh', 'num_neurons_0': 26, 'activation_func_1': 'relu', 'num_neurons_1': 13, 'activation_func_2': 'tanh', 'num_neurons_2': 27}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:01:54,114]\u001b[0m Trial 253 finished with value: 0.0 and parameters: {'num_layers': 1, 'activation_func_0': 'relu', 'num_neurons_0': 22}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:01:58,061]\u001b[0m Trial 254 finished with value: 0.22092824113718101 and parameters: {'num_layers': 2, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 21, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 9}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:02:02,397]\u001b[0m Trial 255 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'sigmoid', 'num_neurons_0': 18, 'activation_func_1': 'sigmoid', 'num_neurons_1': 2, 'activation_func_2': 'relu', 'num_neurons_2': 1, 'activation_func_3': 'sigmoid', 'num_neurons_3': 9, 'activation_func_4': 'tanh', 'num_neurons_4': 24}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:02:06,634]\u001b[0m Trial 256 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 19, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 36, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 10, 'activation_func_3': 'sigmoid', 'num_neurons_3': 23, 'activation_func_4': 'sigmoid', 'num_neurons_4': 8}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:02:10,868]\u001b[0m Trial 257 finished with value: 0.22092824113718101 and parameters: {'num_layers': 4, 'activation_func_0': 'relu', 'num_neurons_0': 35, 'activation_func_1': 'tanh', 'num_neurons_1': 5, 'activation_func_2': 'sigmoid', 'num_neurons_2': 18, 'activation_func_3': 'relu', 'num_neurons_3': 15}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:02:15,005]\u001b[0m Trial 258 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'sigmoid', 'num_neurons_0': 7, 'activation_func_1': 'sigmoid', 'num_neurons_1': 30, 'activation_func_2': 'relu', 'num_neurons_2': 4, 'activation_func_3': 'sigmoid', 'num_neurons_3': 5, 'activation_func_4': 'tanh', 'num_neurons_4': 31}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:02:19,280]\u001b[0m Trial 259 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'tanh', 'num_neurons_0': 28, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 6, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 6, 'activation_func_3': 'sigmoid', 'num_neurons_3': 7, 'activation_func_4': 'leakyrelu', 'num_neurons_4': 32}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:02:23,297]\u001b[0m Trial 260 finished with value: 0.22092824113718101 and parameters: {'num_layers': 3, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 17, 'activation_func_1': 'sigmoid', 'num_neurons_1': 4, 'activation_func_2': 'sigmoid', 'num_neurons_2': 11}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:02:27,608]\u001b[0m Trial 261 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'sigmoid', 'num_neurons_0': 31, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 10, 'activation_func_2': 'tanh', 'num_neurons_2': 20, 'activation_func_3': 'tanh', 'num_neurons_3': 14, 'activation_func_4': 'tanh', 'num_neurons_4': 2}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:02:31,956]\u001b[0m Trial 262 finished with value: 0.22092824113718101 and parameters: {'num_layers': 4, 'activation_func_0': 'relu', 'num_neurons_0': 16, 'activation_func_1': 'relu', 'num_neurons_1': 20, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 13, 'activation_func_3': 'sigmoid', 'num_neurons_3': 18}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:02:36,383]\u001b[0m Trial 263 finished with value: 0.22092824113718101 and parameters: {'num_layers': 4, 'activation_func_0': 'sigmoid', 'num_neurons_0': 25, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 28, 'activation_func_2': 'relu', 'num_neurons_2': 24, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 11}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:02:41,122]\u001b[0m Trial 264 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 24, 'activation_func_1': 'tanh', 'num_neurons_1': 29, 'activation_func_2': 'sigmoid', 'num_neurons_2': 2, 'activation_func_3': 'sigmoid', 'num_neurons_3': 10, 'activation_func_4': 'sigmoid', 'num_neurons_4': 29}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:02:45,830]\u001b[0m Trial 265 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'tanh', 'num_neurons_0': 29, 'activation_func_1': 'sigmoid', 'num_neurons_1': 33, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 10, 'activation_func_3': 'sigmoid', 'num_neurons_3': 39, 'activation_func_4': 'tanh', 'num_neurons_4': 19}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:02:50,040]\u001b[0m Trial 266 finished with value: 0.22092824113718101 and parameters: {'num_layers': 3, 'activation_func_0': 'relu', 'num_neurons_0': 22, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 13, 'activation_func_2': 'relu', 'num_neurons_2': 15}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:02:54,484]\u001b[0m Trial 267 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'sigmoid', 'num_neurons_0': 33, 'activation_func_1': 'sigmoid', 'num_neurons_1': 7, 'activation_func_2': 'tanh', 'num_neurons_2': 29, 'activation_func_3': 'relu', 'num_neurons_3': 1, 'activation_func_4': 'relu', 'num_neurons_4': 22}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:02:58,988]\u001b[0m Trial 268 finished with value: 0.22092824113718101 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 20, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 35, 'activation_func_2': 'sigmoid', 'num_neurons_2': 9, 'activation_func_3': 'tanh', 'num_neurons_3': 21}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:03:03,479]\u001b[0m Trial 269 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'tanh', 'num_neurons_0': 32, 'activation_func_1': 'relu', 'num_neurons_1': 37, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 5, 'activation_func_3': 'sigmoid', 'num_neurons_3': 8, 'activation_func_4': 'sigmoid', 'num_neurons_4': 39}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:03:07,347]\u001b[0m Trial 270 finished with value: 0.22092824113718101 and parameters: {'num_layers': 1, 'activation_func_0': 'sigmoid', 'num_neurons_0': 26}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:03:11,742]\u001b[0m Trial 271 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 2, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 8, 'activation_func_2': 'relu', 'num_neurons_2': 8, 'activation_func_3': 'sigmoid', 'num_neurons_3': 3, 'activation_func_4': 'tanh', 'num_neurons_4': 36}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:03:16,178]\u001b[0m Trial 272 finished with value: 0.22092824113718101 and parameters: {'num_layers': 4, 'activation_func_0': 'relu', 'num_neurons_0': 23, 'activation_func_1': 'tanh', 'num_neurons_1': 22, 'activation_func_2': 'sigmoid', 'num_neurons_2': 34, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 19}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:03:20,512]\u001b[0m Trial 273 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'sigmoid', 'num_neurons_0': 13, 'activation_func_1': 'sigmoid', 'num_neurons_1': 27, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 3, 'activation_func_3': 'sigmoid', 'num_neurons_3': 24, 'activation_func_4': 'leakyrelu', 'num_neurons_4': 28}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:03:24,682]\u001b[0m Trial 274 finished with value: 0.22092824113718101 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 28, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 16, 'activation_func_2': 'relu', 'num_neurons_2': 12, 'activation_func_3': 'sigmoid', 'num_neurons_3': 26}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:03:28,897]\u001b[0m Trial 275 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'tanh', 'num_neurons_0': 8, 'activation_func_1': 'sigmoid', 'num_neurons_1': 14, 'activation_func_2': 'tanh', 'num_neurons_2': 40, 'activation_func_3': 'relu', 'num_neurons_3': 2, 'activation_func_4': 'tanh', 'num_neurons_4': 14}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:03:33,048]\u001b[0m Trial 276 finished with value: 0.22092824113718101 and parameters: {'num_layers': 3, 'activation_func_0': 'relu', 'num_neurons_0': 15, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 34, 'activation_func_2': 'sigmoid', 'num_neurons_2': 6}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:03:37,335]\u001b[0m Trial 277 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'sigmoid', 'num_neurons_0': 30, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 19, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 23, 'activation_func_3': 'tanh', 'num_neurons_3': 10, 'activation_func_4': 'sigmoid', 'num_neurons_4': 4}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:03:41,718]\u001b[0m Trial 278 finished with value: 0.22092824113718101 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 27, 'activation_func_1': 'tanh', 'num_neurons_1': 24, 'activation_func_2': 'sigmoid', 'num_neurons_2': 1, 'activation_func_3': 'sigmoid', 'num_neurons_3': 13}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:03:45,996]\u001b[0m Trial 279 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'sigmoid', 'num_neurons_0': 1, 'activation_func_1': 'sigmoid', 'num_neurons_1': 5, 'activation_func_2': 'relu', 'num_neurons_2': 28, 'activation_func_3': 'sigmoid', 'num_neurons_3': 6, 'activation_func_4': 'tanh', 'num_neurons_4': 11}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:03:50,026]\u001b[0m Trial 280 finished with value: 0.22092824113718101 and parameters: {'num_layers': 2, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 25, 'activation_func_1': 'relu', 'num_neurons_1': 3}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:03:54,376]\u001b[0m Trial 281 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'relu', 'num_neurons_0': 4, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 12, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 2, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 16, 'activation_func_4': 'relu', 'num_neurons_4': 1}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:03:58,764]\u001b[0m Trial 282 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'tanh', 'num_neurons_0': 37, 'activation_func_1': 'sigmoid', 'num_neurons_1': 7, 'activation_func_2': 'tanh', 'num_neurons_2': 7, 'activation_func_3': 'sigmoid', 'num_neurons_3': 20, 'activation_func_4': 'sigmoid', 'num_neurons_4': 25}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:04:03,095]\u001b[0m Trial 283 finished with value: 0.22092824113718101 and parameters: {'num_layers': 4, 'activation_func_0': 'sigmoid', 'num_neurons_0': 18, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 31, 'activation_func_2': 'sigmoid', 'num_neurons_2': 17, 'activation_func_3': 'sigmoid', 'num_neurons_3': 18}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:04:07,335]\u001b[0m Trial 284 finished with value: 0.22092824113718101 and parameters: {'num_layers': 3, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 16, 'activation_func_1': 'tanh', 'num_neurons_1': 9, 'activation_func_2': 'relu', 'num_neurons_2': 13}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:04:11,673]\u001b[0m Trial 285 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'relu', 'num_neurons_0': 13, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 11, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 11, 'activation_func_3': 'tanh', 'num_neurons_3': 22, 'activation_func_4': 'tanh', 'num_neurons_4': 12}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:04:15,696]\u001b[0m Trial 286 finished with value: 0.22092824113718101 and parameters: {'num_layers': 1, 'activation_func_0': 'sigmoid', 'num_neurons_0': 21}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:04:20,189]\u001b[0m Trial 287 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 11, 'activation_func_1': 'sigmoid', 'num_neurons_1': 4, 'activation_func_2': 'sigmoid', 'num_neurons_2': 26, 'activation_func_3': 'sigmoid', 'num_neurons_3': 25, 'activation_func_4': 'tanh', 'num_neurons_4': 10}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:04:24,474]\u001b[0m Trial 288 finished with value: 0.22092824113718101 and parameters: {'num_layers': 4, 'activation_func_0': 'tanh', 'num_neurons_0': 34, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 10, 'activation_func_2': 'relu', 'num_neurons_2': 19, 'activation_func_3': 'relu', 'num_neurons_3': 28}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:04:28,870]\u001b[0m Trial 289 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'sigmoid', 'num_neurons_0': 29, 'activation_func_1': 'relu', 'num_neurons_1': 6, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 9, 'activation_func_3': 'sigmoid', 'num_neurons_3': 17, 'activation_func_4': 'leakyrelu', 'num_neurons_4': 35}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:04:33,060]\u001b[0m Trial 290 finished with value: 0.22092824113718101 and parameters: {'num_layers': 3, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 22, 'activation_func_1': 'sigmoid', 'num_neurons_1': 32, 'activation_func_2': 'tanh', 'num_neurons_2': 8}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:04:37,448]\u001b[0m Trial 291 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'relu', 'num_neurons_0': 20, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 38, 'activation_func_2': 'sigmoid', 'num_neurons_2': 21, 'activation_func_3': 'sigmoid', 'num_neurons_3': 12, 'activation_func_4': 'sigmoid', 'num_neurons_4': 6}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:04:41,770]\u001b[0m Trial 292 finished with value: 0.22092824113718101 and parameters: {'num_layers': 4, 'activation_func_0': 'tanh', 'num_neurons_0': 24, 'activation_func_1': 'tanh', 'num_neurons_1': 15, 'activation_func_2': 'relu', 'num_neurons_2': 14, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 31}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:04:46,241]\u001b[0m Trial 293 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'sigmoid', 'num_neurons_0': 23, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 39, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 4, 'activation_func_3': 'tanh', 'num_neurons_3': 15, 'activation_func_4': 'tanh', 'num_neurons_4': 20}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:04:50,689]\u001b[0m Trial 294 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 30, 'activation_func_1': 'sigmoid', 'num_neurons_1': 8, 'activation_func_2': 'sigmoid', 'num_neurons_2': 25, 'activation_func_3': 'sigmoid', 'num_neurons_3': 19, 'activation_func_4': 'sigmoid', 'num_neurons_4': 15}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:04:54,940]\u001b[0m Trial 295 finished with value: 0.22092824113718101 and parameters: {'num_layers': 4, 'activation_func_0': 'relu', 'num_neurons_0': 15, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 36, 'activation_func_2': 'relu', 'num_neurons_2': 3, 'activation_func_3': 'sigmoid', 'num_neurons_3': 4}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:04:59,014]\u001b[0m Trial 296 finished with value: 0.22092824113718101 and parameters: {'num_layers': 2, 'activation_func_0': 'sigmoid', 'num_neurons_0': 17, 'activation_func_1': 'sigmoid', 'num_neurons_1': 21}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:05:03,503]\u001b[0m Trial 297 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 19, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 5, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 6, 'activation_func_3': 'relu', 'num_neurons_3': 14, 'activation_func_4': 'tanh', 'num_neurons_4': 13}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:05:07,838]\u001b[0m Trial 298 finished with value: 0.22092824113718101 and parameters: {'num_layers': 4, 'activation_func_0': 'tanh', 'num_neurons_0': 14, 'activation_func_1': 'relu', 'num_neurons_1': 2, 'activation_func_2': 'tanh', 'num_neurons_2': 1, 'activation_func_3': 'sigmoid', 'num_neurons_3': 8}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:05:11,898]\u001b[0m Trial 299 finished with value: 0.22092824113718101 and parameters: {'num_layers': 3, 'activation_func_0': 'sigmoid', 'num_neurons_0': 36, 'activation_func_1': 'tanh', 'num_neurons_1': 16, 'activation_func_2': 'sigmoid', 'num_neurons_2': 20}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:05:15,811]\u001b[0m Trial 300 finished with value: 0.22092824113718101 and parameters: {'num_layers': 1, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 39}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:05:20,070]\u001b[0m Trial 301 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'relu', 'num_neurons_0': 26, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 1, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 16, 'activation_func_3': 'tanh', 'num_neurons_3': 23, 'activation_func_4': 'relu', 'num_neurons_4': 34}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:05:24,483]\u001b[0m Trial 302 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'sigmoid', 'num_neurons_0': 12, 'activation_func_1': 'sigmoid', 'num_neurons_1': 26, 'activation_func_2': 'relu', 'num_neurons_2': 37, 'activation_func_3': 'sigmoid', 'num_neurons_3': 2, 'activation_func_4': 'tanh', 'num_neurons_4': 33}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:05:28,613]\u001b[0m Trial 303 finished with value: 0.22092824113718101 and parameters: {'num_layers': 3, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 21, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 18, 'activation_func_2': 'sigmoid', 'num_neurons_2': 18}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:05:32,809]\u001b[0m Trial 304 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'tanh', 'num_neurons_0': 31, 'activation_func_1': 'sigmoid', 'num_neurons_1': 35, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 5, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 6, 'activation_func_4': 'sigmoid', 'num_neurons_4': 9}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:05:36,980]\u001b[0m Trial 305 finished with value: 0.22092824113718101 and parameters: {'num_layers': 4, 'activation_func_0': 'relu', 'num_neurons_0': 28, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 38, 'activation_func_2': 'tanh', 'num_neurons_2': 12, 'activation_func_3': 'sigmoid', 'num_neurons_3': 18}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:05:41,416]\u001b[0m Trial 306 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'sigmoid', 'num_neurons_0': 9, 'activation_func_1': 'tanh', 'num_neurons_1': 8, 'activation_func_2': 'relu', 'num_neurons_2': 30, 'activation_func_3': 'sigmoid', 'num_neurons_3': 9, 'activation_func_4': 'tanh', 'num_neurons_4': 30}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:05:45,687]\u001b[0m Trial 307 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 27, 'activation_func_1': 'relu', 'num_neurons_1': 40, 'activation_func_2': 'sigmoid', 'num_neurons_2': 11, 'activation_func_3': 'relu', 'num_neurons_3': 7, 'activation_func_4': 'leakyrelu', 'num_neurons_4': 17}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:05:49,946]\u001b[0m Trial 308 finished with value: 0.22092824113718101 and parameters: {'num_layers': 4, 'activation_func_0': 'sigmoid', 'num_neurons_0': 38, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 17, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 9, 'activation_func_3': 'sigmoid', 'num_neurons_3': 21}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:05:54,500]\u001b[0m Trial 309 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 24, 'activation_func_1': 'sigmoid', 'num_neurons_1': 3, 'activation_func_2': 'relu', 'num_neurons_2': 7, 'activation_func_3': 'tanh', 'num_neurons_3': 16, 'activation_func_4': 'tanh', 'num_neurons_4': 3}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:05:58,699]\u001b[0m Trial 310 finished with value: 0.22092824113718101 and parameters: {'num_layers': 4, 'activation_func_0': 'tanh', 'num_neurons_0': 18, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 23, 'activation_func_2': 'sigmoid', 'num_neurons_2': 2, 'activation_func_3': 'sigmoid', 'num_neurons_3': 20}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:06:03,225]\u001b[0m Trial 311 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'relu', 'num_neurons_0': 35, 'activation_func_1': 'sigmoid', 'num_neurons_1': 6, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 14, 'activation_func_3': 'sigmoid', 'num_neurons_3': 14, 'activation_func_4': 'sigmoid', 'num_neurons_4': 22}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:06:07,677]\u001b[0m Trial 312 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'sigmoid', 'num_neurons_0': 1, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 4, 'activation_func_2': 'tanh', 'num_neurons_2': 5, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 36, 'activation_func_4': 'tanh', 'num_neurons_4': 5}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:06:11,752]\u001b[0m Trial 313 finished with value: 0.22092824113718101 and parameters: {'num_layers': 3, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 22, 'activation_func_1': 'tanh', 'num_neurons_1': 34, 'activation_func_2': 'sigmoid', 'num_neurons_2': 22}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:06:16,204]\u001b[0m Trial 314 finished with value: 0.22092824113718101 and parameters: {'num_layers': 4, 'activation_func_0': 'relu', 'num_neurons_0': 28, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 29, 'activation_func_2': 'relu', 'num_neurons_2': 1, 'activation_func_3': 'sigmoid', 'num_neurons_3': 11}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:06:20,510]\u001b[0m Trial 315 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'tanh', 'num_neurons_0': 6, 'activation_func_1': 'sigmoid', 'num_neurons_1': 10, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 2, 'activation_func_3': 'tanh', 'num_neurons_3': 17, 'activation_func_4': 'relu', 'num_neurons_4': 38}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:06:25,080]\u001b[0m Trial 316 finished with value: 0.22092824113718101 and parameters: {'num_layers': 4, 'activation_func_0': 'sigmoid', 'num_neurons_0': 25, 'activation_func_1': 'relu', 'num_neurons_1': 27, 'activation_func_2': 'sigmoid', 'num_neurons_2': 13, 'activation_func_3': 'sigmoid', 'num_neurons_3': 28}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:06:29,363]\u001b[0m Trial 317 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 23, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 25, 'activation_func_2': 'relu', 'num_neurons_2': 15, 'activation_func_3': 'relu', 'num_neurons_3': 5, 'activation_func_4': 'sigmoid', 'num_neurons_4': 4}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:06:33,290]\u001b[0m Trial 318 finished with value: 0.22092824113718101 and parameters: {'num_layers': 1, 'activation_func_0': 'sigmoid', 'num_neurons_0': 3}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:06:37,711]\u001b[0m Trial 319 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 16, 'activation_func_1': 'sigmoid', 'num_neurons_1': 5, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 7, 'activation_func_3': 'sigmoid', 'num_neurons_3': 29, 'activation_func_4': 'tanh', 'num_neurons_4': 32}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:06:42,043]\u001b[0m Trial 320 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'relu', 'num_neurons_0': 10, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 12, 'activation_func_2': 'tanh', 'num_neurons_2': 12, 'activation_func_3': 'sigmoid', 'num_neurons_3': 8, 'activation_func_4': 'leakyrelu', 'num_neurons_4': 16}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:06:46,183]\u001b[0m Trial 321 finished with value: 0.22092824113718101 and parameters: {'num_layers': 3, 'activation_func_0': 'tanh', 'num_neurons_0': 20, 'activation_func_1': 'tanh', 'num_neurons_1': 9, 'activation_func_2': 'sigmoid', 'num_neurons_2': 10}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:06:50,562]\u001b[0m Trial 322 finished with value: 0.22092824113718101 and parameters: {'num_layers': 4, 'activation_func_0': 'sigmoid', 'num_neurons_0': 29, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 14, 'activation_func_2': 'relu', 'num_neurons_2': 5, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 13}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:06:55,172]\u001b[0m Trial 323 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 40, 'activation_func_1': 'sigmoid', 'num_neurons_1': 20, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 39, 'activation_func_3': 'tanh', 'num_neurons_3': 3, 'activation_func_4': 'tanh', 'num_neurons_4': 37}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:06:59,757]\u001b[0m Trial 324 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'relu', 'num_neurons_0': 13, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 33, 'activation_func_2': 'sigmoid', 'num_neurons_2': 3, 'activation_func_3': 'sigmoid', 'num_neurons_3': 22, 'activation_func_4': 'sigmoid', 'num_neurons_4': 8}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:07:04,019]\u001b[0m Trial 325 finished with value: 0.22092824113718101 and parameters: {'num_layers': 4, 'activation_func_0': 'sigmoid', 'num_neurons_0': 15, 'activation_func_1': 'relu', 'num_neurons_1': 7, 'activation_func_2': 'relu', 'num_neurons_2': 1, 'activation_func_3': 'sigmoid', 'num_neurons_3': 1}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:07:08,086]\u001b[0m Trial 326 finished with value: 0.22092824113718101 and parameters: {'num_layers': 3, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 30, 'activation_func_1': 'sigmoid', 'num_neurons_1': 35, 'activation_func_2': 'tanh', 'num_neurons_2': 24}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:07:12,404]\u001b[0m Trial 327 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'tanh', 'num_neurons_0': 11, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 32, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 8, 'activation_func_3': 'relu', 'num_neurons_3': 19, 'activation_func_4': 'tanh', 'num_neurons_4': 12}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:07:16,981]\u001b[0m Trial 328 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'sigmoid', 'num_neurons_0': 21, 'activation_func_1': 'tanh', 'num_neurons_1': 37, 'activation_func_2': 'sigmoid', 'num_neurons_2': 23, 'activation_func_3': 'sigmoid', 'num_neurons_3': 15, 'activation_func_4': 'sigmoid', 'num_neurons_4': 1}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:07:21,434]\u001b[0m Trial 329 finished with value: 0.22092824113718101 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 19, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 11, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 19, 'activation_func_3': 'sigmoid', 'num_neurons_3': 27}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:07:25,899]\u001b[0m Trial 330 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'relu', 'num_neurons_0': 26, 'activation_func_1': 'sigmoid', 'num_neurons_1': 13, 'activation_func_2': 'relu', 'num_neurons_2': 4, 'activation_func_3': 'tanh', 'num_neurons_3': 9, 'activation_func_4': 'relu', 'num_neurons_4': 18}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:07:30,416]\u001b[0m Trial 331 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'sigmoid', 'num_neurons_0': 33, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 15, 'activation_func_2': 'sigmoid', 'num_neurons_2': 32, 'activation_func_3': 'sigmoid', 'num_neurons_3': 31, 'activation_func_4': 'tanh', 'num_neurons_4': 28}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:07:34,722]\u001b[0m Trial 332 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 14, 'activation_func_1': 'sigmoid', 'num_neurons_1': 6, 'activation_func_2': 'tanh', 'num_neurons_2': 6, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 18, 'activation_func_4': 'tanh', 'num_neurons_4': 26}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:07:38,944]\u001b[0m Trial 333 finished with value: 0.22092824113718101 and parameters: {'num_layers': 4, 'activation_func_0': 'tanh', 'num_neurons_0': 17, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 30, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 17, 'activation_func_3': 'sigmoid', 'num_neurons_3': 7}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:07:43,195]\u001b[0m Trial 334 finished with value: 0.22092824113718101 and parameters: {'num_layers': 4, 'activation_func_0': 'relu', 'num_neurons_0': 23, 'activation_func_1': 'tanh', 'num_neurons_1': 4, 'activation_func_2': 'relu', 'num_neurons_2': 11, 'activation_func_3': 'sigmoid', 'num_neurons_3': 3}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:07:47,272]\u001b[0m Trial 335 finished with value: 0.22092824113718101 and parameters: {'num_layers': 2, 'activation_func_0': 'sigmoid', 'num_neurons_0': 12, 'activation_func_1': 'relu', 'num_neurons_1': 7}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:07:51,258]\u001b[0m Trial 336 finished with value: 0.22092824113718101 and parameters: {'num_layers': 3, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 36, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 9, 'activation_func_2': 'sigmoid', 'num_neurons_2': 9}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:07:55,573]\u001b[0m Trial 337 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'sigmoid', 'num_neurons_0': 25, 'activation_func_1': 'sigmoid', 'num_neurons_1': 22, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 34, 'activation_func_3': 'relu', 'num_neurons_3': 25, 'activation_func_4': 'sigmoid', 'num_neurons_4': 23}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:07:59,422]\u001b[0m Trial 338 finished with value: 0.22092824113718101 and parameters: {'num_layers': 1, 'activation_func_0': 'tanh', 'num_neurons_0': 22}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:08:03,884]\u001b[0m Trial 339 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 2, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 19, 'activation_func_2': 'relu', 'num_neurons_2': 13, 'activation_func_3': 'tanh', 'num_neurons_3': 16, 'activation_func_4': 'leakyrelu', 'num_neurons_4': 39}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:08:08,407]\u001b[0m Trial 340 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'relu', 'num_neurons_0': 29, 'activation_func_1': 'sigmoid', 'num_neurons_1': 24, 'activation_func_2': 'sigmoid', 'num_neurons_2': 27, 'activation_func_3': 'sigmoid', 'num_neurons_3': 6, 'activation_func_4': 'tanh', 'num_neurons_4': 30}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:08:12,634]\u001b[0m Trial 341 finished with value: 0.22092824113718101 and parameters: {'num_layers': 4, 'activation_func_0': 'sigmoid', 'num_neurons_0': 31, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 36, 'activation_func_2': 'tanh', 'num_neurons_2': 14, 'activation_func_3': 'sigmoid', 'num_neurons_3': 24}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:08:16,777]\u001b[0m Trial 342 finished with value: 0.22092824113718101 and parameters: {'num_layers': 3, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 37, 'activation_func_1': 'tanh', 'num_neurons_1': 8, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 3}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:08:21,130]\u001b[0m Trial 343 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'relu', 'num_neurons_0': 27, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 5, 'activation_func_2': 'sigmoid', 'num_neurons_2': 12, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 12, 'activation_func_4': 'sigmoid', 'num_neurons_4': 14}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:08:25,543]\u001b[0m Trial 344 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'tanh', 'num_neurons_0': 8, 'activation_func_1': 'sigmoid', 'num_neurons_1': 26, 'activation_func_2': 'relu', 'num_neurons_2': 2, 'activation_func_3': 'sigmoid', 'num_neurons_3': 33, 'activation_func_4': 'tanh', 'num_neurons_4': 21}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:08:29,827]\u001b[0m Trial 345 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'sigmoid', 'num_neurons_0': 22, 'activation_func_1': 'relu', 'num_neurons_1': 16, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 7, 'activation_func_3': 'tanh', 'num_neurons_3': 17, 'activation_func_4': 'relu', 'num_neurons_4': 24}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:08:34,276]\u001b[0m Trial 346 finished with value: 0.22092824113718101 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 26, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 6, 'activation_func_2': 'sigmoid', 'num_neurons_2': 1, 'activation_func_3': 'sigmoid', 'num_neurons_3': 10}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:08:38,639]\u001b[0m Trial 347 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'sigmoid', 'num_neurons_0': 34, 'activation_func_1': 'sigmoid', 'num_neurons_1': 2, 'activation_func_2': 'relu', 'num_neurons_2': 10, 'activation_func_3': 'sigmoid', 'num_neurons_3': 15, 'activation_func_4': 'tanh', 'num_neurons_4': 7}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:08:42,918]\u001b[0m Trial 348 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'relu', 'num_neurons_0': 24, 'activation_func_1': 'tanh', 'num_neurons_1': 28, 'activation_func_2': 'tanh', 'num_neurons_2': 18, 'activation_func_3': 'relu', 'num_neurons_3': 39, 'activation_func_4': 'sigmoid', 'num_neurons_4': 15}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:08:47,189]\u001b[0m Trial 349 finished with value: 0.22092824113718101 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 19, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 39, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 15, 'activation_func_3': 'sigmoid', 'num_neurons_3': 20}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:08:51,184]\u001b[0m Trial 350 finished with value: 0.22092824113718101 and parameters: {'num_layers': 1, 'activation_func_0': 'tanh', 'num_neurons_0': 16}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:08:55,486]\u001b[0m Trial 351 finished with value: 0.22092824113718101 and parameters: {'num_layers': 3, 'activation_func_0': 'sigmoid', 'num_neurons_0': 28, 'activation_func_1': 'sigmoid', 'num_neurons_1': 17, 'activation_func_2': 'sigmoid', 'num_neurons_2': 22}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:08:59,801]\u001b[0m Trial 352 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 20, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 4, 'activation_func_2': 'relu', 'num_neurons_2': 26, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 13, 'activation_func_4': 'tanh', 'num_neurons_4': 36}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:09:04,047]\u001b[0m Trial 353 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'relu', 'num_neurons_0': 18, 'activation_func_1': 'relu', 'num_neurons_1': 11, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 8, 'activation_func_3': 'sigmoid', 'num_neurons_3': 14, 'activation_func_4': 'leakyrelu', 'num_neurons_4': 2}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:09:08,254]\u001b[0m Trial 354 finished with value: 0.22092824113718101 and parameters: {'num_layers': 4, 'activation_func_0': 'sigmoid', 'num_neurons_0': 30, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 37, 'activation_func_2': 'sigmoid', 'num_neurons_2': 28, 'activation_func_3': 'tanh', 'num_neurons_3': 5}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:09:12,551]\u001b[0m Trial 355 finished with value: 0.22092824113718101 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 4, 'activation_func_1': 'sigmoid', 'num_neurons_1': 21, 'activation_func_2': 'tanh', 'num_neurons_2': 25, 'activation_func_3': 'sigmoid', 'num_neurons_3': 21}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:09:16,904]\u001b[0m Trial 356 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'tanh', 'num_neurons_0': 32, 'activation_func_1': 'tanh', 'num_neurons_1': 3, 'activation_func_2': 'relu', 'num_neurons_2': 16, 'activation_func_3': 'relu', 'num_neurons_3': 4, 'activation_func_4': 'tanh', 'num_neurons_4': 34}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:09:21,346]\u001b[0m Trial 357 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'sigmoid', 'num_neurons_0': 5, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 18, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 4, 'activation_func_3': 'sigmoid', 'num_neurons_3': 23, 'activation_func_4': 'sigmoid', 'num_neurons_4': 25}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:09:25,504]\u001b[0m Trial 358 finished with value: 0.22092824113718101 and parameters: {'num_layers': 3, 'activation_func_0': 'relu', 'num_neurons_0': 15, 'activation_func_1': 'sigmoid', 'num_neurons_1': 31, 'activation_func_2': 'sigmoid', 'num_neurons_2': 2}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:09:29,823]\u001b[0m Trial 359 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 21, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 33, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 17, 'activation_func_3': 'sigmoid', 'num_neurons_3': 30, 'activation_func_4': 'tanh', 'num_neurons_4': 12}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:09:34,159]\u001b[0m Trial 360 finished with value: 0.22092824113718101 and parameters: {'num_layers': 4, 'activation_func_0': 'sigmoid', 'num_neurons_0': 13, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 38, 'activation_func_2': 'relu', 'num_neurons_2': 10, 'activation_func_3': 'tanh', 'num_neurons_3': 19}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:09:38,665]\u001b[0m Trial 361 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'tanh', 'num_neurons_0': 14, 'activation_func_1': 'sigmoid', 'num_neurons_1': 10, 'activation_func_2': 'sigmoid', 'num_neurons_2': 6, 'activation_func_3': 'sigmoid', 'num_neurons_3': 35, 'activation_func_4': 'relu', 'num_neurons_4': 27}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:09:42,860]\u001b[0m Trial 362 finished with value: 0.22092824113718101 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 1, 'activation_func_1': 'relu', 'num_neurons_1': 12, 'activation_func_2': 'tanh', 'num_neurons_2': 35, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 8}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:09:47,172]\u001b[0m Trial 363 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'relu', 'num_neurons_0': 38, 'activation_func_1': 'tanh', 'num_neurons_1': 34, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 21, 'activation_func_3': 'sigmoid', 'num_neurons_3': 17, 'activation_func_4': 'sigmoid', 'num_neurons_4': 10}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:09:51,448]\u001b[0m Trial 364 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'sigmoid', 'num_neurons_0': 17, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 5, 'activation_func_2': 'relu', 'num_neurons_2': 7, 'activation_func_3': 'sigmoid', 'num_neurons_3': 6, 'activation_func_4': 'tanh', 'num_neurons_4': 19}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:09:55,823]\u001b[0m Trial 365 finished with value: 0.22092824113718101 and parameters: {'num_layers': 3, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 9, 'activation_func_1': 'sigmoid', 'num_neurons_1': 8, 'activation_func_2': 'sigmoid', 'num_neurons_2': 12}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:09:59,859]\u001b[0m Trial 366 finished with value: 0.22092824113718101 and parameters: {'num_layers': 1, 'activation_func_0': 'tanh', 'num_neurons_0': 23}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:10:04,282]\u001b[0m Trial 367 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'sigmoid', 'num_neurons_0': 27, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 7, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 8, 'activation_func_3': 'relu', 'num_neurons_3': 7, 'activation_func_4': 'leakyrelu', 'num_neurons_4': 5}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:10:08,460]\u001b[0m Trial 368 finished with value: 0.22092824113718101 and parameters: {'num_layers': 2, 'activation_func_0': 'relu', 'num_neurons_0': 33, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 23}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:10:12,915]\u001b[0m Trial 369 finished with value: 0.22092824113718101 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 12, 'activation_func_1': 'sigmoid', 'num_neurons_1': 27, 'activation_func_2': 'relu', 'num_neurons_2': 13, 'activation_func_3': 'sigmoid', 'num_neurons_3': 2}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:10:17,326]\u001b[0m Trial 370 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'sigmoid', 'num_neurons_0': 29, 'activation_func_1': 'tanh', 'num_neurons_1': 9, 'activation_func_2': 'sigmoid', 'num_neurons_2': 11, 'activation_func_3': 'tanh', 'num_neurons_3': 1, 'activation_func_4': 'tanh', 'num_neurons_4': 3}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:10:21,638]\u001b[0m Trial 371 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 24, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 5, 'activation_func_2': 'tanh', 'num_neurons_2': 1, 'activation_func_3': 'sigmoid', 'num_neurons_3': 26, 'activation_func_4': 'sigmoid', 'num_neurons_4': 29}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:10:25,902]\u001b[0m Trial 372 finished with value: 0.22092824113718101 and parameters: {'num_layers': 4, 'activation_func_0': 'relu', 'num_neurons_0': 21, 'activation_func_1': 'relu', 'num_neurons_1': 25, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 6, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 11}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:10:30,433]\u001b[0m Trial 373 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'tanh', 'num_neurons_0': 16, 'activation_func_1': 'sigmoid', 'num_neurons_1': 36, 'activation_func_2': 'sigmoid', 'num_neurons_2': 5, 'activation_func_3': 'sigmoid', 'num_neurons_3': 22, 'activation_func_4': 'tanh', 'num_neurons_4': 13}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:10:34,863]\u001b[0m Trial 374 finished with value: 0.22092824113718101 and parameters: {'num_layers': 3, 'activation_func_0': 'sigmoid', 'num_neurons_0': 28, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 15, 'activation_func_2': 'relu', 'num_neurons_2': 9}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:10:39,115]\u001b[0m Trial 375 finished with value: 0.22092824113718101 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 35, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 14, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 3, 'activation_func_3': 'sigmoid', 'num_neurons_3': 10}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:10:43,693]\u001b[0m Trial 376 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'relu', 'num_neurons_0': 22, 'activation_func_1': 'sigmoid', 'num_neurons_1': 1, 'activation_func_2': 'sigmoid', 'num_neurons_2': 15, 'activation_func_3': 'tanh', 'num_neurons_3': 19, 'activation_func_4': 'sigmoid', 'num_neurons_4': 32}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:10:48,384]\u001b[0m Trial 377 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'sigmoid', 'num_neurons_0': 25, 'activation_func_1': 'tanh', 'num_neurons_1': 29, 'activation_func_2': 'tanh', 'num_neurons_2': 19, 'activation_func_3': 'relu', 'num_neurons_3': 18, 'activation_func_4': 'tanh', 'num_neurons_4': 14}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:10:53,233]\u001b[0m Trial 378 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 15, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 10, 'activation_func_2': 'relu', 'num_neurons_2': 24, 'activation_func_3': 'sigmoid', 'num_neurons_3': 16, 'activation_func_4': 'relu', 'num_neurons_4': 17}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:10:57,714]\u001b[0m Trial 379 finished with value: 0.22092824113718101 and parameters: {'num_layers': 4, 'activation_func_0': 'tanh', 'num_neurons_0': 26, 'activation_func_1': 'sigmoid', 'num_neurons_1': 17, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 30, 'activation_func_3': 'sigmoid', 'num_neurons_3': 20}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:11:02,143]\u001b[0m Trial 380 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'sigmoid', 'num_neurons_0': 3, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 6, 'activation_func_2': 'sigmoid', 'num_neurons_2': 1, 'activation_func_3': 'sigmoid', 'num_neurons_3': 37, 'activation_func_4': 'tanh', 'num_neurons_4': 35}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:11:06,147]\u001b[0m Trial 381 finished with value: 0.22092824113718101 and parameters: {'num_layers': 1, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 37}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:11:10,677]\u001b[0m Trial 382 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'relu', 'num_neurons_0': 20, 'activation_func_1': 'relu', 'num_neurons_1': 20, 'activation_func_2': 'relu', 'num_neurons_2': 20, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 15, 'activation_func_4': 'sigmoid', 'num_neurons_4': 6}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:11:15,038]\u001b[0m Trial 383 finished with value: 0.22092824113718101 and parameters: {'num_layers': 2, 'activation_func_0': 'sigmoid', 'num_neurons_0': 23, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 22}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:11:19,231]\u001b[0m Trial 384 finished with value: 0.22092824113718101 and parameters: {'num_layers': 3, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 30, 'activation_func_1': 'sigmoid', 'num_neurons_1': 13, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 13}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:11:23,603]\u001b[0m Trial 385 finished with value: 0.22092824113718101 and parameters: {'num_layers': 4, 'activation_func_0': 'tanh', 'num_neurons_0': 27, 'activation_func_1': 'tanh', 'num_neurons_1': 4, 'activation_func_2': 'sigmoid', 'num_neurons_2': 14, 'activation_func_3': 'tanh', 'num_neurons_3': 27}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:11:27,826]\u001b[0m Trial 386 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'relu', 'num_neurons_0': 11, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 35, 'activation_func_2': 'tanh', 'num_neurons_2': 11, 'activation_func_3': 'sigmoid', 'num_neurons_3': 12, 'activation_func_4': 'leakyrelu', 'num_neurons_4': 11}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:11:32,179]\u001b[0m Trial 387 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'sigmoid', 'num_neurons_0': 7, 'activation_func_1': 'sigmoid', 'num_neurons_1': 3, 'activation_func_2': 'relu', 'num_neurons_2': 2, 'activation_func_3': 'sigmoid', 'num_neurons_3': 9, 'activation_func_4': 'tanh', 'num_neurons_4': 16}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:11:36,678]\u001b[0m Trial 388 finished with value: 0.22092824113718101 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 18, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 40, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 9, 'activation_func_3': 'relu', 'num_neurons_3': 32}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:11:40,858]\u001b[0m Trial 389 finished with value: 0.22092824113718101 and parameters: {'num_layers': 3, 'activation_func_0': 'tanh', 'num_neurons_0': 2, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 37, 'activation_func_2': 'sigmoid', 'num_neurons_2': 4}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:11:45,393]\u001b[0m Trial 390 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'sigmoid', 'num_neurons_0': 24, 'activation_func_1': 'relu', 'num_neurons_1': 8, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 7, 'activation_func_3': 'sigmoid', 'num_neurons_3': 13, 'activation_func_4': 'tanh', 'num_neurons_4': 8}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:11:49,855]\u001b[0m Trial 391 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 13, 'activation_func_1': 'sigmoid', 'num_neurons_1': 24, 'activation_func_2': 'relu', 'num_neurons_2': 16, 'activation_func_3': 'sigmoid', 'num_neurons_3': 18, 'activation_func_4': 'sigmoid', 'num_neurons_4': 37}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:11:54,470]\u001b[0m Trial 392 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'relu', 'num_neurons_0': 14, 'activation_func_1': 'tanh', 'num_neurons_1': 7, 'activation_func_2': 'sigmoid', 'num_neurons_2': 2, 'activation_func_3': 'tanh', 'num_neurons_3': 17, 'activation_func_4': 'relu', 'num_neurons_4': 31}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:11:58,801]\u001b[0m Trial 393 finished with value: 0.22092824113718101 and parameters: {'num_layers': 4, 'activation_func_0': 'sigmoid', 'num_neurons_0': 17, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 18, 'activation_func_2': 'tanh', 'num_neurons_2': 25, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 24}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:12:03,098]\u001b[0m Trial 394 finished with value: 0.22092824113718101 and parameters: {'num_layers': 3, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 29, 'activation_func_1': 'sigmoid', 'num_neurons_1': 39, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 37}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:12:07,438]\u001b[0m Trial 395 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'tanh', 'num_neurons_0': 32, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 6, 'activation_func_2': 'relu', 'num_neurons_2': 23, 'activation_func_3': 'sigmoid', 'num_neurons_3': 7, 'activation_func_4': 'tanh', 'num_neurons_4': 2}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:12:11,652]\u001b[0m Trial 396 finished with value: 0.22092824113718101 and parameters: {'num_layers': 4, 'activation_func_0': 'relu', 'num_neurons_0': 39, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 11, 'activation_func_2': 'sigmoid', 'num_neurons_2': 12, 'activation_func_3': 'sigmoid', 'num_neurons_3': 11}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:12:15,837]\u001b[0m Trial 397 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'sigmoid', 'num_neurons_0': 19, 'activation_func_1': 'tanh', 'num_neurons_1': 25, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 29, 'activation_func_3': 'relu', 'num_neurons_3': 14, 'activation_func_4': 'sigmoid', 'num_neurons_4': 21}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:12:20,087]\u001b[0m Trial 398 finished with value: 0.22092824113718101 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 21, 'activation_func_1': 'sigmoid', 'num_neurons_1': 31, 'activation_func_2': 'relu', 'num_neurons_2': 8, 'activation_func_3': 'sigmoid', 'num_neurons_3': 4}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:12:24,406]\u001b[0m Trial 399 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'sigmoid', 'num_neurons_0': 16, 'activation_func_1': 'relu', 'num_neurons_1': 16, 'activation_func_2': 'sigmoid', 'num_neurons_2': 18, 'activation_func_3': 'tanh', 'num_neurons_3': 2, 'activation_func_4': 'tanh', 'num_neurons_4': 4}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:12:28,269]\u001b[0m Trial 400 finished with value: 0.22092824113718101 and parameters: {'num_layers': 1, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 26}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:12:32,727]\u001b[0m Trial 401 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'relu', 'num_neurons_0': 31, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 26, 'activation_func_2': 'tanh', 'num_neurons_2': 10, 'activation_func_3': 'sigmoid', 'num_neurons_3': 21, 'activation_func_4': 'leakyrelu', 'num_neurons_4': 9}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:12:37,082]\u001b[0m Trial 402 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'tanh', 'num_neurons_0': 25, 'activation_func_1': 'sigmoid', 'num_neurons_1': 19, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 27, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 5, 'activation_func_4': 'tanh', 'num_neurons_4': 39}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:12:41,262]\u001b[0m Trial 403 finished with value: 0.22092824113718101 and parameters: {'num_layers': 4, 'activation_func_0': 'sigmoid', 'num_neurons_0': 23, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 12, 'activation_func_2': 'sigmoid', 'num_neurons_2': 11, 'activation_func_3': 'sigmoid', 'num_neurons_3': 29}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:12:45,469]\u001b[0m Trial 404 finished with value: 0.22092824113718101 and parameters: {'num_layers': 3, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 10, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 9, 'activation_func_2': 'relu', 'num_neurons_2': 3}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:12:50,096]\u001b[0m Trial 405 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'relu', 'num_neurons_0': 28, 'activation_func_1': 'tanh', 'num_neurons_1': 38, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 1, 'activation_func_3': 'sigmoid', 'num_neurons_3': 6, 'activation_func_4': 'sigmoid', 'num_neurons_4': 20}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:12:54,335]\u001b[0m Trial 406 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'sigmoid', 'num_neurons_0': 22, 'activation_func_1': 'sigmoid', 'num_neurons_1': 5, 'activation_func_2': 'tanh', 'num_neurons_2': 6, 'activation_func_3': 'tanh', 'num_neurons_3': 26, 'activation_func_4': 'tanh', 'num_neurons_4': 33}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:12:58,436]\u001b[0m Trial 407 finished with value: 0.22092824113718101 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 36, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 2, 'activation_func_2': 'sigmoid', 'num_neurons_2': 12, 'activation_func_3': 'relu', 'num_neurons_3': 34}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:13:02,736]\u001b[0m Trial 408 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'tanh', 'num_neurons_0': 17, 'activation_func_1': 'relu', 'num_neurons_1': 32, 'activation_func_2': 'relu', 'num_neurons_2': 4, 'activation_func_3': 'sigmoid', 'num_neurons_3': 9, 'activation_func_4': 'relu', 'num_neurons_4': 3}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:13:07,553]\u001b[0m Trial 409 finished with value: 0.22092824113718101 and parameters: {'num_layers': 4, 'activation_func_0': 'sigmoid', 'num_neurons_0': 12, 'activation_func_1': 'sigmoid', 'num_neurons_1': 33, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 13, 'activation_func_3': 'sigmoid', 'num_neurons_3': 8}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:13:12,213]\u001b[0m Trial 410 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 1, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 34, 'activation_func_2': 'sigmoid', 'num_neurons_2': 39, 'activation_func_3': 'sigmoid', 'num_neurons_3': 18, 'activation_func_4': 'sigmoid', 'num_neurons_4': 15}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:13:16,665]\u001b[0m Trial 411 finished with value: 0.22092824113718101 and parameters: {'num_layers': 3, 'activation_func_0': 'relu', 'num_neurons_0': 20, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 6, 'activation_func_2': 'relu', 'num_neurons_2': 5}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:13:20,942]\u001b[0m Trial 412 finished with value: 0.22092824113718101 and parameters: {'num_layers': 4, 'activation_func_0': 'tanh', 'num_neurons_0': 29, 'activation_func_1': 'tanh', 'num_neurons_1': 9, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 26, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 19}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:13:25,170]\u001b[0m Trial 413 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'sigmoid', 'num_neurons_0': 27, 'activation_func_1': 'sigmoid', 'num_neurons_1': 36, 'activation_func_2': 'tanh', 'num_neurons_2': 20, 'activation_func_3': 'sigmoid', 'num_neurons_3': 16, 'activation_func_4': 'tanh', 'num_neurons_4': 24}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:13:29,589]\u001b[0m Trial 414 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 2, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 28, 'activation_func_2': 'sigmoid', 'num_neurons_2': 33, 'activation_func_3': 'tanh', 'num_neurons_3': 12, 'activation_func_4': 'tanh', 'num_neurons_4': 28}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:13:33,976]\u001b[0m Trial 415 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'relu', 'num_neurons_0': 19, 'activation_func_1': 'sigmoid', 'num_neurons_1': 7, 'activation_func_2': 'relu', 'num_neurons_2': 7, 'activation_func_3': 'sigmoid', 'num_neurons_3': 14, 'activation_func_4': 'leakyrelu', 'num_neurons_4': 10}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:13:38,208]\u001b[0m Trial 416 finished with value: 0.22092824113718101 and parameters: {'num_layers': 2, 'activation_func_0': 'sigmoid', 'num_neurons_0': 14, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 30}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:13:42,244]\u001b[0m Trial 417 finished with value: 0.22092824113718101 and parameters: {'num_layers': 1, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 40}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:13:46,553]\u001b[0m Trial 418 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'tanh', 'num_neurons_0': 34, 'activation_func_1': 'relu', 'num_neurons_1': 21, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 1, 'activation_func_3': 'relu', 'num_neurons_3': 15, 'activation_func_4': 'sigmoid', 'num_neurons_4': 18}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:13:50,761]\u001b[0m Trial 419 finished with value: 0.22092824113718101 and parameters: {'num_layers': 4, 'activation_func_0': 'sigmoid', 'num_neurons_0': 24, 'activation_func_1': 'tanh', 'num_neurons_1': 4, 'activation_func_2': 'sigmoid', 'num_neurons_2': 14, 'activation_func_3': 'sigmoid', 'num_neurons_3': 1}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:13:55,098]\u001b[0m Trial 420 finished with value: 0.22092824113718101 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 21, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 11, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 2, 'activation_func_3': 'sigmoid', 'num_neurons_3': 22}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:13:59,678]\u001b[0m Trial 421 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'relu', 'num_neurons_0': 30, 'activation_func_1': 'sigmoid', 'num_neurons_1': 10, 'activation_func_2': 'relu', 'num_neurons_2': 8, 'activation_func_3': 'tanh', 'num_neurons_3': 7, 'activation_func_4': 'tanh', 'num_neurons_4': 1}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:14:03,863]\u001b[0m Trial 422 finished with value: 0.22092824113718101 and parameters: {'num_layers': 3, 'activation_func_0': 'sigmoid', 'num_neurons_0': 22, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 15, 'activation_func_2': 'tanh', 'num_neurons_2': 32}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:14:08,246]\u001b[0m Trial 423 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 15, 'activation_func_1': 'sigmoid', 'num_neurons_1': 13, 'activation_func_2': 'sigmoid', 'num_neurons_2': 22, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 25, 'activation_func_4': 'sigmoid', 'num_neurons_4': 22}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:14:12,563]\u001b[0m Trial 424 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'tanh', 'num_neurons_0': 25, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 23, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 3, 'activation_func_3': 'sigmoid', 'num_neurons_3': 3, 'activation_func_4': 'tanh', 'num_neurons_4': 12}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:14:16,793]\u001b[0m Trial 425 finished with value: 0.22092824113718101 and parameters: {'num_layers': 4, 'activation_func_0': 'relu', 'num_neurons_0': 18, 'activation_func_1': 'tanh', 'num_neurons_1': 3, 'activation_func_2': 'relu', 'num_neurons_2': 10, 'activation_func_3': 'sigmoid', 'num_neurons_3': 20}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:14:21,171]\u001b[0m Trial 426 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'sigmoid', 'num_neurons_0': 11, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 35, 'activation_func_2': 'sigmoid', 'num_neurons_2': 13, 'activation_func_3': 'relu', 'num_neurons_3': 23, 'activation_func_4': 'relu', 'num_neurons_4': 23}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:14:25,776]\u001b[0m Trial 427 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 35, 'activation_func_1': 'relu', 'num_neurons_1': 5, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 6, 'activation_func_3': 'sigmoid', 'num_neurons_3': 16, 'activation_func_4': 'tanh', 'num_neurons_4': 5}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:14:30,182]\u001b[0m Trial 428 finished with value: 0.22092824113718101 and parameters: {'num_layers': 3, 'activation_func_0': 'sigmoid', 'num_neurons_0': 33, 'activation_func_1': 'sigmoid', 'num_neurons_1': 7, 'activation_func_2': 'tanh', 'num_neurons_2': 17}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:14:34,658]\u001b[0m Trial 429 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 13, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 1, 'activation_func_2': 'relu', 'num_neurons_2': 7, 'activation_func_3': 'sigmoid', 'num_neurons_3': 10, 'activation_func_4': 'sigmoid', 'num_neurons_4': 26}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:14:38,815]\u001b[0m Trial 430 finished with value: 0.22092824113718101 and parameters: {'num_layers': 4, 'activation_func_0': 'tanh', 'num_neurons_0': 31, 'activation_func_1': 'sigmoid', 'num_neurons_1': 14, 'activation_func_2': 'sigmoid', 'num_neurons_2': 4, 'activation_func_3': 'tanh', 'num_neurons_3': 5}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:14:42,846]\u001b[0m Trial 431 finished with value: 0.0 and parameters: {'num_layers': 3, 'activation_func_0': 'relu', 'num_neurons_0': 38, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 36, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 24}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:14:47,180]\u001b[0m Trial 432 finished with value: 0.22092824113718101 and parameters: {'num_layers': 4, 'activation_func_0': 'sigmoid', 'num_neurons_0': 28, 'activation_func_1': 'tanh', 'num_neurons_1': 22, 'activation_func_2': 'relu', 'num_neurons_2': 1, 'activation_func_3': 'sigmoid', 'num_neurons_3': 28}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:14:51,820]\u001b[0m Trial 433 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 16, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 37, 'activation_func_2': 'sigmoid', 'num_neurons_2': 11, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 17, 'activation_func_4': 'leakyrelu', 'num_neurons_4': 36}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:14:56,162]\u001b[0m Trial 434 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'relu', 'num_neurons_0': 23, 'activation_func_1': 'sigmoid', 'num_neurons_1': 6, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 9, 'activation_func_3': 'sigmoid', 'num_neurons_3': 6, 'activation_func_4': 'tanh', 'num_neurons_4': 13}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:15:00,177]\u001b[0m Trial 435 finished with value: 0.22092824113718101 and parameters: {'num_layers': 1, 'activation_func_0': 'sigmoid', 'num_neurons_0': 19}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:15:04,499]\u001b[0m Trial 436 finished with value: 0.22092824113718101 and parameters: {'num_layers': 4, 'activation_func_0': 'tanh', 'num_neurons_0': 21, 'activation_func_1': 'relu', 'num_neurons_1': 8, 'activation_func_2': 'tanh', 'num_neurons_2': 12, 'activation_func_3': 'sigmoid', 'num_neurons_3': 30}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:15:08,937]\u001b[0m Trial 437 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 22, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 27, 'activation_func_2': 'sigmoid', 'num_neurons_2': 21, 'activation_func_3': 'relu', 'num_neurons_3': 4, 'activation_func_4': 'tanh', 'num_neurons_4': 38}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:15:13,420]\u001b[0m Trial 438 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'sigmoid', 'num_neurons_0': 29, 'activation_func_1': 'sigmoid', 'num_neurons_1': 4, 'activation_func_2': 'relu', 'num_neurons_2': 35, 'activation_func_3': 'tanh', 'num_neurons_3': 21, 'activation_func_4': 'sigmoid', 'num_neurons_4': 7}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:15:17,702]\u001b[0m Trial 439 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 13, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 12, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 15, 'activation_func_3': 'sigmoid', 'num_neurons_3': 9, 'activation_func_4': 'relu', 'num_neurons_4': 34}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:15:22,075]\u001b[0m Trial 440 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'relu', 'num_neurons_0': 36, 'activation_func_1': 'tanh', 'num_neurons_1': 18, 'activation_func_2': 'sigmoid', 'num_neurons_2': 2, 'activation_func_3': 'sigmoid', 'num_neurons_3': 20, 'activation_func_4': 'tanh', 'num_neurons_4': 40}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:15:26,401]\u001b[0m Trial 441 finished with value: 0.22092824113718101 and parameters: {'num_layers': 4, 'activation_func_0': 'tanh', 'num_neurons_0': 26, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 5, 'activation_func_2': 'relu', 'num_neurons_2': 3, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 13}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:15:30,813]\u001b[0m Trial 442 finished with value: 0.22092824113718101 and parameters: {'num_layers': 3, 'activation_func_0': 'sigmoid', 'num_neurons_0': 39, 'activation_func_1': 'sigmoid', 'num_neurons_1': 17, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 5}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:15:35,155]\u001b[0m Trial 443 finished with value: 0.22092824113718101 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 9, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 40, 'activation_func_2': 'tanh', 'num_neurons_2': 16, 'activation_func_3': 'sigmoid', 'num_neurons_3': 14}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:15:39,128]\u001b[0m Trial 444 finished with value: 0.22092824113718101 and parameters: {'num_layers': 1, 'activation_func_0': 'relu', 'num_neurons_0': 20}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:15:43,536]\u001b[0m Trial 445 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'sigmoid', 'num_neurons_0': 27, 'activation_func_1': 'sigmoid', 'num_neurons_1': 19, 'activation_func_2': 'sigmoid', 'num_neurons_2': 8, 'activation_func_3': 'tanh', 'num_neurons_3': 18, 'activation_func_4': 'sigmoid', 'num_neurons_4': 27}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:15:47,811]\u001b[0m Trial 446 finished with value: 0.22092824113718101 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 6, 'activation_func_1': 'relu', 'num_neurons_1': 38, 'activation_func_2': 'relu', 'num_neurons_2': 19, 'activation_func_3': 'sigmoid', 'num_neurons_3': 19}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:15:52,138]\u001b[0m Trial 447 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'tanh', 'num_neurons_0': 17, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 10, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 38, 'activation_func_3': 'relu', 'num_neurons_3': 8, 'activation_func_4': 'tanh', 'num_neurons_4': 3}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:15:56,513]\u001b[0m Trial 448 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'sigmoid', 'num_neurons_0': 3, 'activation_func_1': 'tanh', 'num_neurons_1': 8, 'activation_func_2': 'sigmoid', 'num_neurons_2': 28, 'activation_func_3': 'sigmoid', 'num_neurons_3': 39, 'activation_func_4': 'leakyrelu', 'num_neurons_4': 35}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:16:00,914]\u001b[0m Trial 449 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 12, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 39, 'activation_func_2': 'relu', 'num_neurons_2': 6, 'activation_func_3': 'sigmoid', 'num_neurons_3': 15, 'activation_func_4': 'tanh', 'num_neurons_4': 30}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:16:05,300]\u001b[0m Trial 450 finished with value: 0.22092824113718101 and parameters: {'num_layers': 3, 'activation_func_0': 'relu', 'num_neurons_0': 1, 'activation_func_1': 'sigmoid', 'num_neurons_1': 20, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 14}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:16:09,723]\u001b[0m Trial 451 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'sigmoid', 'num_neurons_0': 24, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 24, 'activation_func_2': 'tanh', 'num_neurons_2': 26, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 12, 'activation_func_4': 'sigmoid', 'num_neurons_4': 11}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:16:13,730]\u001b[0m Trial 452 finished with value: 0.22092824113718101 and parameters: {'num_layers': 2, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 15, 'activation_func_1': 'sigmoid', 'num_neurons_1': 3}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:16:18,214]\u001b[0m Trial 453 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'relu', 'num_neurons_0': 26, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 14, 'activation_func_2': 'sigmoid', 'num_neurons_2': 2, 'activation_func_3': 'sigmoid', 'num_neurons_3': 24, 'activation_func_4': 'tanh', 'num_neurons_4': 31}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:16:22,468]\u001b[0m Trial 454 finished with value: 0.22092824113718101 and parameters: {'num_layers': 4, 'activation_func_0': 'tanh', 'num_neurons_0': 23, 'activation_func_1': 'tanh', 'num_neurons_1': 16, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 18, 'activation_func_3': 'tanh', 'num_neurons_3': 7}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:16:26,868]\u001b[0m Trial 455 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'sigmoid', 'num_neurons_0': 25, 'activation_func_1': 'relu', 'num_neurons_1': 34, 'activation_func_2': 'relu', 'num_neurons_2': 9, 'activation_func_3': 'sigmoid', 'num_neurons_3': 32, 'activation_func_4': 'relu', 'num_neurons_4': 33}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:16:31,150]\u001b[0m Trial 456 finished with value: 0.22092824113718101 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 31, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 28, 'activation_func_2': 'sigmoid', 'num_neurons_2': 10, 'activation_func_3': 'sigmoid', 'num_neurons_3': 17}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:16:35,555]\u001b[0m Trial 457 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'sigmoid', 'num_neurons_0': 18, 'activation_func_1': 'sigmoid', 'num_neurons_1': 25, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 22, 'activation_func_3': 'relu', 'num_neurons_3': 36, 'activation_func_4': 'sigmoid', 'num_neurons_4': 6}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:16:39,835]\u001b[0m Trial 458 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'tanh', 'num_neurons_0': 28, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 31, 'activation_func_2': 'tanh', 'num_neurons_2': 1, 'activation_func_3': 'sigmoid', 'num_neurons_3': 13, 'activation_func_4': 'tanh', 'num_neurons_4': 15}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:16:44,115]\u001b[0m Trial 459 finished with value: 0.22092824113718101 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 30, 'activation_func_1': 'sigmoid', 'num_neurons_1': 30, 'activation_func_2': 'relu', 'num_neurons_2': 11, 'activation_func_3': 'tanh', 'num_neurons_3': 1}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:16:48,367]\u001b[0m Trial 460 finished with value: 0.22092824113718101 and parameters: {'num_layers': 4, 'activation_func_0': 'relu', 'num_neurons_0': 37, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 29, 'activation_func_2': 'sigmoid', 'num_neurons_2': 7, 'activation_func_3': 'sigmoid', 'num_neurons_3': 3}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:16:52,407]\u001b[0m Trial 461 finished with value: 0.22092824113718101 and parameters: {'num_layers': 3, 'activation_func_0': 'sigmoid', 'num_neurons_0': 20, 'activation_func_1': 'tanh', 'num_neurons_1': 6, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 5}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:16:56,663]\u001b[0m Trial 462 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 14, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 11, 'activation_func_2': 'relu', 'num_neurons_2': 31, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 16, 'activation_func_4': 'tanh', 'num_neurons_4': 4}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:17:00,926]\u001b[0m Trial 463 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'relu', 'num_neurons_0': 22, 'activation_func_1': 'sigmoid', 'num_neurons_1': 4, 'activation_func_2': 'sigmoid', 'num_neurons_2': 23, 'activation_func_3': 'sigmoid', 'num_neurons_3': 19, 'activation_func_4': 'leakyrelu', 'num_neurons_4': 14}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:17:05,151]\u001b[0m Trial 464 finished with value: 0.22092824113718101 and parameters: {'num_layers': 3, 'activation_func_0': 'tanh', 'num_neurons_0': 5, 'activation_func_1': 'relu', 'num_neurons_1': 7, 'activation_func_2': 'tanh', 'num_neurons_2': 8}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:17:09,311]\u001b[0m Trial 465 finished with value: 0.22092824113718101 and parameters: {'num_layers': 1, 'activation_func_0': 'sigmoid', 'num_neurons_0': 23}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:17:13,917]\u001b[0m Trial 466 finished with value: 0.22092824113718101 and parameters: {'num_layers': 5, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 32, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 37, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 16, 'activation_func_3': 'sigmoid', 'num_neurons_3': 27, 'activation_func_4': 'sigmoid', 'num_neurons_4': 2}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:17:17,910]\u001b[0m Trial 467 finished with value: 0.22092824113718101 and parameters: {'num_layers': 2, 'activation_func_0': 'sigmoid', 'num_neurons_0': 27, 'activation_func_1': 'sigmoid', 'num_neurons_1': 9}. Best is trial 1 with value: 0.22092824113718101.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from optuna.samplers import TPESampler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "X_train = train[feature_for_nn]\n",
    "X_valid = valid[feature_for_nn]\n",
    "\n",
    "trainset  = TensorDataset(torch.from_numpy(X_train.copy().to_numpy()).float(), torch.from_numpy(y_train.to_numpy()).float())\n",
    "validset  = TensorDataset(torch.from_numpy(X_valid.copy().to_numpy()).float(), torch.from_numpy(y_valid.to_numpy()).float())\n",
    "trainloader = DataLoader(trainset, batch_size = 1024, shuffle=True)\n",
    "\n",
    "def objective(trial):\n",
    "       \n",
    "    model = train_net(NeuralNetworkBuilder, len(feature_for_nn), trainloader, validset, trial=trial, num_epochs = 20, lr = 5e-3)\n",
    "  \n",
    "    lfp = 1\n",
    "    lfn = 19\n",
    "    tau = lfp/(lfp+lfn)\n",
    "\n",
    "    # y_pred = decision_tree.predict(X_valid[feature_for_dt])\n",
    "\n",
    "    y_prob = predict(model, validset[:][0]).numpy()\n",
    "    y_prob[y_prob < 1e-5] = 1e-5\n",
    "    y_prob[y_prob > 1- 1e-5] =  1- 1e-5\n",
    "    y_pred = (y_prob > tau).astype(int)\n",
    "    f1 = f1_score(y_valid, y_pred)\n",
    "    \n",
    "    return f1\n",
    "\n",
    "sampler = TPESampler(seed=42) \n",
    "study = optuna.create_study(direction='maximize', sampler=sampler)\n",
    "study.optimize(objective, n_trials = 1000, timeout = 2000) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1ad0bff4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'num_layers': 5,\n",
       " 'activation_func_0': 'relu',\n",
       " 'num_neurons_0': 13,\n",
       " 'activation_func_1': 'sigmoid',\n",
       " 'num_neurons_1': 6,\n",
       " 'activation_func_2': 'sigmoid',\n",
       " 'num_neurons_2': 8,\n",
       " 'activation_func_3': 'sigmoid',\n",
       " 'num_neurons_3': 7,\n",
       " 'activation_func_4': 'tanh',\n",
       " 'num_neurons_4': 13}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = study.best_params\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "05d4fceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_nn_modules = [*params]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "509633d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork_No_Class_Balancing(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size):\n",
    "        super(NeuralNetwork_No_Class_Balancing, self).__init__()\n",
    "        \n",
    "        self.feedforward = nn.Sequential(            \n",
    "            nn.Linear(input_size, 27),            \n",
    "            nn.LeakyReLU(),                       \n",
    "            nn.Linear(27, 9),\n",
    "            nn.LeakyReLU(),      \n",
    "            nn.Linear(9, 22),\n",
    "            nn.LeakyReLU(),      \n",
    "            nn.Linear(22, 1),\n",
    "            nn.Sigmoid()\n",
    "        )                        \n",
    "\n",
    "\n",
    "    def forward(self, X):        \n",
    "        return self.feedforward(X).flatten() # returns a flat array as desired"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "086acf3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train loss</th>\n",
       "      <th>valid loss</th>\n",
       "      <th>valid recall</th>\n",
       "      <th>valid average precision</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>50.635</td>\n",
       "      <td>35.918</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.230</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>29.245</td>\n",
       "      <td>21.818</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.235</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>16.575</td>\n",
       "      <td>11.034</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.248</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>9.350</td>\n",
       "      <td>7.052</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.380</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>5.062</td>\n",
       "      <td>3.619</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.398</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>3.431</td>\n",
       "      <td>3.424</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.405</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>3.412</td>\n",
       "      <td>3.449</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.405</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>3.404</td>\n",
       "      <td>3.413</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.404</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>3.379</td>\n",
       "      <td>3.395</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.400</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>3.376</td>\n",
       "      <td>3.394</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.397</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>3.375</td>\n",
       "      <td>3.396</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.404</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>3.374</td>\n",
       "      <td>3.396</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.404</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>3.374</td>\n",
       "      <td>3.395</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.404</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>3.374</td>\n",
       "      <td>3.396</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.404</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>3.373</td>\n",
       "      <td>3.395</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.404</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>3.373</td>\n",
       "      <td>3.395</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.404</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>3.373</td>\n",
       "      <td>3.395</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.405</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>3.373</td>\n",
       "      <td>3.395</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.405</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>3.373</td>\n",
       "      <td>3.394</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.405</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>3.372</td>\n",
       "      <td>3.395</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.405</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>3.372</td>\n",
       "      <td>3.395</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.405</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>3.372</td>\n",
       "      <td>3.394</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.406</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>3.372</td>\n",
       "      <td>3.392</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.403</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>3.371</td>\n",
       "      <td>3.392</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.405</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>3.370</td>\n",
       "      <td>3.392</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.401</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>3.370</td>\n",
       "      <td>3.392</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.406</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>3.370</td>\n",
       "      <td>3.391</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.404</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>3.370</td>\n",
       "      <td>3.394</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.409</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>3.369</td>\n",
       "      <td>3.390</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.401</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>3.369</td>\n",
       "      <td>3.392</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.411</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>3.369</td>\n",
       "      <td>3.390</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.408</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>3.368</td>\n",
       "      <td>3.389</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.393</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>3.367</td>\n",
       "      <td>3.392</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.412</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>3.368</td>\n",
       "      <td>3.388</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.400</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>3.367</td>\n",
       "      <td>3.390</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.411</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>3.371</td>\n",
       "      <td>3.391</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.410</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>3.367</td>\n",
       "      <td>3.387</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.409</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>3.364</td>\n",
       "      <td>3.385</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.401</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>3.363</td>\n",
       "      <td>3.385</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.400</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>3.363</td>\n",
       "      <td>3.383</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.394</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>3.363</td>\n",
       "      <td>3.382</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.394</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>3.360</td>\n",
       "      <td>3.384</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.403</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>3.359</td>\n",
       "      <td>3.379</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.397</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>3.359</td>\n",
       "      <td>3.378</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.398</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>3.357</td>\n",
       "      <td>3.377</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.399</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>3.355</td>\n",
       "      <td>3.374</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.401</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>3.351</td>\n",
       "      <td>3.372</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.403</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>3.348</td>\n",
       "      <td>3.376</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.406</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>3.350</td>\n",
       "      <td>3.377</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.408</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>3.348</td>\n",
       "      <td>3.373</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.409</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>3.347</td>\n",
       "      <td>3.365</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.410</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>3.342</td>\n",
       "      <td>3.365</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.411</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>3.340</td>\n",
       "      <td>3.366</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.413</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>3.343</td>\n",
       "      <td>3.367</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.414</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>3.341</td>\n",
       "      <td>3.363</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.416</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>3.337</td>\n",
       "      <td>3.354</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.416</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>3.331</td>\n",
       "      <td>3.349</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.417</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>3.329</td>\n",
       "      <td>3.349</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.418</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>3.323</td>\n",
       "      <td>3.344</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.419</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>3.319</td>\n",
       "      <td>3.344</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.420</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61</td>\n",
       "      <td>3.320</td>\n",
       "      <td>3.350</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.422</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62</td>\n",
       "      <td>3.318</td>\n",
       "      <td>3.336</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.422</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>63</td>\n",
       "      <td>3.323</td>\n",
       "      <td>3.336</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.422</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>3.322</td>\n",
       "      <td>3.377</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.424</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65</td>\n",
       "      <td>3.315</td>\n",
       "      <td>3.338</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.424</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66</td>\n",
       "      <td>3.315</td>\n",
       "      <td>3.326</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.425</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>67</td>\n",
       "      <td>3.304</td>\n",
       "      <td>3.324</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.426</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68</td>\n",
       "      <td>3.293</td>\n",
       "      <td>3.315</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.426</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69</td>\n",
       "      <td>3.289</td>\n",
       "      <td>3.312</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.427</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>3.285</td>\n",
       "      <td>3.307</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.428</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>71</td>\n",
       "      <td>3.281</td>\n",
       "      <td>3.303</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.428</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72</td>\n",
       "      <td>3.276</td>\n",
       "      <td>3.320</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.430</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>73</td>\n",
       "      <td>3.284</td>\n",
       "      <td>3.294</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.430</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>74</td>\n",
       "      <td>3.265</td>\n",
       "      <td>3.289</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.431</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>3.263</td>\n",
       "      <td>3.284</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.431</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>76</td>\n",
       "      <td>3.267</td>\n",
       "      <td>3.313</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.432</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>77</td>\n",
       "      <td>3.260</td>\n",
       "      <td>3.275</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.432</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78</td>\n",
       "      <td>3.242</td>\n",
       "      <td>3.267</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.432</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>79</td>\n",
       "      <td>3.238</td>\n",
       "      <td>3.284</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.433</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>3.237</td>\n",
       "      <td>3.255</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.432</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>81</td>\n",
       "      <td>3.228</td>\n",
       "      <td>3.247</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.433</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>82</td>\n",
       "      <td>3.221</td>\n",
       "      <td>3.241</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.434</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>83</td>\n",
       "      <td>3.217</td>\n",
       "      <td>3.251</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.434</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>84</td>\n",
       "      <td>3.214</td>\n",
       "      <td>3.220</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.434</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85</td>\n",
       "      <td>3.219</td>\n",
       "      <td>3.227</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.435</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>86</td>\n",
       "      <td>3.183</td>\n",
       "      <td>3.220</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.435</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>87</td>\n",
       "      <td>3.210</td>\n",
       "      <td>3.205</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.436</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>88</td>\n",
       "      <td>3.182</td>\n",
       "      <td>3.220</td>\n",
       "      <td>0.994</td>\n",
       "      <td>0.436</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>89</td>\n",
       "      <td>3.170</td>\n",
       "      <td>3.186</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.436</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>3.152</td>\n",
       "      <td>3.176</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.437</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>91</td>\n",
       "      <td>3.137</td>\n",
       "      <td>3.176</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.438</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>92</td>\n",
       "      <td>3.147</td>\n",
       "      <td>3.145</td>\n",
       "      <td>0.997</td>\n",
       "      <td>0.437</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>93</td>\n",
       "      <td>3.106</td>\n",
       "      <td>3.137</td>\n",
       "      <td>0.971</td>\n",
       "      <td>0.438</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>94</td>\n",
       "      <td>3.098</td>\n",
       "      <td>3.127</td>\n",
       "      <td>0.932</td>\n",
       "      <td>0.439</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95</td>\n",
       "      <td>3.114</td>\n",
       "      <td>3.187</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.438</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>3.075</td>\n",
       "      <td>3.144</td>\n",
       "      <td>0.777</td>\n",
       "      <td>0.439</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>97</td>\n",
       "      <td>3.086</td>\n",
       "      <td>3.144</td>\n",
       "      <td>0.758</td>\n",
       "      <td>0.439</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98</td>\n",
       "      <td>3.098</td>\n",
       "      <td>3.116</td>\n",
       "      <td>0.857</td>\n",
       "      <td>0.440</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>99</td>\n",
       "      <td>3.076</td>\n",
       "      <td>3.117</td>\n",
       "      <td>0.971</td>\n",
       "      <td>0.440</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>3.069</td>\n",
       "      <td>3.109</td>\n",
       "      <td>0.864</td>\n",
       "      <td>0.440</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>101</td>\n",
       "      <td>3.059</td>\n",
       "      <td>3.128</td>\n",
       "      <td>0.760</td>\n",
       "      <td>0.441</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>102</td>\n",
       "      <td>3.064</td>\n",
       "      <td>3.107</td>\n",
       "      <td>0.814</td>\n",
       "      <td>0.441</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>103</td>\n",
       "      <td>3.071</td>\n",
       "      <td>3.114</td>\n",
       "      <td>0.964</td>\n",
       "      <td>0.441</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>104</td>\n",
       "      <td>3.053</td>\n",
       "      <td>3.240</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.441</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>105</td>\n",
       "      <td>3.099</td>\n",
       "      <td>3.187</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.442</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>106</td>\n",
       "      <td>3.111</td>\n",
       "      <td>3.094</td>\n",
       "      <td>0.919</td>\n",
       "      <td>0.443</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>107</td>\n",
       "      <td>3.087</td>\n",
       "      <td>3.106</td>\n",
       "      <td>0.806</td>\n",
       "      <td>0.443</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>108</td>\n",
       "      <td>3.116</td>\n",
       "      <td>3.307</td>\n",
       "      <td>0.682</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>109</td>\n",
       "      <td>3.127</td>\n",
       "      <td>3.120</td>\n",
       "      <td>0.774</td>\n",
       "      <td>0.443</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>3.050</td>\n",
       "      <td>3.082</td>\n",
       "      <td>0.929</td>\n",
       "      <td>0.443</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>111</td>\n",
       "      <td>3.047</td>\n",
       "      <td>3.233</td>\n",
       "      <td>0.695</td>\n",
       "      <td>0.443</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>112</td>\n",
       "      <td>3.094</td>\n",
       "      <td>3.106</td>\n",
       "      <td>0.775</td>\n",
       "      <td>0.443</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>113</td>\n",
       "      <td>3.029</td>\n",
       "      <td>3.175</td>\n",
       "      <td>0.989</td>\n",
       "      <td>0.442</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>114</td>\n",
       "      <td>3.059</td>\n",
       "      <td>3.082</td>\n",
       "      <td>0.814</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>115</td>\n",
       "      <td>3.049</td>\n",
       "      <td>3.137</td>\n",
       "      <td>0.983</td>\n",
       "      <td>0.443</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>116</td>\n",
       "      <td>3.112</td>\n",
       "      <td>3.073</td>\n",
       "      <td>0.980</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>117</td>\n",
       "      <td>3.031</td>\n",
       "      <td>3.079</td>\n",
       "      <td>0.840</td>\n",
       "      <td>0.445</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>118</td>\n",
       "      <td>3.046</td>\n",
       "      <td>3.170</td>\n",
       "      <td>0.701</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>119</td>\n",
       "      <td>3.045</td>\n",
       "      <td>3.093</td>\n",
       "      <td>0.758</td>\n",
       "      <td>0.445</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>3.027</td>\n",
       "      <td>3.087</td>\n",
       "      <td>0.798</td>\n",
       "      <td>0.443</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>121</td>\n",
       "      <td>3.023</td>\n",
       "      <td>3.097</td>\n",
       "      <td>0.760</td>\n",
       "      <td>0.445</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>122</td>\n",
       "      <td>3.052</td>\n",
       "      <td>3.079</td>\n",
       "      <td>0.809</td>\n",
       "      <td>0.445</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>123</td>\n",
       "      <td>3.020</td>\n",
       "      <td>3.086</td>\n",
       "      <td>0.781</td>\n",
       "      <td>0.445</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>124</td>\n",
       "      <td>3.023</td>\n",
       "      <td>3.070</td>\n",
       "      <td>0.811</td>\n",
       "      <td>0.445</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>3.018</td>\n",
       "      <td>3.061</td>\n",
       "      <td>0.853</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>126</td>\n",
       "      <td>3.026</td>\n",
       "      <td>3.068</td>\n",
       "      <td>0.916</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>127</td>\n",
       "      <td>3.053</td>\n",
       "      <td>3.061</td>\n",
       "      <td>0.899</td>\n",
       "      <td>0.445</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>128</td>\n",
       "      <td>3.022</td>\n",
       "      <td>3.082</td>\n",
       "      <td>0.946</td>\n",
       "      <td>0.443</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>129</td>\n",
       "      <td>3.018</td>\n",
       "      <td>3.095</td>\n",
       "      <td>0.747</td>\n",
       "      <td>0.446</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>3.128</td>\n",
       "      <td>3.081</td>\n",
       "      <td>0.878</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>131</td>\n",
       "      <td>3.059</td>\n",
       "      <td>3.129</td>\n",
       "      <td>0.972</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>132</td>\n",
       "      <td>3.104</td>\n",
       "      <td>3.136</td>\n",
       "      <td>0.761</td>\n",
       "      <td>0.447</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>133</td>\n",
       "      <td>3.095</td>\n",
       "      <td>3.064</td>\n",
       "      <td>0.870</td>\n",
       "      <td>0.447</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>134</td>\n",
       "      <td>3.019</td>\n",
       "      <td>3.059</td>\n",
       "      <td>0.856</td>\n",
       "      <td>0.446</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>135</td>\n",
       "      <td>3.043</td>\n",
       "      <td>3.151</td>\n",
       "      <td>0.995</td>\n",
       "      <td>0.447</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>136</td>\n",
       "      <td>3.054</td>\n",
       "      <td>3.221</td>\n",
       "      <td>0.687</td>\n",
       "      <td>0.447</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>137</td>\n",
       "      <td>3.029</td>\n",
       "      <td>3.056</td>\n",
       "      <td>0.840</td>\n",
       "      <td>0.447</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>138</td>\n",
       "      <td>3.041</td>\n",
       "      <td>3.170</td>\n",
       "      <td>0.693</td>\n",
       "      <td>0.447</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>139</td>\n",
       "      <td>3.113</td>\n",
       "      <td>3.077</td>\n",
       "      <td>0.995</td>\n",
       "      <td>0.448</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>3.041</td>\n",
       "      <td>3.080</td>\n",
       "      <td>0.961</td>\n",
       "      <td>0.448</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>141</td>\n",
       "      <td>3.033</td>\n",
       "      <td>3.056</td>\n",
       "      <td>0.853</td>\n",
       "      <td>0.447</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>142</td>\n",
       "      <td>3.015</td>\n",
       "      <td>3.165</td>\n",
       "      <td>0.695</td>\n",
       "      <td>0.447</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>143</td>\n",
       "      <td>3.044</td>\n",
       "      <td>3.053</td>\n",
       "      <td>0.859</td>\n",
       "      <td>0.448</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>144</td>\n",
       "      <td>3.047</td>\n",
       "      <td>3.070</td>\n",
       "      <td>0.798</td>\n",
       "      <td>0.448</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>145</td>\n",
       "      <td>3.019</td>\n",
       "      <td>3.229</td>\n",
       "      <td>0.994</td>\n",
       "      <td>0.445</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>146</td>\n",
       "      <td>3.070</td>\n",
       "      <td>3.094</td>\n",
       "      <td>0.873</td>\n",
       "      <td>0.447</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>147</td>\n",
       "      <td>3.011</td>\n",
       "      <td>3.054</td>\n",
       "      <td>0.836</td>\n",
       "      <td>0.447</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>148</td>\n",
       "      <td>3.022</td>\n",
       "      <td>3.094</td>\n",
       "      <td>0.755</td>\n",
       "      <td>0.447</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>149</td>\n",
       "      <td>3.018</td>\n",
       "      <td>3.092</td>\n",
       "      <td>0.749</td>\n",
       "      <td>0.447</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>3.019</td>\n",
       "      <td>3.122</td>\n",
       "      <td>0.710</td>\n",
       "      <td>0.448</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>151</td>\n",
       "      <td>3.047</td>\n",
       "      <td>3.102</td>\n",
       "      <td>0.760</td>\n",
       "      <td>0.448</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>152</td>\n",
       "      <td>3.005</td>\n",
       "      <td>3.058</td>\n",
       "      <td>0.797</td>\n",
       "      <td>0.448</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>153</td>\n",
       "      <td>3.027</td>\n",
       "      <td>3.050</td>\n",
       "      <td>0.868</td>\n",
       "      <td>0.447</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>154</td>\n",
       "      <td>3.065</td>\n",
       "      <td>3.084</td>\n",
       "      <td>0.946</td>\n",
       "      <td>0.447</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>155</td>\n",
       "      <td>3.011</td>\n",
       "      <td>3.047</td>\n",
       "      <td>0.842</td>\n",
       "      <td>0.447</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>156</td>\n",
       "      <td>3.036</td>\n",
       "      <td>3.097</td>\n",
       "      <td>0.992</td>\n",
       "      <td>0.448</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>157</td>\n",
       "      <td>3.027</td>\n",
       "      <td>3.073</td>\n",
       "      <td>0.831</td>\n",
       "      <td>0.448</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>158</td>\n",
       "      <td>3.036</td>\n",
       "      <td>3.054</td>\n",
       "      <td>0.856</td>\n",
       "      <td>0.448</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>159</td>\n",
       "      <td>3.093</td>\n",
       "      <td>3.063</td>\n",
       "      <td>0.788</td>\n",
       "      <td>0.447</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>3.028</td>\n",
       "      <td>3.316</td>\n",
       "      <td>0.997</td>\n",
       "      <td>0.448</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>161</td>\n",
       "      <td>3.111</td>\n",
       "      <td>3.306</td>\n",
       "      <td>0.659</td>\n",
       "      <td>0.449</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>162</td>\n",
       "      <td>3.042</td>\n",
       "      <td>3.051</td>\n",
       "      <td>0.836</td>\n",
       "      <td>0.448</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>163</td>\n",
       "      <td>3.038</td>\n",
       "      <td>3.138</td>\n",
       "      <td>0.736</td>\n",
       "      <td>0.448</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>164</td>\n",
       "      <td>3.058</td>\n",
       "      <td>3.121</td>\n",
       "      <td>0.975</td>\n",
       "      <td>0.447</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>165</td>\n",
       "      <td>3.007</td>\n",
       "      <td>3.112</td>\n",
       "      <td>0.760</td>\n",
       "      <td>0.448</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>166</td>\n",
       "      <td>3.057</td>\n",
       "      <td>3.072</td>\n",
       "      <td>0.823</td>\n",
       "      <td>0.448</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>167</td>\n",
       "      <td>3.022</td>\n",
       "      <td>3.104</td>\n",
       "      <td>0.713</td>\n",
       "      <td>0.448</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>168</td>\n",
       "      <td>3.011</td>\n",
       "      <td>3.068</td>\n",
       "      <td>0.981</td>\n",
       "      <td>0.447</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>169</td>\n",
       "      <td>3.002</td>\n",
       "      <td>3.195</td>\n",
       "      <td>0.696</td>\n",
       "      <td>0.449</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>3.028</td>\n",
       "      <td>3.057</td>\n",
       "      <td>0.887</td>\n",
       "      <td>0.449</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>171</td>\n",
       "      <td>3.002</td>\n",
       "      <td>3.150</td>\n",
       "      <td>0.687</td>\n",
       "      <td>0.448</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>172</td>\n",
       "      <td>3.022</td>\n",
       "      <td>3.045</td>\n",
       "      <td>0.833</td>\n",
       "      <td>0.448</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>173</td>\n",
       "      <td>3.079</td>\n",
       "      <td>3.079</td>\n",
       "      <td>0.935</td>\n",
       "      <td>0.448</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>174</td>\n",
       "      <td>3.060</td>\n",
       "      <td>3.081</td>\n",
       "      <td>0.977</td>\n",
       "      <td>0.450</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>3.072</td>\n",
       "      <td>3.089</td>\n",
       "      <td>0.820</td>\n",
       "      <td>0.450</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>176</td>\n",
       "      <td>3.026</td>\n",
       "      <td>3.037</td>\n",
       "      <td>0.848</td>\n",
       "      <td>0.450</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>177</td>\n",
       "      <td>3.026</td>\n",
       "      <td>3.044</td>\n",
       "      <td>0.881</td>\n",
       "      <td>0.450</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>178</td>\n",
       "      <td>3.011</td>\n",
       "      <td>3.073</td>\n",
       "      <td>0.955</td>\n",
       "      <td>0.448</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>179</td>\n",
       "      <td>3.022</td>\n",
       "      <td>3.059</td>\n",
       "      <td>0.791</td>\n",
       "      <td>0.449</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>3.014</td>\n",
       "      <td>3.058</td>\n",
       "      <td>0.819</td>\n",
       "      <td>0.449</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>181</td>\n",
       "      <td>3.017</td>\n",
       "      <td>3.061</td>\n",
       "      <td>0.958</td>\n",
       "      <td>0.449</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>182</td>\n",
       "      <td>3.104</td>\n",
       "      <td>3.220</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.450</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>183</td>\n",
       "      <td>3.199</td>\n",
       "      <td>3.141</td>\n",
       "      <td>0.981</td>\n",
       "      <td>0.449</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>184</td>\n",
       "      <td>3.064</td>\n",
       "      <td>3.070</td>\n",
       "      <td>0.955</td>\n",
       "      <td>0.448</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>185</td>\n",
       "      <td>3.067</td>\n",
       "      <td>3.055</td>\n",
       "      <td>0.816</td>\n",
       "      <td>0.448</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>186</td>\n",
       "      <td>3.016</td>\n",
       "      <td>3.046</td>\n",
       "      <td>0.890</td>\n",
       "      <td>0.449</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>187</td>\n",
       "      <td>3.020</td>\n",
       "      <td>3.096</td>\n",
       "      <td>0.848</td>\n",
       "      <td>0.448</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>188</td>\n",
       "      <td>3.068</td>\n",
       "      <td>3.142</td>\n",
       "      <td>0.995</td>\n",
       "      <td>0.447</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>189</td>\n",
       "      <td>3.089</td>\n",
       "      <td>3.067</td>\n",
       "      <td>0.995</td>\n",
       "      <td>0.448</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>3.015</td>\n",
       "      <td>3.214</td>\n",
       "      <td>0.653</td>\n",
       "      <td>0.449</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>191</td>\n",
       "      <td>3.058</td>\n",
       "      <td>3.049</td>\n",
       "      <td>0.890</td>\n",
       "      <td>0.448</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>192</td>\n",
       "      <td>3.122</td>\n",
       "      <td>3.079</td>\n",
       "      <td>0.718</td>\n",
       "      <td>0.448</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>193</td>\n",
       "      <td>3.034</td>\n",
       "      <td>3.050</td>\n",
       "      <td>0.848</td>\n",
       "      <td>0.448</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>194</td>\n",
       "      <td>3.025</td>\n",
       "      <td>3.109</td>\n",
       "      <td>0.997</td>\n",
       "      <td>0.449</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>195</td>\n",
       "      <td>3.024</td>\n",
       "      <td>3.041</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.449</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>196</td>\n",
       "      <td>3.060</td>\n",
       "      <td>3.088</td>\n",
       "      <td>0.981</td>\n",
       "      <td>0.450</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>197</td>\n",
       "      <td>3.016</td>\n",
       "      <td>3.081</td>\n",
       "      <td>0.953</td>\n",
       "      <td>0.450</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>198</td>\n",
       "      <td>3.023</td>\n",
       "      <td>3.096</td>\n",
       "      <td>0.794</td>\n",
       "      <td>0.449</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>199</td>\n",
       "      <td>3.024</td>\n",
       "      <td>3.076</td>\n",
       "      <td>0.957</td>\n",
       "      <td>0.450</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>3.013</td>\n",
       "      <td>3.073</td>\n",
       "      <td>0.814</td>\n",
       "      <td>0.449</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>201</td>\n",
       "      <td>3.042</td>\n",
       "      <td>3.042</td>\n",
       "      <td>0.986</td>\n",
       "      <td>0.450</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>202</td>\n",
       "      <td>3.005</td>\n",
       "      <td>3.050</td>\n",
       "      <td>0.820</td>\n",
       "      <td>0.450</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>203</td>\n",
       "      <td>3.010</td>\n",
       "      <td>3.035</td>\n",
       "      <td>0.961</td>\n",
       "      <td>0.450</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>204</td>\n",
       "      <td>3.002</td>\n",
       "      <td>3.050</td>\n",
       "      <td>0.823</td>\n",
       "      <td>0.450</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>205</td>\n",
       "      <td>3.000</td>\n",
       "      <td>3.032</td>\n",
       "      <td>0.879</td>\n",
       "      <td>0.450</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>206</td>\n",
       "      <td>3.010</td>\n",
       "      <td>3.033</td>\n",
       "      <td>0.921</td>\n",
       "      <td>0.450</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>207</td>\n",
       "      <td>3.000</td>\n",
       "      <td>3.087</td>\n",
       "      <td>0.941</td>\n",
       "      <td>0.451</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>208</td>\n",
       "      <td>3.048</td>\n",
       "      <td>3.039</td>\n",
       "      <td>0.837</td>\n",
       "      <td>0.451</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>209</td>\n",
       "      <td>3.035</td>\n",
       "      <td>3.045</td>\n",
       "      <td>0.924</td>\n",
       "      <td>0.451</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>3.026</td>\n",
       "      <td>3.061</td>\n",
       "      <td>0.997</td>\n",
       "      <td>0.450</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>211</td>\n",
       "      <td>3.004</td>\n",
       "      <td>3.039</td>\n",
       "      <td>0.887</td>\n",
       "      <td>0.449</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>212</td>\n",
       "      <td>3.031</td>\n",
       "      <td>3.050</td>\n",
       "      <td>0.944</td>\n",
       "      <td>0.451</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>213</td>\n",
       "      <td>3.028</td>\n",
       "      <td>3.058</td>\n",
       "      <td>0.988</td>\n",
       "      <td>0.451</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>214</td>\n",
       "      <td>3.000</td>\n",
       "      <td>3.072</td>\n",
       "      <td>0.733</td>\n",
       "      <td>0.450</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>215</td>\n",
       "      <td>3.000</td>\n",
       "      <td>3.034</td>\n",
       "      <td>0.881</td>\n",
       "      <td>0.449</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>216</td>\n",
       "      <td>2.993</td>\n",
       "      <td>3.032</td>\n",
       "      <td>0.940</td>\n",
       "      <td>0.450</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>217</td>\n",
       "      <td>3.002</td>\n",
       "      <td>3.051</td>\n",
       "      <td>0.828</td>\n",
       "      <td>0.449</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>218</td>\n",
       "      <td>3.017</td>\n",
       "      <td>3.136</td>\n",
       "      <td>0.687</td>\n",
       "      <td>0.452</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>219</td>\n",
       "      <td>3.025</td>\n",
       "      <td>3.125</td>\n",
       "      <td>0.685</td>\n",
       "      <td>0.450</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>3.000</td>\n",
       "      <td>3.038</td>\n",
       "      <td>0.969</td>\n",
       "      <td>0.451</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>221</td>\n",
       "      <td>3.011</td>\n",
       "      <td>3.031</td>\n",
       "      <td>0.890</td>\n",
       "      <td>0.451</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>222</td>\n",
       "      <td>3.016</td>\n",
       "      <td>3.109</td>\n",
       "      <td>0.814</td>\n",
       "      <td>0.451</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>223</td>\n",
       "      <td>3.009</td>\n",
       "      <td>3.156</td>\n",
       "      <td>0.949</td>\n",
       "      <td>0.451</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>224</td>\n",
       "      <td>3.008</td>\n",
       "      <td>3.069</td>\n",
       "      <td>0.909</td>\n",
       "      <td>0.450</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>3.021</td>\n",
       "      <td>3.094</td>\n",
       "      <td>0.952</td>\n",
       "      <td>0.449</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>226</td>\n",
       "      <td>3.024</td>\n",
       "      <td>3.061</td>\n",
       "      <td>0.943</td>\n",
       "      <td>0.449</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>227</td>\n",
       "      <td>3.028</td>\n",
       "      <td>3.105</td>\n",
       "      <td>0.992</td>\n",
       "      <td>0.450</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>228</td>\n",
       "      <td>3.026</td>\n",
       "      <td>3.061</td>\n",
       "      <td>0.924</td>\n",
       "      <td>0.450</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>229</td>\n",
       "      <td>3.052</td>\n",
       "      <td>3.191</td>\n",
       "      <td>0.726</td>\n",
       "      <td>0.449</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>3.047</td>\n",
       "      <td>3.136</td>\n",
       "      <td>0.857</td>\n",
       "      <td>0.449</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>231</td>\n",
       "      <td>3.002</td>\n",
       "      <td>3.144</td>\n",
       "      <td>0.679</td>\n",
       "      <td>0.450</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>232</td>\n",
       "      <td>3.017</td>\n",
       "      <td>3.044</td>\n",
       "      <td>0.919</td>\n",
       "      <td>0.451</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>233</td>\n",
       "      <td>3.025</td>\n",
       "      <td>3.059</td>\n",
       "      <td>0.919</td>\n",
       "      <td>0.447</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>234</td>\n",
       "      <td>2.999</td>\n",
       "      <td>3.178</td>\n",
       "      <td>0.972</td>\n",
       "      <td>0.450</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>235</td>\n",
       "      <td>3.054</td>\n",
       "      <td>3.043</td>\n",
       "      <td>0.896</td>\n",
       "      <td>0.452</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>236</td>\n",
       "      <td>3.035</td>\n",
       "      <td>3.123</td>\n",
       "      <td>0.961</td>\n",
       "      <td>0.448</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>237</td>\n",
       "      <td>3.034</td>\n",
       "      <td>3.103</td>\n",
       "      <td>0.791</td>\n",
       "      <td>0.449</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>238</td>\n",
       "      <td>3.043</td>\n",
       "      <td>3.084</td>\n",
       "      <td>0.727</td>\n",
       "      <td>0.450</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>239</td>\n",
       "      <td>3.003</td>\n",
       "      <td>3.036</td>\n",
       "      <td>0.848</td>\n",
       "      <td>0.449</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>3.049</td>\n",
       "      <td>3.084</td>\n",
       "      <td>0.950</td>\n",
       "      <td>0.449</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>241</td>\n",
       "      <td>3.002</td>\n",
       "      <td>3.054</td>\n",
       "      <td>0.860</td>\n",
       "      <td>0.450</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>242</td>\n",
       "      <td>3.006</td>\n",
       "      <td>3.131</td>\n",
       "      <td>0.794</td>\n",
       "      <td>0.450</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>243</td>\n",
       "      <td>3.096</td>\n",
       "      <td>3.098</td>\n",
       "      <td>0.792</td>\n",
       "      <td>0.449</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>244</td>\n",
       "      <td>3.016</td>\n",
       "      <td>3.055</td>\n",
       "      <td>0.828</td>\n",
       "      <td>0.451</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>245</td>\n",
       "      <td>3.043</td>\n",
       "      <td>3.130</td>\n",
       "      <td>0.851</td>\n",
       "      <td>0.451</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>246</td>\n",
       "      <td>3.041</td>\n",
       "      <td>3.208</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.449</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>247</td>\n",
       "      <td>3.023</td>\n",
       "      <td>3.227</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.450</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>248</td>\n",
       "      <td>3.032</td>\n",
       "      <td>3.046</td>\n",
       "      <td>0.767</td>\n",
       "      <td>0.450</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>249</td>\n",
       "      <td>2.998</td>\n",
       "      <td>3.029</td>\n",
       "      <td>0.899</td>\n",
       "      <td>0.450</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>3.025</td>\n",
       "      <td>3.062</td>\n",
       "      <td>0.957</td>\n",
       "      <td>0.453</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>251</td>\n",
       "      <td>2.994</td>\n",
       "      <td>3.055</td>\n",
       "      <td>0.794</td>\n",
       "      <td>0.450</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>252</td>\n",
       "      <td>3.030</td>\n",
       "      <td>3.032</td>\n",
       "      <td>0.955</td>\n",
       "      <td>0.450</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>253</td>\n",
       "      <td>3.060</td>\n",
       "      <td>3.133</td>\n",
       "      <td>0.986</td>\n",
       "      <td>0.450</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>254</td>\n",
       "      <td>3.041</td>\n",
       "      <td>3.044</td>\n",
       "      <td>0.850</td>\n",
       "      <td>0.451</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>255</td>\n",
       "      <td>3.017</td>\n",
       "      <td>3.029</td>\n",
       "      <td>0.947</td>\n",
       "      <td>0.451</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>256</td>\n",
       "      <td>3.037</td>\n",
       "      <td>3.031</td>\n",
       "      <td>0.949</td>\n",
       "      <td>0.450</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>257</td>\n",
       "      <td>2.995</td>\n",
       "      <td>3.085</td>\n",
       "      <td>0.967</td>\n",
       "      <td>0.450</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>258</td>\n",
       "      <td>3.008</td>\n",
       "      <td>3.067</td>\n",
       "      <td>0.719</td>\n",
       "      <td>0.449</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>259</td>\n",
       "      <td>2.994</td>\n",
       "      <td>3.054</td>\n",
       "      <td>0.828</td>\n",
       "      <td>0.451</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>2.993</td>\n",
       "      <td>3.032</td>\n",
       "      <td>0.887</td>\n",
       "      <td>0.451</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>261</td>\n",
       "      <td>3.006</td>\n",
       "      <td>3.028</td>\n",
       "      <td>0.873</td>\n",
       "      <td>0.451</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>262</td>\n",
       "      <td>2.993</td>\n",
       "      <td>3.052</td>\n",
       "      <td>0.771</td>\n",
       "      <td>0.450</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>263</td>\n",
       "      <td>3.029</td>\n",
       "      <td>3.152</td>\n",
       "      <td>0.696</td>\n",
       "      <td>0.450</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>264</td>\n",
       "      <td>3.044</td>\n",
       "      <td>3.045</td>\n",
       "      <td>0.828</td>\n",
       "      <td>0.451</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>265</td>\n",
       "      <td>3.027</td>\n",
       "      <td>3.067</td>\n",
       "      <td>0.984</td>\n",
       "      <td>0.450</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>266</td>\n",
       "      <td>3.018</td>\n",
       "      <td>3.045</td>\n",
       "      <td>0.927</td>\n",
       "      <td>0.451</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>267</td>\n",
       "      <td>3.050</td>\n",
       "      <td>3.041</td>\n",
       "      <td>0.899</td>\n",
       "      <td>0.453</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>268</td>\n",
       "      <td>3.054</td>\n",
       "      <td>3.211</td>\n",
       "      <td>0.668</td>\n",
       "      <td>0.451</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>269</td>\n",
       "      <td>3.022</td>\n",
       "      <td>3.022</td>\n",
       "      <td>0.918</td>\n",
       "      <td>0.451</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>3.017</td>\n",
       "      <td>3.058</td>\n",
       "      <td>0.967</td>\n",
       "      <td>0.449</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>271</td>\n",
       "      <td>3.013</td>\n",
       "      <td>3.070</td>\n",
       "      <td>0.994</td>\n",
       "      <td>0.450</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>272</td>\n",
       "      <td>3.014</td>\n",
       "      <td>3.171</td>\n",
       "      <td>0.696</td>\n",
       "      <td>0.451</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>273</td>\n",
       "      <td>3.052</td>\n",
       "      <td>3.085</td>\n",
       "      <td>0.774</td>\n",
       "      <td>0.450</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>274</td>\n",
       "      <td>2.997</td>\n",
       "      <td>3.061</td>\n",
       "      <td>0.957</td>\n",
       "      <td>0.450</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>3.027</td>\n",
       "      <td>3.270</td>\n",
       "      <td>0.678</td>\n",
       "      <td>0.450</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>276</td>\n",
       "      <td>3.019</td>\n",
       "      <td>3.177</td>\n",
       "      <td>0.994</td>\n",
       "      <td>0.451</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>277</td>\n",
       "      <td>3.036</td>\n",
       "      <td>3.137</td>\n",
       "      <td>0.695</td>\n",
       "      <td>0.449</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>278</td>\n",
       "      <td>3.047</td>\n",
       "      <td>3.033</td>\n",
       "      <td>0.947</td>\n",
       "      <td>0.451</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>279</td>\n",
       "      <td>3.034</td>\n",
       "      <td>3.062</td>\n",
       "      <td>0.907</td>\n",
       "      <td>0.449</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>2.999</td>\n",
       "      <td>3.065</td>\n",
       "      <td>0.941</td>\n",
       "      <td>0.449</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>281</td>\n",
       "      <td>2.989</td>\n",
       "      <td>3.174</td>\n",
       "      <td>0.994</td>\n",
       "      <td>0.442</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>282</td>\n",
       "      <td>3.017</td>\n",
       "      <td>3.180</td>\n",
       "      <td>0.961</td>\n",
       "      <td>0.449</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>283</td>\n",
       "      <td>3.017</td>\n",
       "      <td>3.056</td>\n",
       "      <td>0.992</td>\n",
       "      <td>0.450</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>284</td>\n",
       "      <td>3.003</td>\n",
       "      <td>3.087</td>\n",
       "      <td>0.802</td>\n",
       "      <td>0.451</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>285</td>\n",
       "      <td>3.012</td>\n",
       "      <td>3.045</td>\n",
       "      <td>0.860</td>\n",
       "      <td>0.451</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>286</td>\n",
       "      <td>2.999</td>\n",
       "      <td>3.120</td>\n",
       "      <td>0.684</td>\n",
       "      <td>0.450</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>287</td>\n",
       "      <td>3.058</td>\n",
       "      <td>3.091</td>\n",
       "      <td>0.969</td>\n",
       "      <td>0.448</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>288</td>\n",
       "      <td>3.022</td>\n",
       "      <td>3.236</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.451</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>289</td>\n",
       "      <td>3.002</td>\n",
       "      <td>3.033</td>\n",
       "      <td>0.926</td>\n",
       "      <td>0.453</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>2.984</td>\n",
       "      <td>3.109</td>\n",
       "      <td>0.989</td>\n",
       "      <td>0.449</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>291</td>\n",
       "      <td>3.007</td>\n",
       "      <td>3.070</td>\n",
       "      <td>0.763</td>\n",
       "      <td>0.450</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>292</td>\n",
       "      <td>2.995</td>\n",
       "      <td>3.079</td>\n",
       "      <td>0.722</td>\n",
       "      <td>0.448</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>293</td>\n",
       "      <td>3.010</td>\n",
       "      <td>3.078</td>\n",
       "      <td>0.767</td>\n",
       "      <td>0.451</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>294</td>\n",
       "      <td>3.006</td>\n",
       "      <td>3.063</td>\n",
       "      <td>0.933</td>\n",
       "      <td>0.450</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>295</td>\n",
       "      <td>3.052</td>\n",
       "      <td>3.080</td>\n",
       "      <td>0.944</td>\n",
       "      <td>0.450</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>296</td>\n",
       "      <td>3.082</td>\n",
       "      <td>3.094</td>\n",
       "      <td>0.983</td>\n",
       "      <td>0.449</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>297</td>\n",
       "      <td>3.026</td>\n",
       "      <td>3.043</td>\n",
       "      <td>0.933</td>\n",
       "      <td>0.450</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>298</td>\n",
       "      <td>2.998</td>\n",
       "      <td>3.051</td>\n",
       "      <td>0.780</td>\n",
       "      <td>0.450</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>299</td>\n",
       "      <td>3.001</td>\n",
       "      <td>3.083</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.451</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>3.025</td>\n",
       "      <td>3.116</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.450</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>301</td>\n",
       "      <td>3.055</td>\n",
       "      <td>3.041</td>\n",
       "      <td>0.975</td>\n",
       "      <td>0.450</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>302</td>\n",
       "      <td>2.999</td>\n",
       "      <td>3.030</td>\n",
       "      <td>0.868</td>\n",
       "      <td>0.452</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>303</td>\n",
       "      <td>3.035</td>\n",
       "      <td>3.067</td>\n",
       "      <td>0.949</td>\n",
       "      <td>0.451</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>304</td>\n",
       "      <td>2.990</td>\n",
       "      <td>3.070</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.451</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>305</td>\n",
       "      <td>3.012</td>\n",
       "      <td>3.029</td>\n",
       "      <td>0.946</td>\n",
       "      <td>0.452</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>306</td>\n",
       "      <td>3.004</td>\n",
       "      <td>3.074</td>\n",
       "      <td>0.826</td>\n",
       "      <td>0.452</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>307</td>\n",
       "      <td>2.992</td>\n",
       "      <td>3.050</td>\n",
       "      <td>0.853</td>\n",
       "      <td>0.453</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>308</td>\n",
       "      <td>3.005</td>\n",
       "      <td>3.041</td>\n",
       "      <td>0.854</td>\n",
       "      <td>0.449</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>309</td>\n",
       "      <td>2.984</td>\n",
       "      <td>3.027</td>\n",
       "      <td>0.847</td>\n",
       "      <td>0.450</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>2.992</td>\n",
       "      <td>3.030</td>\n",
       "      <td>0.842</td>\n",
       "      <td>0.450</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>311</td>\n",
       "      <td>3.015</td>\n",
       "      <td>3.049</td>\n",
       "      <td>0.947</td>\n",
       "      <td>0.449</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>312</td>\n",
       "      <td>3.006</td>\n",
       "      <td>3.042</td>\n",
       "      <td>0.946</td>\n",
       "      <td>0.451</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>313</td>\n",
       "      <td>2.987</td>\n",
       "      <td>3.075</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.445</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>314</td>\n",
       "      <td>3.000</td>\n",
       "      <td>3.094</td>\n",
       "      <td>0.736</td>\n",
       "      <td>0.450</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>315</td>\n",
       "      <td>3.035</td>\n",
       "      <td>3.279</td>\n",
       "      <td>0.626</td>\n",
       "      <td>0.449</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>316</td>\n",
       "      <td>3.041</td>\n",
       "      <td>3.035</td>\n",
       "      <td>0.946</td>\n",
       "      <td>0.447</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>317</td>\n",
       "      <td>3.031</td>\n",
       "      <td>3.105</td>\n",
       "      <td>0.994</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>318</td>\n",
       "      <td>3.027</td>\n",
       "      <td>3.055</td>\n",
       "      <td>0.949</td>\n",
       "      <td>0.447</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>319</td>\n",
       "      <td>3.013</td>\n",
       "      <td>3.072</td>\n",
       "      <td>0.803</td>\n",
       "      <td>0.450</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>2.995</td>\n",
       "      <td>3.191</td>\n",
       "      <td>0.960</td>\n",
       "      <td>0.448</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>321</td>\n",
       "      <td>2.996</td>\n",
       "      <td>3.118</td>\n",
       "      <td>0.688</td>\n",
       "      <td>0.450</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>322</td>\n",
       "      <td>2.995</td>\n",
       "      <td>3.073</td>\n",
       "      <td>0.760</td>\n",
       "      <td>0.449</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>323</td>\n",
       "      <td>3.039</td>\n",
       "      <td>3.049</td>\n",
       "      <td>0.879</td>\n",
       "      <td>0.449</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>324</td>\n",
       "      <td>2.999</td>\n",
       "      <td>3.028</td>\n",
       "      <td>0.868</td>\n",
       "      <td>0.450</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325</td>\n",
       "      <td>3.014</td>\n",
       "      <td>3.050</td>\n",
       "      <td>0.834</td>\n",
       "      <td>0.447</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>326</td>\n",
       "      <td>2.991</td>\n",
       "      <td>3.039</td>\n",
       "      <td>0.808</td>\n",
       "      <td>0.449</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>327</td>\n",
       "      <td>3.012</td>\n",
       "      <td>3.064</td>\n",
       "      <td>0.983</td>\n",
       "      <td>0.449</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>328</td>\n",
       "      <td>3.011</td>\n",
       "      <td>3.032</td>\n",
       "      <td>0.842</td>\n",
       "      <td>0.448</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>329</td>\n",
       "      <td>3.004</td>\n",
       "      <td>3.024</td>\n",
       "      <td>0.876</td>\n",
       "      <td>0.450</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>2.999</td>\n",
       "      <td>3.039</td>\n",
       "      <td>0.943</td>\n",
       "      <td>0.450</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>331</td>\n",
       "      <td>2.976</td>\n",
       "      <td>3.174</td>\n",
       "      <td>0.687</td>\n",
       "      <td>0.439</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>332</td>\n",
       "      <td>3.074</td>\n",
       "      <td>3.350</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.449</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>333</td>\n",
       "      <td>3.089</td>\n",
       "      <td>3.042</td>\n",
       "      <td>0.893</td>\n",
       "      <td>0.448</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>334</td>\n",
       "      <td>2.989</td>\n",
       "      <td>3.052</td>\n",
       "      <td>0.834</td>\n",
       "      <td>0.451</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>335</td>\n",
       "      <td>2.998</td>\n",
       "      <td>3.072</td>\n",
       "      <td>0.719</td>\n",
       "      <td>0.449</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>336</td>\n",
       "      <td>3.006</td>\n",
       "      <td>3.067</td>\n",
       "      <td>0.901</td>\n",
       "      <td>0.447</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>337</td>\n",
       "      <td>3.002</td>\n",
       "      <td>3.024</td>\n",
       "      <td>0.873</td>\n",
       "      <td>0.448</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>338</td>\n",
       "      <td>3.013</td>\n",
       "      <td>3.073</td>\n",
       "      <td>0.896</td>\n",
       "      <td>0.448</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>339</td>\n",
       "      <td>2.995</td>\n",
       "      <td>3.025</td>\n",
       "      <td>0.891</td>\n",
       "      <td>0.450</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>3.020</td>\n",
       "      <td>3.436</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.449</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>341</td>\n",
       "      <td>3.070</td>\n",
       "      <td>3.058</td>\n",
       "      <td>0.834</td>\n",
       "      <td>0.452</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>342</td>\n",
       "      <td>2.988</td>\n",
       "      <td>3.052</td>\n",
       "      <td>0.822</td>\n",
       "      <td>0.449</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>343</td>\n",
       "      <td>2.995</td>\n",
       "      <td>3.024</td>\n",
       "      <td>0.840</td>\n",
       "      <td>0.448</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>344</td>\n",
       "      <td>2.982</td>\n",
       "      <td>3.043</td>\n",
       "      <td>0.868</td>\n",
       "      <td>0.449</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>345</td>\n",
       "      <td>3.017</td>\n",
       "      <td>3.053</td>\n",
       "      <td>0.932</td>\n",
       "      <td>0.448</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>346</td>\n",
       "      <td>2.996</td>\n",
       "      <td>3.039</td>\n",
       "      <td>0.834</td>\n",
       "      <td>0.450</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>347</td>\n",
       "      <td>3.008</td>\n",
       "      <td>3.059</td>\n",
       "      <td>0.991</td>\n",
       "      <td>0.448</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>348</td>\n",
       "      <td>3.001</td>\n",
       "      <td>3.023</td>\n",
       "      <td>0.919</td>\n",
       "      <td>0.448</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>349</td>\n",
       "      <td>2.983</td>\n",
       "      <td>3.078</td>\n",
       "      <td>0.753</td>\n",
       "      <td>0.450</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>2.992</td>\n",
       "      <td>3.108</td>\n",
       "      <td>0.988</td>\n",
       "      <td>0.439</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>351</td>\n",
       "      <td>3.041</td>\n",
       "      <td>3.049</td>\n",
       "      <td>0.753</td>\n",
       "      <td>0.448</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>352</td>\n",
       "      <td>2.986</td>\n",
       "      <td>3.114</td>\n",
       "      <td>0.984</td>\n",
       "      <td>0.441</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>353</td>\n",
       "      <td>3.010</td>\n",
       "      <td>3.046</td>\n",
       "      <td>0.831</td>\n",
       "      <td>0.451</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>354</td>\n",
       "      <td>2.994</td>\n",
       "      <td>3.064</td>\n",
       "      <td>0.836</td>\n",
       "      <td>0.448</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>355</td>\n",
       "      <td>2.990</td>\n",
       "      <td>3.118</td>\n",
       "      <td>0.960</td>\n",
       "      <td>0.442</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>356</td>\n",
       "      <td>2.992</td>\n",
       "      <td>3.123</td>\n",
       "      <td>0.699</td>\n",
       "      <td>0.449</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>357</td>\n",
       "      <td>3.038</td>\n",
       "      <td>3.112</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.446</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>358</td>\n",
       "      <td>3.013</td>\n",
       "      <td>3.028</td>\n",
       "      <td>0.907</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>359</td>\n",
       "      <td>2.996</td>\n",
       "      <td>3.048</td>\n",
       "      <td>0.991</td>\n",
       "      <td>0.448</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>2.986</td>\n",
       "      <td>3.033</td>\n",
       "      <td>0.828</td>\n",
       "      <td>0.447</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>361</td>\n",
       "      <td>2.989</td>\n",
       "      <td>3.210</td>\n",
       "      <td>0.986</td>\n",
       "      <td>0.438</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>362</td>\n",
       "      <td>3.006</td>\n",
       "      <td>3.087</td>\n",
       "      <td>0.719</td>\n",
       "      <td>0.451</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>363</td>\n",
       "      <td>3.010</td>\n",
       "      <td>3.030</td>\n",
       "      <td>0.848</td>\n",
       "      <td>0.448</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>364</td>\n",
       "      <td>3.007</td>\n",
       "      <td>3.032</td>\n",
       "      <td>0.854</td>\n",
       "      <td>0.448</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>365</td>\n",
       "      <td>3.001</td>\n",
       "      <td>3.036</td>\n",
       "      <td>0.808</td>\n",
       "      <td>0.449</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>366</td>\n",
       "      <td>3.001</td>\n",
       "      <td>3.030</td>\n",
       "      <td>0.924</td>\n",
       "      <td>0.448</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>367</td>\n",
       "      <td>2.982</td>\n",
       "      <td>3.081</td>\n",
       "      <td>0.975</td>\n",
       "      <td>0.448</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>368</td>\n",
       "      <td>3.029</td>\n",
       "      <td>3.074</td>\n",
       "      <td>0.833</td>\n",
       "      <td>0.453</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>369</td>\n",
       "      <td>2.986</td>\n",
       "      <td>3.027</td>\n",
       "      <td>0.930</td>\n",
       "      <td>0.450</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>2.988</td>\n",
       "      <td>3.045</td>\n",
       "      <td>0.805</td>\n",
       "      <td>0.449</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>371</td>\n",
       "      <td>2.996</td>\n",
       "      <td>3.049</td>\n",
       "      <td>0.780</td>\n",
       "      <td>0.449</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>372</td>\n",
       "      <td>3.008</td>\n",
       "      <td>3.061</td>\n",
       "      <td>0.789</td>\n",
       "      <td>0.449</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>373</td>\n",
       "      <td>3.023</td>\n",
       "      <td>3.062</td>\n",
       "      <td>0.924</td>\n",
       "      <td>0.449</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>374</td>\n",
       "      <td>3.003</td>\n",
       "      <td>3.106</td>\n",
       "      <td>0.994</td>\n",
       "      <td>0.448</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375</td>\n",
       "      <td>2.991</td>\n",
       "      <td>3.034</td>\n",
       "      <td>0.771</td>\n",
       "      <td>0.449</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>376</td>\n",
       "      <td>3.011</td>\n",
       "      <td>3.029</td>\n",
       "      <td>0.980</td>\n",
       "      <td>0.448</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>377</td>\n",
       "      <td>3.021</td>\n",
       "      <td>3.058</td>\n",
       "      <td>0.912</td>\n",
       "      <td>0.449</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>378</td>\n",
       "      <td>3.000</td>\n",
       "      <td>3.051</td>\n",
       "      <td>0.784</td>\n",
       "      <td>0.451</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>379</td>\n",
       "      <td>3.013</td>\n",
       "      <td>3.039</td>\n",
       "      <td>0.927</td>\n",
       "      <td>0.452</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>2.987</td>\n",
       "      <td>3.090</td>\n",
       "      <td>0.780</td>\n",
       "      <td>0.451</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>381</td>\n",
       "      <td>2.987</td>\n",
       "      <td>3.027</td>\n",
       "      <td>0.836</td>\n",
       "      <td>0.450</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>382</td>\n",
       "      <td>2.982</td>\n",
       "      <td>3.036</td>\n",
       "      <td>0.916</td>\n",
       "      <td>0.450</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>383</td>\n",
       "      <td>2.986</td>\n",
       "      <td>3.020</td>\n",
       "      <td>0.839</td>\n",
       "      <td>0.447</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>384</td>\n",
       "      <td>2.993</td>\n",
       "      <td>3.093</td>\n",
       "      <td>0.837</td>\n",
       "      <td>0.432</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>385</td>\n",
       "      <td>2.983</td>\n",
       "      <td>3.063</td>\n",
       "      <td>0.757</td>\n",
       "      <td>0.450</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>386</td>\n",
       "      <td>3.004</td>\n",
       "      <td>3.117</td>\n",
       "      <td>0.687</td>\n",
       "      <td>0.449</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>387</td>\n",
       "      <td>3.003</td>\n",
       "      <td>3.047</td>\n",
       "      <td>0.831</td>\n",
       "      <td>0.450</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>388</td>\n",
       "      <td>2.995</td>\n",
       "      <td>3.025</td>\n",
       "      <td>0.839</td>\n",
       "      <td>0.449</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>389</td>\n",
       "      <td>2.989</td>\n",
       "      <td>3.152</td>\n",
       "      <td>0.984</td>\n",
       "      <td>0.448</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>3.006</td>\n",
       "      <td>3.037</td>\n",
       "      <td>0.927</td>\n",
       "      <td>0.450</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>391</td>\n",
       "      <td>2.975</td>\n",
       "      <td>3.081</td>\n",
       "      <td>0.732</td>\n",
       "      <td>0.450</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>392</td>\n",
       "      <td>2.987</td>\n",
       "      <td>3.049</td>\n",
       "      <td>0.842</td>\n",
       "      <td>0.451</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>393</td>\n",
       "      <td>2.986</td>\n",
       "      <td>3.047</td>\n",
       "      <td>0.926</td>\n",
       "      <td>0.448</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>394</td>\n",
       "      <td>2.977</td>\n",
       "      <td>3.071</td>\n",
       "      <td>0.752</td>\n",
       "      <td>0.450</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>395</td>\n",
       "      <td>2.987</td>\n",
       "      <td>3.028</td>\n",
       "      <td>0.857</td>\n",
       "      <td>0.446</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>396</td>\n",
       "      <td>2.994</td>\n",
       "      <td>3.034</td>\n",
       "      <td>0.859</td>\n",
       "      <td>0.449</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>397</td>\n",
       "      <td>3.026</td>\n",
       "      <td>3.048</td>\n",
       "      <td>0.859</td>\n",
       "      <td>0.452</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>398</td>\n",
       "      <td>2.997</td>\n",
       "      <td>3.029</td>\n",
       "      <td>0.873</td>\n",
       "      <td>0.451</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>399</td>\n",
       "      <td>2.986</td>\n",
       "      <td>3.023</td>\n",
       "      <td>0.930</td>\n",
       "      <td>0.450</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>2.984</td>\n",
       "      <td>3.040</td>\n",
       "      <td>0.896</td>\n",
       "      <td>0.448</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>401</td>\n",
       "      <td>2.984</td>\n",
       "      <td>3.040</td>\n",
       "      <td>0.840</td>\n",
       "      <td>0.447</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>402</td>\n",
       "      <td>2.990</td>\n",
       "      <td>3.042</td>\n",
       "      <td>0.842</td>\n",
       "      <td>0.450</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>403</td>\n",
       "      <td>3.003</td>\n",
       "      <td>3.033</td>\n",
       "      <td>0.905</td>\n",
       "      <td>0.449</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>404</td>\n",
       "      <td>3.017</td>\n",
       "      <td>3.024</td>\n",
       "      <td>0.932</td>\n",
       "      <td>0.450</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>405</td>\n",
       "      <td>2.973</td>\n",
       "      <td>3.050</td>\n",
       "      <td>0.809</td>\n",
       "      <td>0.451</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>406</td>\n",
       "      <td>2.999</td>\n",
       "      <td>3.032</td>\n",
       "      <td>0.929</td>\n",
       "      <td>0.451</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>407</td>\n",
       "      <td>2.988</td>\n",
       "      <td>3.041</td>\n",
       "      <td>0.940</td>\n",
       "      <td>0.447</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>408</td>\n",
       "      <td>2.974</td>\n",
       "      <td>3.052</td>\n",
       "      <td>0.805</td>\n",
       "      <td>0.451</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>409</td>\n",
       "      <td>2.973</td>\n",
       "      <td>3.047</td>\n",
       "      <td>0.752</td>\n",
       "      <td>0.450</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>2.995</td>\n",
       "      <td>3.027</td>\n",
       "      <td>0.828</td>\n",
       "      <td>0.453</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>411</td>\n",
       "      <td>2.985</td>\n",
       "      <td>3.068</td>\n",
       "      <td>0.983</td>\n",
       "      <td>0.442</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>412</td>\n",
       "      <td>2.985</td>\n",
       "      <td>3.022</td>\n",
       "      <td>0.936</td>\n",
       "      <td>0.448</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>413</td>\n",
       "      <td>3.008</td>\n",
       "      <td>3.035</td>\n",
       "      <td>0.826</td>\n",
       "      <td>0.449</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>414</td>\n",
       "      <td>2.987</td>\n",
       "      <td>3.052</td>\n",
       "      <td>0.828</td>\n",
       "      <td>0.451</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>415</td>\n",
       "      <td>2.987</td>\n",
       "      <td>3.016</td>\n",
       "      <td>0.910</td>\n",
       "      <td>0.448</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>416</td>\n",
       "      <td>2.975</td>\n",
       "      <td>3.016</td>\n",
       "      <td>0.859</td>\n",
       "      <td>0.450</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>417</td>\n",
       "      <td>2.977</td>\n",
       "      <td>3.024</td>\n",
       "      <td>0.874</td>\n",
       "      <td>0.447</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>418</td>\n",
       "      <td>2.980</td>\n",
       "      <td>3.047</td>\n",
       "      <td>0.933</td>\n",
       "      <td>0.447</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>419</td>\n",
       "      <td>2.980</td>\n",
       "      <td>3.038</td>\n",
       "      <td>0.836</td>\n",
       "      <td>0.452</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>3.008</td>\n",
       "      <td>3.081</td>\n",
       "      <td>0.746</td>\n",
       "      <td>0.448</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>421</td>\n",
       "      <td>2.979</td>\n",
       "      <td>3.039</td>\n",
       "      <td>0.826</td>\n",
       "      <td>0.453</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>422</td>\n",
       "      <td>2.978</td>\n",
       "      <td>3.038</td>\n",
       "      <td>0.826</td>\n",
       "      <td>0.451</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>423</td>\n",
       "      <td>2.978</td>\n",
       "      <td>3.015</td>\n",
       "      <td>0.905</td>\n",
       "      <td>0.448</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>424</td>\n",
       "      <td>2.978</td>\n",
       "      <td>3.033</td>\n",
       "      <td>0.929</td>\n",
       "      <td>0.446</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>425</td>\n",
       "      <td>2.994</td>\n",
       "      <td>3.060</td>\n",
       "      <td>0.828</td>\n",
       "      <td>0.450</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>426</td>\n",
       "      <td>2.985</td>\n",
       "      <td>3.019</td>\n",
       "      <td>0.840</td>\n",
       "      <td>0.450</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>427</td>\n",
       "      <td>2.974</td>\n",
       "      <td>3.032</td>\n",
       "      <td>0.839</td>\n",
       "      <td>0.449</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>428</td>\n",
       "      <td>2.977</td>\n",
       "      <td>3.025</td>\n",
       "      <td>0.929</td>\n",
       "      <td>0.447</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>429</td>\n",
       "      <td>2.978</td>\n",
       "      <td>3.126</td>\n",
       "      <td>0.698</td>\n",
       "      <td>0.451</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>430</td>\n",
       "      <td>3.005</td>\n",
       "      <td>3.072</td>\n",
       "      <td>0.769</td>\n",
       "      <td>0.448</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>431</td>\n",
       "      <td>2.985</td>\n",
       "      <td>3.020</td>\n",
       "      <td>0.837</td>\n",
       "      <td>0.451</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>432</td>\n",
       "      <td>2.967</td>\n",
       "      <td>3.015</td>\n",
       "      <td>0.853</td>\n",
       "      <td>0.451</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>433</td>\n",
       "      <td>2.974</td>\n",
       "      <td>3.025</td>\n",
       "      <td>0.929</td>\n",
       "      <td>0.450</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>434</td>\n",
       "      <td>2.972</td>\n",
       "      <td>3.017</td>\n",
       "      <td>0.860</td>\n",
       "      <td>0.451</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>435</td>\n",
       "      <td>2.977</td>\n",
       "      <td>3.035</td>\n",
       "      <td>0.944</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>436</td>\n",
       "      <td>2.987</td>\n",
       "      <td>3.034</td>\n",
       "      <td>0.774</td>\n",
       "      <td>0.449</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>437</td>\n",
       "      <td>2.975</td>\n",
       "      <td>3.081</td>\n",
       "      <td>0.837</td>\n",
       "      <td>0.450</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>438</td>\n",
       "      <td>2.997</td>\n",
       "      <td>3.028</td>\n",
       "      <td>0.929</td>\n",
       "      <td>0.445</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>439</td>\n",
       "      <td>2.976</td>\n",
       "      <td>3.050</td>\n",
       "      <td>0.760</td>\n",
       "      <td>0.450</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>2.977</td>\n",
       "      <td>3.014</td>\n",
       "      <td>0.879</td>\n",
       "      <td>0.446</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>441</td>\n",
       "      <td>2.979</td>\n",
       "      <td>3.020</td>\n",
       "      <td>0.873</td>\n",
       "      <td>0.447</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>442</td>\n",
       "      <td>2.993</td>\n",
       "      <td>3.017</td>\n",
       "      <td>0.881</td>\n",
       "      <td>0.449</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>443</td>\n",
       "      <td>2.970</td>\n",
       "      <td>3.030</td>\n",
       "      <td>0.840</td>\n",
       "      <td>0.449</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>444</td>\n",
       "      <td>2.975</td>\n",
       "      <td>3.053</td>\n",
       "      <td>0.926</td>\n",
       "      <td>0.443</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>445</td>\n",
       "      <td>2.977</td>\n",
       "      <td>3.022</td>\n",
       "      <td>0.828</td>\n",
       "      <td>0.447</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>446</td>\n",
       "      <td>2.971</td>\n",
       "      <td>3.048</td>\n",
       "      <td>0.946</td>\n",
       "      <td>0.445</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>447</td>\n",
       "      <td>3.007</td>\n",
       "      <td>3.040</td>\n",
       "      <td>0.854</td>\n",
       "      <td>0.451</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>448</td>\n",
       "      <td>3.002</td>\n",
       "      <td>3.017</td>\n",
       "      <td>0.898</td>\n",
       "      <td>0.446</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>449</td>\n",
       "      <td>3.011</td>\n",
       "      <td>3.056</td>\n",
       "      <td>0.749</td>\n",
       "      <td>0.446</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>2.972</td>\n",
       "      <td>3.032</td>\n",
       "      <td>0.809</td>\n",
       "      <td>0.449</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>451</td>\n",
       "      <td>2.975</td>\n",
       "      <td>3.031</td>\n",
       "      <td>0.826</td>\n",
       "      <td>0.450</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>452</td>\n",
       "      <td>2.963</td>\n",
       "      <td>3.024</td>\n",
       "      <td>0.836</td>\n",
       "      <td>0.449</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>453</td>\n",
       "      <td>2.970</td>\n",
       "      <td>3.030</td>\n",
       "      <td>0.864</td>\n",
       "      <td>0.448</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>454</td>\n",
       "      <td>2.976</td>\n",
       "      <td>3.017</td>\n",
       "      <td>0.867</td>\n",
       "      <td>0.450</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>455</td>\n",
       "      <td>2.963</td>\n",
       "      <td>3.026</td>\n",
       "      <td>0.829</td>\n",
       "      <td>0.450</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>456</td>\n",
       "      <td>2.990</td>\n",
       "      <td>3.060</td>\n",
       "      <td>0.836</td>\n",
       "      <td>0.447</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>457</td>\n",
       "      <td>2.977</td>\n",
       "      <td>3.059</td>\n",
       "      <td>0.936</td>\n",
       "      <td>0.449</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>458</td>\n",
       "      <td>2.990</td>\n",
       "      <td>3.018</td>\n",
       "      <td>0.870</td>\n",
       "      <td>0.451</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>459</td>\n",
       "      <td>2.963</td>\n",
       "      <td>3.016</td>\n",
       "      <td>0.910</td>\n",
       "      <td>0.452</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>2.968</td>\n",
       "      <td>3.055</td>\n",
       "      <td>0.944</td>\n",
       "      <td>0.445</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>461</td>\n",
       "      <td>2.966</td>\n",
       "      <td>3.023</td>\n",
       "      <td>0.847</td>\n",
       "      <td>0.449</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>462</td>\n",
       "      <td>2.987</td>\n",
       "      <td>3.038</td>\n",
       "      <td>0.811</td>\n",
       "      <td>0.448</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>463</td>\n",
       "      <td>3.000</td>\n",
       "      <td>3.033</td>\n",
       "      <td>0.984</td>\n",
       "      <td>0.450</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>464</td>\n",
       "      <td>2.967</td>\n",
       "      <td>3.012</td>\n",
       "      <td>0.876</td>\n",
       "      <td>0.449</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>465</td>\n",
       "      <td>2.981</td>\n",
       "      <td>3.031</td>\n",
       "      <td>0.932</td>\n",
       "      <td>0.449</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>466</td>\n",
       "      <td>2.970</td>\n",
       "      <td>3.035</td>\n",
       "      <td>0.927</td>\n",
       "      <td>0.447</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>467</td>\n",
       "      <td>2.986</td>\n",
       "      <td>3.019</td>\n",
       "      <td>0.848</td>\n",
       "      <td>0.452</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>468</td>\n",
       "      <td>2.969</td>\n",
       "      <td>3.017</td>\n",
       "      <td>0.882</td>\n",
       "      <td>0.449</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>469</td>\n",
       "      <td>2.972</td>\n",
       "      <td>3.019</td>\n",
       "      <td>0.916</td>\n",
       "      <td>0.448</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>470</td>\n",
       "      <td>2.968</td>\n",
       "      <td>3.039</td>\n",
       "      <td>0.929</td>\n",
       "      <td>0.443</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>471</td>\n",
       "      <td>2.973</td>\n",
       "      <td>3.021</td>\n",
       "      <td>0.842</td>\n",
       "      <td>0.450</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>472</td>\n",
       "      <td>2.968</td>\n",
       "      <td>3.016</td>\n",
       "      <td>0.905</td>\n",
       "      <td>0.448</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>473</td>\n",
       "      <td>2.987</td>\n",
       "      <td>3.080</td>\n",
       "      <td>0.718</td>\n",
       "      <td>0.448</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>474</td>\n",
       "      <td>2.969</td>\n",
       "      <td>3.037</td>\n",
       "      <td>0.823</td>\n",
       "      <td>0.450</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>475</td>\n",
       "      <td>2.965</td>\n",
       "      <td>3.041</td>\n",
       "      <td>0.915</td>\n",
       "      <td>0.443</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>476</td>\n",
       "      <td>2.965</td>\n",
       "      <td>3.016</td>\n",
       "      <td>0.916</td>\n",
       "      <td>0.449</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>477</td>\n",
       "      <td>2.974</td>\n",
       "      <td>3.065</td>\n",
       "      <td>0.940</td>\n",
       "      <td>0.441</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>478</td>\n",
       "      <td>2.977</td>\n",
       "      <td>3.014</td>\n",
       "      <td>0.907</td>\n",
       "      <td>0.448</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>479</td>\n",
       "      <td>2.964</td>\n",
       "      <td>3.013</td>\n",
       "      <td>0.867</td>\n",
       "      <td>0.447</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>2.966</td>\n",
       "      <td>3.030</td>\n",
       "      <td>0.819</td>\n",
       "      <td>0.449</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>481</td>\n",
       "      <td>2.962</td>\n",
       "      <td>3.024</td>\n",
       "      <td>0.831</td>\n",
       "      <td>0.446</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>482</td>\n",
       "      <td>2.971</td>\n",
       "      <td>3.028</td>\n",
       "      <td>0.876</td>\n",
       "      <td>0.443</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>483</td>\n",
       "      <td>2.979</td>\n",
       "      <td>3.024</td>\n",
       "      <td>0.842</td>\n",
       "      <td>0.447</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>484</td>\n",
       "      <td>2.972</td>\n",
       "      <td>3.058</td>\n",
       "      <td>0.795</td>\n",
       "      <td>0.451</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>485</td>\n",
       "      <td>2.971</td>\n",
       "      <td>3.012</td>\n",
       "      <td>0.881</td>\n",
       "      <td>0.448</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>486</td>\n",
       "      <td>2.961</td>\n",
       "      <td>3.045</td>\n",
       "      <td>0.949</td>\n",
       "      <td>0.446</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>487</td>\n",
       "      <td>2.976</td>\n",
       "      <td>3.047</td>\n",
       "      <td>0.857</td>\n",
       "      <td>0.447</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>488</td>\n",
       "      <td>2.965</td>\n",
       "      <td>3.027</td>\n",
       "      <td>0.898</td>\n",
       "      <td>0.446</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>489</td>\n",
       "      <td>2.963</td>\n",
       "      <td>3.014</td>\n",
       "      <td>0.860</td>\n",
       "      <td>0.450</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>490</td>\n",
       "      <td>2.966</td>\n",
       "      <td>3.028</td>\n",
       "      <td>0.819</td>\n",
       "      <td>0.448</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>491</td>\n",
       "      <td>2.972</td>\n",
       "      <td>3.021</td>\n",
       "      <td>0.837</td>\n",
       "      <td>0.448</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>492</td>\n",
       "      <td>2.968</td>\n",
       "      <td>3.057</td>\n",
       "      <td>0.921</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>493</td>\n",
       "      <td>2.971</td>\n",
       "      <td>3.017</td>\n",
       "      <td>0.857</td>\n",
       "      <td>0.451</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>494</td>\n",
       "      <td>2.959</td>\n",
       "      <td>3.015</td>\n",
       "      <td>0.857</td>\n",
       "      <td>0.449</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>495</td>\n",
       "      <td>2.962</td>\n",
       "      <td>3.014</td>\n",
       "      <td>0.856</td>\n",
       "      <td>0.450</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>496</td>\n",
       "      <td>2.962</td>\n",
       "      <td>3.016</td>\n",
       "      <td>0.839</td>\n",
       "      <td>0.447</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>497</td>\n",
       "      <td>2.963</td>\n",
       "      <td>3.034</td>\n",
       "      <td>0.803</td>\n",
       "      <td>0.449</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>498</td>\n",
       "      <td>2.965</td>\n",
       "      <td>3.039</td>\n",
       "      <td>0.940</td>\n",
       "      <td>0.443</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>499</td>\n",
       "      <td>2.960</td>\n",
       "      <td>3.030</td>\n",
       "      <td>0.816</td>\n",
       "      <td>0.451</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>2.955</td>\n",
       "      <td>3.013</td>\n",
       "      <td>0.857</td>\n",
       "      <td>0.450</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>501</td>\n",
       "      <td>2.965</td>\n",
       "      <td>3.023</td>\n",
       "      <td>0.829</td>\n",
       "      <td>0.450</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>502</td>\n",
       "      <td>2.958</td>\n",
       "      <td>3.035</td>\n",
       "      <td>0.941</td>\n",
       "      <td>0.448</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>503</td>\n",
       "      <td>2.983</td>\n",
       "      <td>3.030</td>\n",
       "      <td>0.851</td>\n",
       "      <td>0.447</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>504</td>\n",
       "      <td>2.967</td>\n",
       "      <td>3.025</td>\n",
       "      <td>0.916</td>\n",
       "      <td>0.449</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>505</td>\n",
       "      <td>2.965</td>\n",
       "      <td>3.020</td>\n",
       "      <td>0.836</td>\n",
       "      <td>0.450</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>506</td>\n",
       "      <td>2.960</td>\n",
       "      <td>3.019</td>\n",
       "      <td>0.871</td>\n",
       "      <td>0.449</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>507</td>\n",
       "      <td>2.957</td>\n",
       "      <td>3.030</td>\n",
       "      <td>0.845</td>\n",
       "      <td>0.448</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>508</td>\n",
       "      <td>2.963</td>\n",
       "      <td>3.014</td>\n",
       "      <td>0.885</td>\n",
       "      <td>0.450</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>509</td>\n",
       "      <td>2.959</td>\n",
       "      <td>3.030</td>\n",
       "      <td>0.828</td>\n",
       "      <td>0.449</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>510</td>\n",
       "      <td>2.958</td>\n",
       "      <td>3.018</td>\n",
       "      <td>0.865</td>\n",
       "      <td>0.449</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>511</td>\n",
       "      <td>2.966</td>\n",
       "      <td>3.013</td>\n",
       "      <td>0.842</td>\n",
       "      <td>0.448</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>512</td>\n",
       "      <td>2.955</td>\n",
       "      <td>3.014</td>\n",
       "      <td>0.853</td>\n",
       "      <td>0.448</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>513</td>\n",
       "      <td>2.963</td>\n",
       "      <td>3.016</td>\n",
       "      <td>0.909</td>\n",
       "      <td>0.450</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>514</td>\n",
       "      <td>2.956</td>\n",
       "      <td>3.022</td>\n",
       "      <td>0.842</td>\n",
       "      <td>0.450</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>515</td>\n",
       "      <td>2.953</td>\n",
       "      <td>3.012</td>\n",
       "      <td>0.868</td>\n",
       "      <td>0.450</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>516</td>\n",
       "      <td>2.954</td>\n",
       "      <td>3.020</td>\n",
       "      <td>0.840</td>\n",
       "      <td>0.449</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>517</td>\n",
       "      <td>2.950</td>\n",
       "      <td>3.016</td>\n",
       "      <td>0.874</td>\n",
       "      <td>0.449</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>518</td>\n",
       "      <td>2.958</td>\n",
       "      <td>3.018</td>\n",
       "      <td>0.828</td>\n",
       "      <td>0.448</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>519</td>\n",
       "      <td>2.958</td>\n",
       "      <td>3.018</td>\n",
       "      <td>0.843</td>\n",
       "      <td>0.445</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>2.956</td>\n",
       "      <td>3.023</td>\n",
       "      <td>0.860</td>\n",
       "      <td>0.447</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>521</td>\n",
       "      <td>2.955</td>\n",
       "      <td>3.026</td>\n",
       "      <td>0.819</td>\n",
       "      <td>0.449</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>522</td>\n",
       "      <td>2.957</td>\n",
       "      <td>3.018</td>\n",
       "      <td>0.854</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>523</td>\n",
       "      <td>2.959</td>\n",
       "      <td>3.026</td>\n",
       "      <td>0.898</td>\n",
       "      <td>0.445</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>524</td>\n",
       "      <td>2.952</td>\n",
       "      <td>3.013</td>\n",
       "      <td>0.859</td>\n",
       "      <td>0.450</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>525</td>\n",
       "      <td>2.951</td>\n",
       "      <td>3.014</td>\n",
       "      <td>0.882</td>\n",
       "      <td>0.449</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>526</td>\n",
       "      <td>2.953</td>\n",
       "      <td>3.023</td>\n",
       "      <td>0.837</td>\n",
       "      <td>0.446</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>527</td>\n",
       "      <td>2.949</td>\n",
       "      <td>3.020</td>\n",
       "      <td>0.867</td>\n",
       "      <td>0.445</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>528</td>\n",
       "      <td>2.952</td>\n",
       "      <td>3.019</td>\n",
       "      <td>0.826</td>\n",
       "      <td>0.449</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>529</td>\n",
       "      <td>2.952</td>\n",
       "      <td>3.017</td>\n",
       "      <td>0.893</td>\n",
       "      <td>0.448</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>530</td>\n",
       "      <td>2.950</td>\n",
       "      <td>3.034</td>\n",
       "      <td>0.930</td>\n",
       "      <td>0.442</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>531</td>\n",
       "      <td>2.959</td>\n",
       "      <td>3.017</td>\n",
       "      <td>0.888</td>\n",
       "      <td>0.448</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>532</td>\n",
       "      <td>2.950</td>\n",
       "      <td>3.012</td>\n",
       "      <td>0.862</td>\n",
       "      <td>0.449</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>533</td>\n",
       "      <td>2.950</td>\n",
       "      <td>3.020</td>\n",
       "      <td>0.839</td>\n",
       "      <td>0.445</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>534</td>\n",
       "      <td>2.953</td>\n",
       "      <td>3.014</td>\n",
       "      <td>0.843</td>\n",
       "      <td>0.449</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>535</td>\n",
       "      <td>2.954</td>\n",
       "      <td>3.022</td>\n",
       "      <td>0.919</td>\n",
       "      <td>0.446</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>536</td>\n",
       "      <td>2.953</td>\n",
       "      <td>3.013</td>\n",
       "      <td>0.845</td>\n",
       "      <td>0.449</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>537</td>\n",
       "      <td>2.947</td>\n",
       "      <td>3.012</td>\n",
       "      <td>0.847</td>\n",
       "      <td>0.447</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>538</td>\n",
       "      <td>2.956</td>\n",
       "      <td>3.020</td>\n",
       "      <td>0.921</td>\n",
       "      <td>0.447</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>539</td>\n",
       "      <td>2.951</td>\n",
       "      <td>3.021</td>\n",
       "      <td>0.893</td>\n",
       "      <td>0.446</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>2.950</td>\n",
       "      <td>3.019</td>\n",
       "      <td>0.926</td>\n",
       "      <td>0.449</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>541</td>\n",
       "      <td>2.949</td>\n",
       "      <td>3.018</td>\n",
       "      <td>0.823</td>\n",
       "      <td>0.448</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>542</td>\n",
       "      <td>2.950</td>\n",
       "      <td>3.021</td>\n",
       "      <td>0.826</td>\n",
       "      <td>0.449</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>543</td>\n",
       "      <td>2.947</td>\n",
       "      <td>3.016</td>\n",
       "      <td>0.845</td>\n",
       "      <td>0.447</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>544</td>\n",
       "      <td>2.947</td>\n",
       "      <td>3.013</td>\n",
       "      <td>0.868</td>\n",
       "      <td>0.448</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>545</td>\n",
       "      <td>2.948</td>\n",
       "      <td>3.017</td>\n",
       "      <td>0.829</td>\n",
       "      <td>0.449</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>546</td>\n",
       "      <td>2.948</td>\n",
       "      <td>3.029</td>\n",
       "      <td>0.819</td>\n",
       "      <td>0.447</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>547</td>\n",
       "      <td>2.951</td>\n",
       "      <td>3.031</td>\n",
       "      <td>0.812</td>\n",
       "      <td>0.449</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>548</td>\n",
       "      <td>2.955</td>\n",
       "      <td>3.033</td>\n",
       "      <td>0.809</td>\n",
       "      <td>0.448</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>549</td>\n",
       "      <td>2.951</td>\n",
       "      <td>3.033</td>\n",
       "      <td>0.842</td>\n",
       "      <td>0.446</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>2.954</td>\n",
       "      <td>3.017</td>\n",
       "      <td>0.825</td>\n",
       "      <td>0.446</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>551</td>\n",
       "      <td>2.948</td>\n",
       "      <td>3.015</td>\n",
       "      <td>0.854</td>\n",
       "      <td>0.447</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>552</td>\n",
       "      <td>2.949</td>\n",
       "      <td>3.031</td>\n",
       "      <td>0.833</td>\n",
       "      <td>0.446</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>553</td>\n",
       "      <td>2.955</td>\n",
       "      <td>3.024</td>\n",
       "      <td>0.812</td>\n",
       "      <td>0.447</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>554</td>\n",
       "      <td>2.957</td>\n",
       "      <td>3.022</td>\n",
       "      <td>0.834</td>\n",
       "      <td>0.447</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>555</td>\n",
       "      <td>2.953</td>\n",
       "      <td>3.011</td>\n",
       "      <td>0.853</td>\n",
       "      <td>0.449</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>556</td>\n",
       "      <td>2.948</td>\n",
       "      <td>3.021</td>\n",
       "      <td>0.833</td>\n",
       "      <td>0.447</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>557</td>\n",
       "      <td>2.953</td>\n",
       "      <td>3.018</td>\n",
       "      <td>0.834</td>\n",
       "      <td>0.447</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>558</td>\n",
       "      <td>2.946</td>\n",
       "      <td>3.012</td>\n",
       "      <td>0.856</td>\n",
       "      <td>0.448</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>559</td>\n",
       "      <td>2.944</td>\n",
       "      <td>3.014</td>\n",
       "      <td>0.881</td>\n",
       "      <td>0.448</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>2.948</td>\n",
       "      <td>3.012</td>\n",
       "      <td>0.876</td>\n",
       "      <td>0.448</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>561</td>\n",
       "      <td>2.944</td>\n",
       "      <td>3.013</td>\n",
       "      <td>0.874</td>\n",
       "      <td>0.448</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>562</td>\n",
       "      <td>2.944</td>\n",
       "      <td>3.020</td>\n",
       "      <td>0.853</td>\n",
       "      <td>0.446</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>563</td>\n",
       "      <td>2.945</td>\n",
       "      <td>3.013</td>\n",
       "      <td>0.854</td>\n",
       "      <td>0.447</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>564</td>\n",
       "      <td>2.953</td>\n",
       "      <td>3.025</td>\n",
       "      <td>0.913</td>\n",
       "      <td>0.446</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>565</td>\n",
       "      <td>2.951</td>\n",
       "      <td>3.014</td>\n",
       "      <td>0.918</td>\n",
       "      <td>0.448</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>566</td>\n",
       "      <td>2.952</td>\n",
       "      <td>3.018</td>\n",
       "      <td>0.834</td>\n",
       "      <td>0.448</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>567</td>\n",
       "      <td>2.950</td>\n",
       "      <td>3.031</td>\n",
       "      <td>0.812</td>\n",
       "      <td>0.447</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>568</td>\n",
       "      <td>2.950</td>\n",
       "      <td>3.013</td>\n",
       "      <td>0.859</td>\n",
       "      <td>0.447</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>569</td>\n",
       "      <td>2.946</td>\n",
       "      <td>3.014</td>\n",
       "      <td>0.901</td>\n",
       "      <td>0.447</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>570</td>\n",
       "      <td>2.950</td>\n",
       "      <td>3.013</td>\n",
       "      <td>0.847</td>\n",
       "      <td>0.448</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>571</td>\n",
       "      <td>2.944</td>\n",
       "      <td>3.012</td>\n",
       "      <td>0.864</td>\n",
       "      <td>0.447</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>572</td>\n",
       "      <td>2.943</td>\n",
       "      <td>3.013</td>\n",
       "      <td>0.847</td>\n",
       "      <td>0.447</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>573</td>\n",
       "      <td>2.943</td>\n",
       "      <td>3.018</td>\n",
       "      <td>0.833</td>\n",
       "      <td>0.447</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>574</td>\n",
       "      <td>2.945</td>\n",
       "      <td>3.013</td>\n",
       "      <td>0.874</td>\n",
       "      <td>0.447</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>575</td>\n",
       "      <td>2.946</td>\n",
       "      <td>3.014</td>\n",
       "      <td>0.881</td>\n",
       "      <td>0.447</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>576</td>\n",
       "      <td>2.945</td>\n",
       "      <td>3.022</td>\n",
       "      <td>0.828</td>\n",
       "      <td>0.447</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>577</td>\n",
       "      <td>2.949</td>\n",
       "      <td>3.017</td>\n",
       "      <td>0.833</td>\n",
       "      <td>0.447</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>578</td>\n",
       "      <td>2.947</td>\n",
       "      <td>3.013</td>\n",
       "      <td>0.898</td>\n",
       "      <td>0.448</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>579</td>\n",
       "      <td>2.951</td>\n",
       "      <td>3.025</td>\n",
       "      <td>0.814</td>\n",
       "      <td>0.448</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>2.946</td>\n",
       "      <td>3.012</td>\n",
       "      <td>0.856</td>\n",
       "      <td>0.448</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>581</td>\n",
       "      <td>2.944</td>\n",
       "      <td>3.014</td>\n",
       "      <td>0.865</td>\n",
       "      <td>0.447</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>582</td>\n",
       "      <td>2.944</td>\n",
       "      <td>3.016</td>\n",
       "      <td>0.847</td>\n",
       "      <td>0.446</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>583</td>\n",
       "      <td>2.944</td>\n",
       "      <td>3.009</td>\n",
       "      <td>0.865</td>\n",
       "      <td>0.449</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>584</td>\n",
       "      <td>2.943</td>\n",
       "      <td>3.016</td>\n",
       "      <td>0.845</td>\n",
       "      <td>0.447</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>585</td>\n",
       "      <td>2.942</td>\n",
       "      <td>3.012</td>\n",
       "      <td>0.859</td>\n",
       "      <td>0.448</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>586</td>\n",
       "      <td>2.944</td>\n",
       "      <td>3.015</td>\n",
       "      <td>0.874</td>\n",
       "      <td>0.445</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>587</td>\n",
       "      <td>2.944</td>\n",
       "      <td>3.011</td>\n",
       "      <td>0.856</td>\n",
       "      <td>0.448</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>588</td>\n",
       "      <td>2.942</td>\n",
       "      <td>3.013</td>\n",
       "      <td>0.873</td>\n",
       "      <td>0.447</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>589</td>\n",
       "      <td>2.944</td>\n",
       "      <td>3.016</td>\n",
       "      <td>0.833</td>\n",
       "      <td>0.447</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>590</td>\n",
       "      <td>2.943</td>\n",
       "      <td>3.011</td>\n",
       "      <td>0.864</td>\n",
       "      <td>0.448</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>591</td>\n",
       "      <td>2.943</td>\n",
       "      <td>3.013</td>\n",
       "      <td>0.860</td>\n",
       "      <td>0.447</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>592</td>\n",
       "      <td>2.943</td>\n",
       "      <td>3.013</td>\n",
       "      <td>0.853</td>\n",
       "      <td>0.447</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>593</td>\n",
       "      <td>2.943</td>\n",
       "      <td>3.019</td>\n",
       "      <td>0.833</td>\n",
       "      <td>0.447</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>594</td>\n",
       "      <td>2.942</td>\n",
       "      <td>3.012</td>\n",
       "      <td>0.865</td>\n",
       "      <td>0.448</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>595</td>\n",
       "      <td>2.943</td>\n",
       "      <td>3.015</td>\n",
       "      <td>0.854</td>\n",
       "      <td>0.446</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>596</td>\n",
       "      <td>2.942</td>\n",
       "      <td>3.012</td>\n",
       "      <td>0.854</td>\n",
       "      <td>0.448</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>597</td>\n",
       "      <td>2.943</td>\n",
       "      <td>3.013</td>\n",
       "      <td>0.873</td>\n",
       "      <td>0.447</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>598</td>\n",
       "      <td>2.944</td>\n",
       "      <td>3.013</td>\n",
       "      <td>0.862</td>\n",
       "      <td>0.447</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>599</td>\n",
       "      <td>2.944</td>\n",
       "      <td>3.011</td>\n",
       "      <td>0.845</td>\n",
       "      <td>0.448</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>2.945</td>\n",
       "      <td>3.015</td>\n",
       "      <td>0.870</td>\n",
       "      <td>0.446</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>601</td>\n",
       "      <td>2.943</td>\n",
       "      <td>3.013</td>\n",
       "      <td>0.840</td>\n",
       "      <td>0.447</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>602</td>\n",
       "      <td>2.945</td>\n",
       "      <td>3.018</td>\n",
       "      <td>0.848</td>\n",
       "      <td>0.446</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>603</td>\n",
       "      <td>2.943</td>\n",
       "      <td>3.010</td>\n",
       "      <td>0.868</td>\n",
       "      <td>0.449</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>604</td>\n",
       "      <td>2.941</td>\n",
       "      <td>3.016</td>\n",
       "      <td>0.857</td>\n",
       "      <td>0.446</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>605</td>\n",
       "      <td>2.942</td>\n",
       "      <td>3.013</td>\n",
       "      <td>0.860</td>\n",
       "      <td>0.447</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>606</td>\n",
       "      <td>2.944</td>\n",
       "      <td>3.014</td>\n",
       "      <td>0.837</td>\n",
       "      <td>0.448</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>607</td>\n",
       "      <td>2.944</td>\n",
       "      <td>3.015</td>\n",
       "      <td>0.859</td>\n",
       "      <td>0.446</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>608</td>\n",
       "      <td>2.943</td>\n",
       "      <td>3.011</td>\n",
       "      <td>0.843</td>\n",
       "      <td>0.448</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>609</td>\n",
       "      <td>2.944</td>\n",
       "      <td>3.022</td>\n",
       "      <td>0.834</td>\n",
       "      <td>0.446</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>610</td>\n",
       "      <td>2.945</td>\n",
       "      <td>3.011</td>\n",
       "      <td>0.853</td>\n",
       "      <td>0.448</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>611</td>\n",
       "      <td>2.945</td>\n",
       "      <td>3.015</td>\n",
       "      <td>0.893</td>\n",
       "      <td>0.446</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>612</td>\n",
       "      <td>2.947</td>\n",
       "      <td>3.012</td>\n",
       "      <td>0.837</td>\n",
       "      <td>0.448</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>613</td>\n",
       "      <td>2.943</td>\n",
       "      <td>3.017</td>\n",
       "      <td>0.856</td>\n",
       "      <td>0.445</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>614</td>\n",
       "      <td>2.944</td>\n",
       "      <td>3.010</td>\n",
       "      <td>0.857</td>\n",
       "      <td>0.448</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>615</td>\n",
       "      <td>2.943</td>\n",
       "      <td>3.016</td>\n",
       "      <td>0.860</td>\n",
       "      <td>0.445</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>616</td>\n",
       "      <td>2.943</td>\n",
       "      <td>3.012</td>\n",
       "      <td>0.845</td>\n",
       "      <td>0.448</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>617</td>\n",
       "      <td>2.942</td>\n",
       "      <td>3.016</td>\n",
       "      <td>0.868</td>\n",
       "      <td>0.445</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>618</td>\n",
       "      <td>2.942</td>\n",
       "      <td>3.012</td>\n",
       "      <td>0.860</td>\n",
       "      <td>0.448</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>619</td>\n",
       "      <td>2.942</td>\n",
       "      <td>3.014</td>\n",
       "      <td>0.864</td>\n",
       "      <td>0.447</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>2.941</td>\n",
       "      <td>3.014</td>\n",
       "      <td>0.843</td>\n",
       "      <td>0.447</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>621</td>\n",
       "      <td>2.942</td>\n",
       "      <td>3.014</td>\n",
       "      <td>0.884</td>\n",
       "      <td>0.447</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>622</td>\n",
       "      <td>2.942</td>\n",
       "      <td>3.014</td>\n",
       "      <td>0.848</td>\n",
       "      <td>0.447</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>623</td>\n",
       "      <td>2.944</td>\n",
       "      <td>3.019</td>\n",
       "      <td>0.833</td>\n",
       "      <td>0.446</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>624</td>\n",
       "      <td>2.942</td>\n",
       "      <td>3.012</td>\n",
       "      <td>0.874</td>\n",
       "      <td>0.447</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>625</td>\n",
       "      <td>2.941</td>\n",
       "      <td>3.016</td>\n",
       "      <td>0.839</td>\n",
       "      <td>0.446</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>626</td>\n",
       "      <td>2.944</td>\n",
       "      <td>3.014</td>\n",
       "      <td>0.840</td>\n",
       "      <td>0.447</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>627</td>\n",
       "      <td>2.942</td>\n",
       "      <td>3.013</td>\n",
       "      <td>0.854</td>\n",
       "      <td>0.447</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>628</td>\n",
       "      <td>2.941</td>\n",
       "      <td>3.014</td>\n",
       "      <td>0.860</td>\n",
       "      <td>0.446</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>629</td>\n",
       "      <td>2.940</td>\n",
       "      <td>3.012</td>\n",
       "      <td>0.860</td>\n",
       "      <td>0.447</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>630</td>\n",
       "      <td>2.940</td>\n",
       "      <td>3.014</td>\n",
       "      <td>0.857</td>\n",
       "      <td>0.446</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>631</td>\n",
       "      <td>2.940</td>\n",
       "      <td>3.014</td>\n",
       "      <td>0.859</td>\n",
       "      <td>0.446</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>632</td>\n",
       "      <td>2.940</td>\n",
       "      <td>3.013</td>\n",
       "      <td>0.854</td>\n",
       "      <td>0.446</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>633</td>\n",
       "      <td>2.941</td>\n",
       "      <td>3.018</td>\n",
       "      <td>0.833</td>\n",
       "      <td>0.447</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>634</td>\n",
       "      <td>2.943</td>\n",
       "      <td>3.012</td>\n",
       "      <td>0.856</td>\n",
       "      <td>0.447</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>635</td>\n",
       "      <td>2.941</td>\n",
       "      <td>3.013</td>\n",
       "      <td>0.864</td>\n",
       "      <td>0.447</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>636</td>\n",
       "      <td>2.942</td>\n",
       "      <td>3.014</td>\n",
       "      <td>0.856</td>\n",
       "      <td>0.447</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>637</td>\n",
       "      <td>2.943</td>\n",
       "      <td>3.017</td>\n",
       "      <td>0.833</td>\n",
       "      <td>0.447</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>638</td>\n",
       "      <td>2.946</td>\n",
       "      <td>3.013</td>\n",
       "      <td>0.884</td>\n",
       "      <td>0.447</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>639</td>\n",
       "      <td>2.941</td>\n",
       "      <td>3.014</td>\n",
       "      <td>0.851</td>\n",
       "      <td>0.446</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>640</td>\n",
       "      <td>2.941</td>\n",
       "      <td>3.017</td>\n",
       "      <td>0.839</td>\n",
       "      <td>0.446</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>641</td>\n",
       "      <td>2.941</td>\n",
       "      <td>3.015</td>\n",
       "      <td>0.896</td>\n",
       "      <td>0.446</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>642</td>\n",
       "      <td>2.942</td>\n",
       "      <td>3.014</td>\n",
       "      <td>0.842</td>\n",
       "      <td>0.447</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>643</td>\n",
       "      <td>2.940</td>\n",
       "      <td>3.014</td>\n",
       "      <td>0.868</td>\n",
       "      <td>0.446</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>644</td>\n",
       "      <td>2.942</td>\n",
       "      <td>3.017</td>\n",
       "      <td>0.837</td>\n",
       "      <td>0.446</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>645</td>\n",
       "      <td>2.940</td>\n",
       "      <td>3.014</td>\n",
       "      <td>0.873</td>\n",
       "      <td>0.446</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>646</td>\n",
       "      <td>2.940</td>\n",
       "      <td>3.022</td>\n",
       "      <td>0.828</td>\n",
       "      <td>0.446</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>647</td>\n",
       "      <td>2.943</td>\n",
       "      <td>3.013</td>\n",
       "      <td>0.854</td>\n",
       "      <td>0.447</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>648</td>\n",
       "      <td>2.941</td>\n",
       "      <td>3.015</td>\n",
       "      <td>0.839</td>\n",
       "      <td>0.447</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>649</td>\n",
       "      <td>2.940</td>\n",
       "      <td>3.014</td>\n",
       "      <td>0.864</td>\n",
       "      <td>0.446</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>2.940</td>\n",
       "      <td>3.012</td>\n",
       "      <td>0.865</td>\n",
       "      <td>0.447</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>651</td>\n",
       "      <td>2.940</td>\n",
       "      <td>3.014</td>\n",
       "      <td>0.845</td>\n",
       "      <td>0.446</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>652</td>\n",
       "      <td>2.940</td>\n",
       "      <td>3.013</td>\n",
       "      <td>0.874</td>\n",
       "      <td>0.447</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>653</td>\n",
       "      <td>2.942</td>\n",
       "      <td>3.014</td>\n",
       "      <td>0.848</td>\n",
       "      <td>0.447</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>654</td>\n",
       "      <td>2.944</td>\n",
       "      <td>3.019</td>\n",
       "      <td>0.831</td>\n",
       "      <td>0.446</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>655</td>\n",
       "      <td>2.946</td>\n",
       "      <td>3.017</td>\n",
       "      <td>0.898</td>\n",
       "      <td>0.446</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>656</td>\n",
       "      <td>2.944</td>\n",
       "      <td>3.023</td>\n",
       "      <td>0.825</td>\n",
       "      <td>0.447</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>657</td>\n",
       "      <td>2.940</td>\n",
       "      <td>3.014</td>\n",
       "      <td>0.876</td>\n",
       "      <td>0.446</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>658</td>\n",
       "      <td>2.940</td>\n",
       "      <td>3.012</td>\n",
       "      <td>0.843</td>\n",
       "      <td>0.447</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>659</td>\n",
       "      <td>2.942</td>\n",
       "      <td>3.014</td>\n",
       "      <td>0.857</td>\n",
       "      <td>0.446</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>2.941</td>\n",
       "      <td>3.014</td>\n",
       "      <td>0.870</td>\n",
       "      <td>0.446</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>661</td>\n",
       "      <td>2.940</td>\n",
       "      <td>3.017</td>\n",
       "      <td>0.840</td>\n",
       "      <td>0.445</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>662</td>\n",
       "      <td>2.941</td>\n",
       "      <td>3.012</td>\n",
       "      <td>0.879</td>\n",
       "      <td>0.447</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>663</td>\n",
       "      <td>2.940</td>\n",
       "      <td>3.016</td>\n",
       "      <td>0.845</td>\n",
       "      <td>0.446</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>664</td>\n",
       "      <td>2.940</td>\n",
       "      <td>3.014</td>\n",
       "      <td>0.854</td>\n",
       "      <td>0.446</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>665</td>\n",
       "      <td>2.941</td>\n",
       "      <td>3.016</td>\n",
       "      <td>0.848</td>\n",
       "      <td>0.446</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>666</td>\n",
       "      <td>2.941</td>\n",
       "      <td>3.013</td>\n",
       "      <td>0.851</td>\n",
       "      <td>0.446</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>667</td>\n",
       "      <td>2.942</td>\n",
       "      <td>3.014</td>\n",
       "      <td>0.876</td>\n",
       "      <td>0.446</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>668</td>\n",
       "      <td>2.940</td>\n",
       "      <td>3.014</td>\n",
       "      <td>0.850</td>\n",
       "      <td>0.446</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>669</td>\n",
       "      <td>2.941</td>\n",
       "      <td>3.013</td>\n",
       "      <td>0.840</td>\n",
       "      <td>0.447</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>670</td>\n",
       "      <td>2.942</td>\n",
       "      <td>3.014</td>\n",
       "      <td>0.867</td>\n",
       "      <td>0.445</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>671</td>\n",
       "      <td>2.941</td>\n",
       "      <td>3.011</td>\n",
       "      <td>0.868</td>\n",
       "      <td>0.447</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>672</td>\n",
       "      <td>2.941</td>\n",
       "      <td>3.018</td>\n",
       "      <td>0.831</td>\n",
       "      <td>0.446</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>673</td>\n",
       "      <td>2.941</td>\n",
       "      <td>3.013</td>\n",
       "      <td>0.868</td>\n",
       "      <td>0.446</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>674</td>\n",
       "      <td>2.940</td>\n",
       "      <td>3.013</td>\n",
       "      <td>0.865</td>\n",
       "      <td>0.446</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>675</td>\n",
       "      <td>2.940</td>\n",
       "      <td>3.013</td>\n",
       "      <td>0.867</td>\n",
       "      <td>0.446</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>676</td>\n",
       "      <td>2.940</td>\n",
       "      <td>3.011</td>\n",
       "      <td>0.859</td>\n",
       "      <td>0.447</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>677</td>\n",
       "      <td>2.940</td>\n",
       "      <td>3.014</td>\n",
       "      <td>0.859</td>\n",
       "      <td>0.446</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>678</td>\n",
       "      <td>2.942</td>\n",
       "      <td>3.016</td>\n",
       "      <td>0.833</td>\n",
       "      <td>0.446</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>679</td>\n",
       "      <td>2.943</td>\n",
       "      <td>3.015</td>\n",
       "      <td>0.896</td>\n",
       "      <td>0.446</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>680</td>\n",
       "      <td>2.942</td>\n",
       "      <td>3.014</td>\n",
       "      <td>0.851</td>\n",
       "      <td>0.446</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>681</td>\n",
       "      <td>2.938</td>\n",
       "      <td>3.013</td>\n",
       "      <td>0.867</td>\n",
       "      <td>0.446</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>682</td>\n",
       "      <td>2.939</td>\n",
       "      <td>3.015</td>\n",
       "      <td>0.833</td>\n",
       "      <td>0.446</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>683</td>\n",
       "      <td>2.940</td>\n",
       "      <td>3.013</td>\n",
       "      <td>0.865</td>\n",
       "      <td>0.446</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>684</td>\n",
       "      <td>2.941</td>\n",
       "      <td>3.017</td>\n",
       "      <td>0.854</td>\n",
       "      <td>0.446</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>685</td>\n",
       "      <td>2.941</td>\n",
       "      <td>3.013</td>\n",
       "      <td>0.871</td>\n",
       "      <td>0.446</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>686</td>\n",
       "      <td>2.939</td>\n",
       "      <td>3.013</td>\n",
       "      <td>0.865</td>\n",
       "      <td>0.445</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>687</td>\n",
       "      <td>2.939</td>\n",
       "      <td>3.012</td>\n",
       "      <td>0.851</td>\n",
       "      <td>0.446</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>688</td>\n",
       "      <td>2.939</td>\n",
       "      <td>3.014</td>\n",
       "      <td>0.878</td>\n",
       "      <td>0.446</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>689</td>\n",
       "      <td>2.940</td>\n",
       "      <td>3.012</td>\n",
       "      <td>0.854</td>\n",
       "      <td>0.446</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>690</td>\n",
       "      <td>2.938</td>\n",
       "      <td>3.013</td>\n",
       "      <td>0.854</td>\n",
       "      <td>0.446</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>691</td>\n",
       "      <td>2.938</td>\n",
       "      <td>3.013</td>\n",
       "      <td>0.864</td>\n",
       "      <td>0.445</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>692</td>\n",
       "      <td>2.940</td>\n",
       "      <td>3.014</td>\n",
       "      <td>0.870</td>\n",
       "      <td>0.445</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>693</td>\n",
       "      <td>2.938</td>\n",
       "      <td>3.013</td>\n",
       "      <td>0.856</td>\n",
       "      <td>0.446</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>694</td>\n",
       "      <td>2.940</td>\n",
       "      <td>3.014</td>\n",
       "      <td>0.851</td>\n",
       "      <td>0.445</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>695</td>\n",
       "      <td>2.938</td>\n",
       "      <td>3.013</td>\n",
       "      <td>0.859</td>\n",
       "      <td>0.445</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>696</td>\n",
       "      <td>2.939</td>\n",
       "      <td>3.015</td>\n",
       "      <td>0.842</td>\n",
       "      <td>0.445</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>697</td>\n",
       "      <td>2.940</td>\n",
       "      <td>3.013</td>\n",
       "      <td>0.862</td>\n",
       "      <td>0.445</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>698</td>\n",
       "      <td>2.938</td>\n",
       "      <td>3.014</td>\n",
       "      <td>0.856</td>\n",
       "      <td>0.445</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>699</td>\n",
       "      <td>2.938</td>\n",
       "      <td>3.014</td>\n",
       "      <td>0.856</td>\n",
       "      <td>0.445</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>2.938</td>\n",
       "      <td>3.012</td>\n",
       "      <td>0.851</td>\n",
       "      <td>0.446</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>701</td>\n",
       "      <td>2.939</td>\n",
       "      <td>3.012</td>\n",
       "      <td>0.864</td>\n",
       "      <td>0.446</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>702</td>\n",
       "      <td>2.939</td>\n",
       "      <td>3.012</td>\n",
       "      <td>0.851</td>\n",
       "      <td>0.446</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>703</td>\n",
       "      <td>2.938</td>\n",
       "      <td>3.014</td>\n",
       "      <td>0.865</td>\n",
       "      <td>0.445</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>704</td>\n",
       "      <td>2.939</td>\n",
       "      <td>3.012</td>\n",
       "      <td>0.867</td>\n",
       "      <td>0.446</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>705</td>\n",
       "      <td>2.939</td>\n",
       "      <td>3.015</td>\n",
       "      <td>0.854</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>706</td>\n",
       "      <td>2.940</td>\n",
       "      <td>3.017</td>\n",
       "      <td>0.831</td>\n",
       "      <td>0.445</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>707</td>\n",
       "      <td>2.939</td>\n",
       "      <td>3.012</td>\n",
       "      <td>0.878</td>\n",
       "      <td>0.446</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>708</td>\n",
       "      <td>2.939</td>\n",
       "      <td>3.015</td>\n",
       "      <td>0.853</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>709</td>\n",
       "      <td>2.938</td>\n",
       "      <td>3.011</td>\n",
       "      <td>0.864</td>\n",
       "      <td>0.446</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>710</td>\n",
       "      <td>2.938</td>\n",
       "      <td>3.014</td>\n",
       "      <td>0.865</td>\n",
       "      <td>0.445</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>711</td>\n",
       "      <td>2.939</td>\n",
       "      <td>3.012</td>\n",
       "      <td>0.847</td>\n",
       "      <td>0.446</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>712</td>\n",
       "      <td>2.938</td>\n",
       "      <td>3.015</td>\n",
       "      <td>0.874</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>713</td>\n",
       "      <td>2.939</td>\n",
       "      <td>3.012</td>\n",
       "      <td>0.853</td>\n",
       "      <td>0.446</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>714</td>\n",
       "      <td>2.940</td>\n",
       "      <td>3.015</td>\n",
       "      <td>0.870</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>715</td>\n",
       "      <td>2.939</td>\n",
       "      <td>3.016</td>\n",
       "      <td>0.840</td>\n",
       "      <td>0.445</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>716</td>\n",
       "      <td>2.938</td>\n",
       "      <td>3.014</td>\n",
       "      <td>0.891</td>\n",
       "      <td>0.445</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>717</td>\n",
       "      <td>2.939</td>\n",
       "      <td>3.018</td>\n",
       "      <td>0.831</td>\n",
       "      <td>0.445</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>718</td>\n",
       "      <td>2.940</td>\n",
       "      <td>3.018</td>\n",
       "      <td>0.891</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>719</td>\n",
       "      <td>2.940</td>\n",
       "      <td>3.013</td>\n",
       "      <td>0.851</td>\n",
       "      <td>0.446</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>2.938</td>\n",
       "      <td>3.013</td>\n",
       "      <td>0.867</td>\n",
       "      <td>0.445</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>721</td>\n",
       "      <td>2.939</td>\n",
       "      <td>3.013</td>\n",
       "      <td>0.859</td>\n",
       "      <td>0.445</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>722</td>\n",
       "      <td>2.939</td>\n",
       "      <td>3.013</td>\n",
       "      <td>0.871</td>\n",
       "      <td>0.445</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>723</td>\n",
       "      <td>2.940</td>\n",
       "      <td>3.016</td>\n",
       "      <td>0.836</td>\n",
       "      <td>0.445</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>724</td>\n",
       "      <td>2.937</td>\n",
       "      <td>3.014</td>\n",
       "      <td>0.878</td>\n",
       "      <td>0.445</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>725</td>\n",
       "      <td>2.938</td>\n",
       "      <td>3.012</td>\n",
       "      <td>0.859</td>\n",
       "      <td>0.446</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>726</td>\n",
       "      <td>2.939</td>\n",
       "      <td>3.014</td>\n",
       "      <td>0.854</td>\n",
       "      <td>0.445</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>727</td>\n",
       "      <td>2.937</td>\n",
       "      <td>3.013</td>\n",
       "      <td>0.870</td>\n",
       "      <td>0.445</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>728</td>\n",
       "      <td>2.937</td>\n",
       "      <td>3.015</td>\n",
       "      <td>0.847</td>\n",
       "      <td>0.445</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>729</td>\n",
       "      <td>2.938</td>\n",
       "      <td>3.013</td>\n",
       "      <td>0.871</td>\n",
       "      <td>0.445</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>730</td>\n",
       "      <td>2.940</td>\n",
       "      <td>3.016</td>\n",
       "      <td>0.845</td>\n",
       "      <td>0.445</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>731</td>\n",
       "      <td>2.939</td>\n",
       "      <td>3.013</td>\n",
       "      <td>0.857</td>\n",
       "      <td>0.445</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>732</td>\n",
       "      <td>2.938</td>\n",
       "      <td>3.015</td>\n",
       "      <td>0.857</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>733</td>\n",
       "      <td>2.938</td>\n",
       "      <td>3.012</td>\n",
       "      <td>0.857</td>\n",
       "      <td>0.446</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>734</td>\n",
       "      <td>2.938</td>\n",
       "      <td>3.016</td>\n",
       "      <td>0.870</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>735</td>\n",
       "      <td>2.939</td>\n",
       "      <td>3.014</td>\n",
       "      <td>0.847</td>\n",
       "      <td>0.445</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>736</td>\n",
       "      <td>2.937</td>\n",
       "      <td>3.013</td>\n",
       "      <td>0.874</td>\n",
       "      <td>0.445</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>737</td>\n",
       "      <td>2.939</td>\n",
       "      <td>3.012</td>\n",
       "      <td>0.856</td>\n",
       "      <td>0.445</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>738</td>\n",
       "      <td>2.938</td>\n",
       "      <td>3.015</td>\n",
       "      <td>0.847</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>739</td>\n",
       "      <td>2.938</td>\n",
       "      <td>3.012</td>\n",
       "      <td>0.859</td>\n",
       "      <td>0.445</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>740</td>\n",
       "      <td>2.938</td>\n",
       "      <td>3.013</td>\n",
       "      <td>0.870</td>\n",
       "      <td>0.445</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>741</td>\n",
       "      <td>2.937</td>\n",
       "      <td>3.013</td>\n",
       "      <td>0.848</td>\n",
       "      <td>0.445</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>742</td>\n",
       "      <td>2.938</td>\n",
       "      <td>3.014</td>\n",
       "      <td>0.857</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>743</td>\n",
       "      <td>2.939</td>\n",
       "      <td>3.012</td>\n",
       "      <td>0.876</td>\n",
       "      <td>0.445</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>744</td>\n",
       "      <td>2.937</td>\n",
       "      <td>3.015</td>\n",
       "      <td>0.848</td>\n",
       "      <td>0.445</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>745</td>\n",
       "      <td>2.938</td>\n",
       "      <td>3.014</td>\n",
       "      <td>0.870</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>746</td>\n",
       "      <td>2.938</td>\n",
       "      <td>3.015</td>\n",
       "      <td>0.836</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>747</td>\n",
       "      <td>2.937</td>\n",
       "      <td>3.014</td>\n",
       "      <td>0.864</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>748</td>\n",
       "      <td>2.939</td>\n",
       "      <td>3.011</td>\n",
       "      <td>0.884</td>\n",
       "      <td>0.446</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>749</td>\n",
       "      <td>2.939</td>\n",
       "      <td>3.017</td>\n",
       "      <td>0.834</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>2.941</td>\n",
       "      <td>3.014</td>\n",
       "      <td>0.870</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>751</td>\n",
       "      <td>2.938</td>\n",
       "      <td>3.015</td>\n",
       "      <td>0.853</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>752</td>\n",
       "      <td>2.938</td>\n",
       "      <td>3.013</td>\n",
       "      <td>0.857</td>\n",
       "      <td>0.445</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>753</td>\n",
       "      <td>2.937</td>\n",
       "      <td>3.014</td>\n",
       "      <td>0.865</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>754</td>\n",
       "      <td>2.937</td>\n",
       "      <td>3.012</td>\n",
       "      <td>0.862</td>\n",
       "      <td>0.445</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>755</td>\n",
       "      <td>2.938</td>\n",
       "      <td>3.016</td>\n",
       "      <td>0.837</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>756</td>\n",
       "      <td>2.937</td>\n",
       "      <td>3.012</td>\n",
       "      <td>0.874</td>\n",
       "      <td>0.445</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>757</td>\n",
       "      <td>2.938</td>\n",
       "      <td>3.014</td>\n",
       "      <td>0.848</td>\n",
       "      <td>0.445</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>758</td>\n",
       "      <td>2.937</td>\n",
       "      <td>3.014</td>\n",
       "      <td>0.870</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>759</td>\n",
       "      <td>2.938</td>\n",
       "      <td>3.015</td>\n",
       "      <td>0.853</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>760</td>\n",
       "      <td>2.938</td>\n",
       "      <td>3.013</td>\n",
       "      <td>0.860</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>761</td>\n",
       "      <td>2.937</td>\n",
       "      <td>3.014</td>\n",
       "      <td>0.854</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>762</td>\n",
       "      <td>2.936</td>\n",
       "      <td>3.014</td>\n",
       "      <td>0.874</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>763</td>\n",
       "      <td>2.937</td>\n",
       "      <td>3.014</td>\n",
       "      <td>0.850</td>\n",
       "      <td>0.445</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>764</td>\n",
       "      <td>2.937</td>\n",
       "      <td>3.013</td>\n",
       "      <td>0.870</td>\n",
       "      <td>0.445</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>765</td>\n",
       "      <td>2.939</td>\n",
       "      <td>3.017</td>\n",
       "      <td>0.856</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>766</td>\n",
       "      <td>2.936</td>\n",
       "      <td>3.011</td>\n",
       "      <td>0.868</td>\n",
       "      <td>0.446</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>767</td>\n",
       "      <td>2.938</td>\n",
       "      <td>3.015</td>\n",
       "      <td>0.859</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>768</td>\n",
       "      <td>2.938</td>\n",
       "      <td>3.015</td>\n",
       "      <td>0.868</td>\n",
       "      <td>0.443</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>769</td>\n",
       "      <td>2.938</td>\n",
       "      <td>3.015</td>\n",
       "      <td>0.840</td>\n",
       "      <td>0.445</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>770</td>\n",
       "      <td>2.939</td>\n",
       "      <td>3.015</td>\n",
       "      <td>0.860</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>771</td>\n",
       "      <td>2.938</td>\n",
       "      <td>3.012</td>\n",
       "      <td>0.864</td>\n",
       "      <td>0.445</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>772</td>\n",
       "      <td>2.937</td>\n",
       "      <td>3.014</td>\n",
       "      <td>0.860</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>773</td>\n",
       "      <td>2.937</td>\n",
       "      <td>3.014</td>\n",
       "      <td>0.854</td>\n",
       "      <td>0.445</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>774</td>\n",
       "      <td>2.937</td>\n",
       "      <td>3.014</td>\n",
       "      <td>0.865</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>775</td>\n",
       "      <td>2.937</td>\n",
       "      <td>3.012</td>\n",
       "      <td>0.857</td>\n",
       "      <td>0.445</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>776</td>\n",
       "      <td>2.937</td>\n",
       "      <td>3.013</td>\n",
       "      <td>0.853</td>\n",
       "      <td>0.445</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>777</td>\n",
       "      <td>2.939</td>\n",
       "      <td>3.012</td>\n",
       "      <td>0.868</td>\n",
       "      <td>0.445</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>778</td>\n",
       "      <td>2.938</td>\n",
       "      <td>3.018</td>\n",
       "      <td>0.847</td>\n",
       "      <td>0.443</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>779</td>\n",
       "      <td>2.937</td>\n",
       "      <td>3.012</td>\n",
       "      <td>0.862</td>\n",
       "      <td>0.445</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>2.937</td>\n",
       "      <td>3.014</td>\n",
       "      <td>0.857</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>781</td>\n",
       "      <td>2.938</td>\n",
       "      <td>3.014</td>\n",
       "      <td>0.865</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>782</td>\n",
       "      <td>2.936</td>\n",
       "      <td>3.013</td>\n",
       "      <td>0.848</td>\n",
       "      <td>0.445</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>783</td>\n",
       "      <td>2.936</td>\n",
       "      <td>3.012</td>\n",
       "      <td>0.870</td>\n",
       "      <td>0.445</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>784</td>\n",
       "      <td>2.936</td>\n",
       "      <td>3.016</td>\n",
       "      <td>0.857</td>\n",
       "      <td>0.443</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>785</td>\n",
       "      <td>2.937</td>\n",
       "      <td>3.013</td>\n",
       "      <td>0.854</td>\n",
       "      <td>0.445</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>786</td>\n",
       "      <td>2.936</td>\n",
       "      <td>3.014</td>\n",
       "      <td>0.854</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>787</td>\n",
       "      <td>2.936</td>\n",
       "      <td>3.012</td>\n",
       "      <td>0.865</td>\n",
       "      <td>0.445</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>788</td>\n",
       "      <td>2.939</td>\n",
       "      <td>3.014</td>\n",
       "      <td>0.847</td>\n",
       "      <td>0.445</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>789</td>\n",
       "      <td>2.939</td>\n",
       "      <td>3.015</td>\n",
       "      <td>0.884</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>790</td>\n",
       "      <td>2.939</td>\n",
       "      <td>3.015</td>\n",
       "      <td>0.845</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>791</td>\n",
       "      <td>2.937</td>\n",
       "      <td>3.013</td>\n",
       "      <td>0.870</td>\n",
       "      <td>0.445</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>792</td>\n",
       "      <td>2.936</td>\n",
       "      <td>3.014</td>\n",
       "      <td>0.854</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>793</td>\n",
       "      <td>2.937</td>\n",
       "      <td>3.014</td>\n",
       "      <td>0.870</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>794</td>\n",
       "      <td>2.938</td>\n",
       "      <td>3.014</td>\n",
       "      <td>0.856</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>795</td>\n",
       "      <td>2.935</td>\n",
       "      <td>3.013</td>\n",
       "      <td>0.862</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>796</td>\n",
       "      <td>2.938</td>\n",
       "      <td>3.014</td>\n",
       "      <td>0.854</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>797</td>\n",
       "      <td>2.940</td>\n",
       "      <td>3.010</td>\n",
       "      <td>0.859</td>\n",
       "      <td>0.446</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>798</td>\n",
       "      <td>2.936</td>\n",
       "      <td>3.014</td>\n",
       "      <td>0.857</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>799</td>\n",
       "      <td>2.936</td>\n",
       "      <td>3.015</td>\n",
       "      <td>0.856</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>2.937</td>\n",
       "      <td>3.013</td>\n",
       "      <td>0.857</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>801</td>\n",
       "      <td>2.938</td>\n",
       "      <td>3.013</td>\n",
       "      <td>0.853</td>\n",
       "      <td>0.445</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>802</td>\n",
       "      <td>2.937</td>\n",
       "      <td>3.014</td>\n",
       "      <td>0.865</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>803</td>\n",
       "      <td>2.936</td>\n",
       "      <td>3.015</td>\n",
       "      <td>0.853</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>804</td>\n",
       "      <td>2.936</td>\n",
       "      <td>3.012</td>\n",
       "      <td>0.859</td>\n",
       "      <td>0.445</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>805</td>\n",
       "      <td>2.935</td>\n",
       "      <td>3.014</td>\n",
       "      <td>0.857</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>806</td>\n",
       "      <td>2.936</td>\n",
       "      <td>3.014</td>\n",
       "      <td>0.853</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>807</td>\n",
       "      <td>2.936</td>\n",
       "      <td>3.012</td>\n",
       "      <td>0.865</td>\n",
       "      <td>0.445</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>808</td>\n",
       "      <td>2.935</td>\n",
       "      <td>3.014</td>\n",
       "      <td>0.856</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>809</td>\n",
       "      <td>2.936</td>\n",
       "      <td>3.013</td>\n",
       "      <td>0.853</td>\n",
       "      <td>0.445</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>810</td>\n",
       "      <td>2.936</td>\n",
       "      <td>3.014</td>\n",
       "      <td>0.865</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>811</td>\n",
       "      <td>2.935</td>\n",
       "      <td>3.012</td>\n",
       "      <td>0.859</td>\n",
       "      <td>0.445</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>812</td>\n",
       "      <td>2.939</td>\n",
       "      <td>3.015</td>\n",
       "      <td>0.851</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>813</td>\n",
       "      <td>2.936</td>\n",
       "      <td>3.012</td>\n",
       "      <td>0.870</td>\n",
       "      <td>0.445</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>814</td>\n",
       "      <td>2.937</td>\n",
       "      <td>3.017</td>\n",
       "      <td>0.857</td>\n",
       "      <td>0.443</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>815</td>\n",
       "      <td>2.936</td>\n",
       "      <td>3.012</td>\n",
       "      <td>0.857</td>\n",
       "      <td>0.445</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>816</td>\n",
       "      <td>2.935</td>\n",
       "      <td>3.015</td>\n",
       "      <td>0.864</td>\n",
       "      <td>0.443</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>817</td>\n",
       "      <td>2.935</td>\n",
       "      <td>3.014</td>\n",
       "      <td>0.854</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>818</td>\n",
       "      <td>2.935</td>\n",
       "      <td>3.013</td>\n",
       "      <td>0.853</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>819</td>\n",
       "      <td>2.935</td>\n",
       "      <td>3.014</td>\n",
       "      <td>0.860</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>820</td>\n",
       "      <td>2.936</td>\n",
       "      <td>3.014</td>\n",
       "      <td>0.848</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>821</td>\n",
       "      <td>2.936</td>\n",
       "      <td>3.014</td>\n",
       "      <td>0.857</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>822</td>\n",
       "      <td>2.937</td>\n",
       "      <td>3.014</td>\n",
       "      <td>0.857</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>823</td>\n",
       "      <td>2.937</td>\n",
       "      <td>3.013</td>\n",
       "      <td>0.859</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>824</td>\n",
       "      <td>2.936</td>\n",
       "      <td>3.016</td>\n",
       "      <td>0.848</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>825</td>\n",
       "      <td>2.935</td>\n",
       "      <td>3.013</td>\n",
       "      <td>0.870</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>826</td>\n",
       "      <td>2.937</td>\n",
       "      <td>3.014</td>\n",
       "      <td>0.848</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>827</td>\n",
       "      <td>2.936</td>\n",
       "      <td>3.014</td>\n",
       "      <td>0.857</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>828</td>\n",
       "      <td>2.935</td>\n",
       "      <td>3.013</td>\n",
       "      <td>0.865</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>829</td>\n",
       "      <td>2.935</td>\n",
       "      <td>3.013</td>\n",
       "      <td>0.856</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>830</td>\n",
       "      <td>2.937</td>\n",
       "      <td>3.015</td>\n",
       "      <td>0.870</td>\n",
       "      <td>0.443</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>831</td>\n",
       "      <td>2.936</td>\n",
       "      <td>3.015</td>\n",
       "      <td>0.842</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>832</td>\n",
       "      <td>2.936</td>\n",
       "      <td>3.015</td>\n",
       "      <td>0.867</td>\n",
       "      <td>0.443</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>833</td>\n",
       "      <td>2.937</td>\n",
       "      <td>3.014</td>\n",
       "      <td>0.848</td>\n",
       "      <td>0.445</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>834</td>\n",
       "      <td>2.936</td>\n",
       "      <td>3.016</td>\n",
       "      <td>0.876</td>\n",
       "      <td>0.443</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>835</td>\n",
       "      <td>2.936</td>\n",
       "      <td>3.011</td>\n",
       "      <td>0.853</td>\n",
       "      <td>0.445</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>836</td>\n",
       "      <td>2.936</td>\n",
       "      <td>3.014</td>\n",
       "      <td>0.857</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>837</td>\n",
       "      <td>2.935</td>\n",
       "      <td>3.014</td>\n",
       "      <td>0.864</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>838</td>\n",
       "      <td>2.935</td>\n",
       "      <td>3.014</td>\n",
       "      <td>0.857</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>839</td>\n",
       "      <td>2.935</td>\n",
       "      <td>3.012</td>\n",
       "      <td>0.859</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>2.936</td>\n",
       "      <td>3.014</td>\n",
       "      <td>0.862</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>841</td>\n",
       "      <td>2.935</td>\n",
       "      <td>3.014</td>\n",
       "      <td>0.862</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>842</td>\n",
       "      <td>2.937</td>\n",
       "      <td>3.013</td>\n",
       "      <td>0.859</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>843</td>\n",
       "      <td>2.935</td>\n",
       "      <td>3.014</td>\n",
       "      <td>0.856</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>844</td>\n",
       "      <td>2.935</td>\n",
       "      <td>3.012</td>\n",
       "      <td>0.862</td>\n",
       "      <td>0.445</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>845</td>\n",
       "      <td>2.935</td>\n",
       "      <td>3.015</td>\n",
       "      <td>0.856</td>\n",
       "      <td>0.443</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>846</td>\n",
       "      <td>2.936</td>\n",
       "      <td>3.013</td>\n",
       "      <td>0.867</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>847</td>\n",
       "      <td>2.936</td>\n",
       "      <td>3.013</td>\n",
       "      <td>0.853</td>\n",
       "      <td>0.445</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>848</td>\n",
       "      <td>2.934</td>\n",
       "      <td>3.014</td>\n",
       "      <td>0.868</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>849</td>\n",
       "      <td>2.936</td>\n",
       "      <td>3.014</td>\n",
       "      <td>0.848</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>2.935</td>\n",
       "      <td>3.013</td>\n",
       "      <td>0.859</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>851</td>\n",
       "      <td>2.936</td>\n",
       "      <td>3.015</td>\n",
       "      <td>0.848</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>852</td>\n",
       "      <td>2.935</td>\n",
       "      <td>3.013</td>\n",
       "      <td>0.868</td>\n",
       "      <td>0.445</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>853</td>\n",
       "      <td>2.935</td>\n",
       "      <td>3.014</td>\n",
       "      <td>0.848</td>\n",
       "      <td>0.445</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>854</td>\n",
       "      <td>2.935</td>\n",
       "      <td>3.012</td>\n",
       "      <td>0.867</td>\n",
       "      <td>0.445</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>855</td>\n",
       "      <td>2.935</td>\n",
       "      <td>3.015</td>\n",
       "      <td>0.851</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>856</td>\n",
       "      <td>2.935</td>\n",
       "      <td>3.014</td>\n",
       "      <td>0.857</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>857</td>\n",
       "      <td>2.935</td>\n",
       "      <td>3.013</td>\n",
       "      <td>0.862</td>\n",
       "      <td>0.445</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>858</td>\n",
       "      <td>2.935</td>\n",
       "      <td>3.013</td>\n",
       "      <td>0.854</td>\n",
       "      <td>0.445</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>859</td>\n",
       "      <td>2.936</td>\n",
       "      <td>3.014</td>\n",
       "      <td>0.873</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>860</td>\n",
       "      <td>2.934</td>\n",
       "      <td>3.015</td>\n",
       "      <td>0.848</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>861</td>\n",
       "      <td>2.935</td>\n",
       "      <td>3.013</td>\n",
       "      <td>0.854</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>862</td>\n",
       "      <td>2.935</td>\n",
       "      <td>3.013</td>\n",
       "      <td>0.870</td>\n",
       "      <td>0.445</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>863</td>\n",
       "      <td>2.936</td>\n",
       "      <td>3.016</td>\n",
       "      <td>0.848</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>864</td>\n",
       "      <td>2.935</td>\n",
       "      <td>3.013</td>\n",
       "      <td>0.868</td>\n",
       "      <td>0.445</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>865</td>\n",
       "      <td>2.935</td>\n",
       "      <td>3.014</td>\n",
       "      <td>0.856</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>866</td>\n",
       "      <td>2.935</td>\n",
       "      <td>3.013</td>\n",
       "      <td>0.856</td>\n",
       "      <td>0.445</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>867</td>\n",
       "      <td>2.935</td>\n",
       "      <td>3.013</td>\n",
       "      <td>0.870</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>868</td>\n",
       "      <td>2.935</td>\n",
       "      <td>3.013</td>\n",
       "      <td>0.856</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>869</td>\n",
       "      <td>2.935</td>\n",
       "      <td>3.014</td>\n",
       "      <td>0.857</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>870</td>\n",
       "      <td>2.934</td>\n",
       "      <td>3.014</td>\n",
       "      <td>0.856</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>871</td>\n",
       "      <td>2.934</td>\n",
       "      <td>3.014</td>\n",
       "      <td>0.856</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>872</td>\n",
       "      <td>2.935</td>\n",
       "      <td>3.014</td>\n",
       "      <td>0.856</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>873</td>\n",
       "      <td>2.935</td>\n",
       "      <td>3.012</td>\n",
       "      <td>0.862</td>\n",
       "      <td>0.445</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>874</td>\n",
       "      <td>2.935</td>\n",
       "      <td>3.014</td>\n",
       "      <td>0.856</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>875</td>\n",
       "      <td>2.935</td>\n",
       "      <td>3.014</td>\n",
       "      <td>0.857</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>876</td>\n",
       "      <td>2.935</td>\n",
       "      <td>3.013</td>\n",
       "      <td>0.853</td>\n",
       "      <td>0.445</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>877</td>\n",
       "      <td>2.934</td>\n",
       "      <td>3.015</td>\n",
       "      <td>0.857</td>\n",
       "      <td>0.443</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>878</td>\n",
       "      <td>2.935</td>\n",
       "      <td>3.015</td>\n",
       "      <td>0.868</td>\n",
       "      <td>0.443</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>879</td>\n",
       "      <td>2.935</td>\n",
       "      <td>3.012</td>\n",
       "      <td>0.848</td>\n",
       "      <td>0.445</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>880</td>\n",
       "      <td>2.935</td>\n",
       "      <td>3.013</td>\n",
       "      <td>0.864</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>881</td>\n",
       "      <td>2.934</td>\n",
       "      <td>3.013</td>\n",
       "      <td>0.859</td>\n",
       "      <td>0.445</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>882</td>\n",
       "      <td>2.934</td>\n",
       "      <td>3.014</td>\n",
       "      <td>0.857</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>883</td>\n",
       "      <td>2.934</td>\n",
       "      <td>3.014</td>\n",
       "      <td>0.857</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>884</td>\n",
       "      <td>2.935</td>\n",
       "      <td>3.013</td>\n",
       "      <td>0.856</td>\n",
       "      <td>0.445</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>885</td>\n",
       "      <td>2.934</td>\n",
       "      <td>3.013</td>\n",
       "      <td>0.865</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>886</td>\n",
       "      <td>2.934</td>\n",
       "      <td>3.014</td>\n",
       "      <td>0.859</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>887</td>\n",
       "      <td>2.935</td>\n",
       "      <td>3.013</td>\n",
       "      <td>0.856</td>\n",
       "      <td>0.445</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>888</td>\n",
       "      <td>2.934</td>\n",
       "      <td>3.013</td>\n",
       "      <td>0.857</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>889</td>\n",
       "      <td>2.935</td>\n",
       "      <td>3.013</td>\n",
       "      <td>0.860</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>890</td>\n",
       "      <td>2.935</td>\n",
       "      <td>3.015</td>\n",
       "      <td>0.848</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>891</td>\n",
       "      <td>2.934</td>\n",
       "      <td>3.013</td>\n",
       "      <td>0.860</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>892</td>\n",
       "      <td>2.935</td>\n",
       "      <td>3.013</td>\n",
       "      <td>0.856</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>893</td>\n",
       "      <td>2.934</td>\n",
       "      <td>3.014</td>\n",
       "      <td>0.860</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>894</td>\n",
       "      <td>2.935</td>\n",
       "      <td>3.014</td>\n",
       "      <td>0.865</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>895</td>\n",
       "      <td>2.935</td>\n",
       "      <td>3.014</td>\n",
       "      <td>0.854</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>896</td>\n",
       "      <td>2.934</td>\n",
       "      <td>3.013</td>\n",
       "      <td>0.857</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>897</td>\n",
       "      <td>2.935</td>\n",
       "      <td>3.014</td>\n",
       "      <td>0.856</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>898</td>\n",
       "      <td>2.935</td>\n",
       "      <td>3.014</td>\n",
       "      <td>0.865</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>899</td>\n",
       "      <td>2.935</td>\n",
       "      <td>3.014</td>\n",
       "      <td>0.848</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>2.934</td>\n",
       "      <td>3.014</td>\n",
       "      <td>0.867</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>901</td>\n",
       "      <td>2.934</td>\n",
       "      <td>3.013</td>\n",
       "      <td>0.860</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>902</td>\n",
       "      <td>2.935</td>\n",
       "      <td>3.013</td>\n",
       "      <td>0.856</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>903</td>\n",
       "      <td>2.934</td>\n",
       "      <td>3.014</td>\n",
       "      <td>0.857</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>904</td>\n",
       "      <td>2.935</td>\n",
       "      <td>3.015</td>\n",
       "      <td>0.854</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>905</td>\n",
       "      <td>2.934</td>\n",
       "      <td>3.014</td>\n",
       "      <td>0.857</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>906</td>\n",
       "      <td>2.934</td>\n",
       "      <td>3.013</td>\n",
       "      <td>0.859</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>907</td>\n",
       "      <td>2.935</td>\n",
       "      <td>3.014</td>\n",
       "      <td>0.848</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>908</td>\n",
       "      <td>2.934</td>\n",
       "      <td>3.014</td>\n",
       "      <td>0.857</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>909</td>\n",
       "      <td>2.934</td>\n",
       "      <td>3.013</td>\n",
       "      <td>0.867</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>910</td>\n",
       "      <td>2.934</td>\n",
       "      <td>3.014</td>\n",
       "      <td>0.856</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>911</td>\n",
       "      <td>2.934</td>\n",
       "      <td>3.014</td>\n",
       "      <td>0.856</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>912</td>\n",
       "      <td>2.934</td>\n",
       "      <td>3.014</td>\n",
       "      <td>0.867</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>913</td>\n",
       "      <td>2.934</td>\n",
       "      <td>3.014</td>\n",
       "      <td>0.856</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>914</td>\n",
       "      <td>2.934</td>\n",
       "      <td>3.014</td>\n",
       "      <td>0.856</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>915</td>\n",
       "      <td>2.935</td>\n",
       "      <td>3.014</td>\n",
       "      <td>0.865</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>916</td>\n",
       "      <td>2.934</td>\n",
       "      <td>3.014</td>\n",
       "      <td>0.856</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>917</td>\n",
       "      <td>2.934</td>\n",
       "      <td>3.013</td>\n",
       "      <td>0.856</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>918</td>\n",
       "      <td>2.934</td>\n",
       "      <td>3.013</td>\n",
       "      <td>0.857</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>919</td>\n",
       "      <td>2.934</td>\n",
       "      <td>3.013</td>\n",
       "      <td>0.856</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>920</td>\n",
       "      <td>2.934</td>\n",
       "      <td>3.013</td>\n",
       "      <td>0.857</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>921</td>\n",
       "      <td>2.934</td>\n",
       "      <td>3.013</td>\n",
       "      <td>0.856</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>922</td>\n",
       "      <td>2.934</td>\n",
       "      <td>3.013</td>\n",
       "      <td>0.859</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>923</td>\n",
       "      <td>2.934</td>\n",
       "      <td>3.014</td>\n",
       "      <td>0.857</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>924</td>\n",
       "      <td>2.934</td>\n",
       "      <td>3.013</td>\n",
       "      <td>0.857</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>925</td>\n",
       "      <td>2.934</td>\n",
       "      <td>3.013</td>\n",
       "      <td>0.856</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>926</td>\n",
       "      <td>2.934</td>\n",
       "      <td>3.014</td>\n",
       "      <td>0.857</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>927</td>\n",
       "      <td>2.934</td>\n",
       "      <td>3.014</td>\n",
       "      <td>0.856</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>928</td>\n",
       "      <td>2.935</td>\n",
       "      <td>3.013</td>\n",
       "      <td>0.868</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>929</td>\n",
       "      <td>2.934</td>\n",
       "      <td>3.013</td>\n",
       "      <td>0.856</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>930</td>\n",
       "      <td>2.934</td>\n",
       "      <td>3.013</td>\n",
       "      <td>0.856</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>931</td>\n",
       "      <td>2.934</td>\n",
       "      <td>3.013</td>\n",
       "      <td>0.864</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>932</td>\n",
       "      <td>2.934</td>\n",
       "      <td>3.013</td>\n",
       "      <td>0.857</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>933</td>\n",
       "      <td>2.934</td>\n",
       "      <td>3.013</td>\n",
       "      <td>0.857</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>934</td>\n",
       "      <td>2.934</td>\n",
       "      <td>3.013</td>\n",
       "      <td>0.856</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>935</td>\n",
       "      <td>2.934</td>\n",
       "      <td>3.013</td>\n",
       "      <td>0.857</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>936</td>\n",
       "      <td>2.934</td>\n",
       "      <td>3.013</td>\n",
       "      <td>0.857</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>937</td>\n",
       "      <td>2.934</td>\n",
       "      <td>3.014</td>\n",
       "      <td>0.857</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>938</td>\n",
       "      <td>2.934</td>\n",
       "      <td>3.014</td>\n",
       "      <td>0.857</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>939</td>\n",
       "      <td>2.934</td>\n",
       "      <td>3.014</td>\n",
       "      <td>0.862</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>940</td>\n",
       "      <td>2.934</td>\n",
       "      <td>3.014</td>\n",
       "      <td>0.856</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>941</td>\n",
       "      <td>2.934</td>\n",
       "      <td>3.014</td>\n",
       "      <td>0.856</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>942</td>\n",
       "      <td>2.934</td>\n",
       "      <td>3.014</td>\n",
       "      <td>0.856</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>943</td>\n",
       "      <td>2.934</td>\n",
       "      <td>3.013</td>\n",
       "      <td>0.856</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>944</td>\n",
       "      <td>2.934</td>\n",
       "      <td>3.013</td>\n",
       "      <td>0.857</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>945</td>\n",
       "      <td>2.934</td>\n",
       "      <td>3.013</td>\n",
       "      <td>0.857</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>946</td>\n",
       "      <td>2.934</td>\n",
       "      <td>3.013</td>\n",
       "      <td>0.856</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>947</td>\n",
       "      <td>2.934</td>\n",
       "      <td>3.014</td>\n",
       "      <td>0.857</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>948</td>\n",
       "      <td>2.934</td>\n",
       "      <td>3.014</td>\n",
       "      <td>0.857</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>949</td>\n",
       "      <td>2.934</td>\n",
       "      <td>3.014</td>\n",
       "      <td>0.856</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>2.934</td>\n",
       "      <td>3.014</td>\n",
       "      <td>0.856</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>951</td>\n",
       "      <td>2.934</td>\n",
       "      <td>3.014</td>\n",
       "      <td>0.857</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>952</td>\n",
       "      <td>2.934</td>\n",
       "      <td>3.014</td>\n",
       "      <td>0.857</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>953</td>\n",
       "      <td>2.934</td>\n",
       "      <td>3.014</td>\n",
       "      <td>0.856</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>954</td>\n",
       "      <td>2.934</td>\n",
       "      <td>3.013</td>\n",
       "      <td>0.856</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>955</td>\n",
       "      <td>2.934</td>\n",
       "      <td>3.014</td>\n",
       "      <td>0.857</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>956</td>\n",
       "      <td>2.934</td>\n",
       "      <td>3.014</td>\n",
       "      <td>0.856</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>957</td>\n",
       "      <td>2.934</td>\n",
       "      <td>3.014</td>\n",
       "      <td>0.856</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>958</td>\n",
       "      <td>2.934</td>\n",
       "      <td>3.014</td>\n",
       "      <td>0.856</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>959</td>\n",
       "      <td>2.934</td>\n",
       "      <td>3.014</td>\n",
       "      <td>0.856</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>2.934</td>\n",
       "      <td>3.014</td>\n",
       "      <td>0.856</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>961</td>\n",
       "      <td>2.934</td>\n",
       "      <td>3.013</td>\n",
       "      <td>0.856</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>962</td>\n",
       "      <td>2.934</td>\n",
       "      <td>3.014</td>\n",
       "      <td>0.856</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>963</td>\n",
       "      <td>2.934</td>\n",
       "      <td>3.014</td>\n",
       "      <td>0.856</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>964</td>\n",
       "      <td>2.934</td>\n",
       "      <td>3.014</td>\n",
       "      <td>0.856</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>965</td>\n",
       "      <td>2.934</td>\n",
       "      <td>3.014</td>\n",
       "      <td>0.856</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>966</td>\n",
       "      <td>2.934</td>\n",
       "      <td>3.014</td>\n",
       "      <td>0.856</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>967</td>\n",
       "      <td>2.934</td>\n",
       "      <td>3.014</td>\n",
       "      <td>0.856</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>968</td>\n",
       "      <td>2.934</td>\n",
       "      <td>3.014</td>\n",
       "      <td>0.856</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>969</td>\n",
       "      <td>2.934</td>\n",
       "      <td>3.014</td>\n",
       "      <td>0.856</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>970</td>\n",
       "      <td>2.934</td>\n",
       "      <td>3.014</td>\n",
       "      <td>0.856</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>971</td>\n",
       "      <td>2.934</td>\n",
       "      <td>3.014</td>\n",
       "      <td>0.856</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>972</td>\n",
       "      <td>2.934</td>\n",
       "      <td>3.014</td>\n",
       "      <td>0.856</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>973</td>\n",
       "      <td>2.934</td>\n",
       "      <td>3.014</td>\n",
       "      <td>0.856</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>974</td>\n",
       "      <td>2.934</td>\n",
       "      <td>3.014</td>\n",
       "      <td>0.856</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>975</td>\n",
       "      <td>2.934</td>\n",
       "      <td>3.014</td>\n",
       "      <td>0.856</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>976</td>\n",
       "      <td>2.934</td>\n",
       "      <td>3.014</td>\n",
       "      <td>0.856</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>977</td>\n",
       "      <td>2.934</td>\n",
       "      <td>3.014</td>\n",
       "      <td>0.856</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>978</td>\n",
       "      <td>2.934</td>\n",
       "      <td>3.014</td>\n",
       "      <td>0.856</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>979</td>\n",
       "      <td>2.934</td>\n",
       "      <td>3.014</td>\n",
       "      <td>0.856</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>980</td>\n",
       "      <td>2.934</td>\n",
       "      <td>3.014</td>\n",
       "      <td>0.856</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>981</td>\n",
       "      <td>2.934</td>\n",
       "      <td>3.014</td>\n",
       "      <td>0.856</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>982</td>\n",
       "      <td>2.934</td>\n",
       "      <td>3.014</td>\n",
       "      <td>0.856</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>983</td>\n",
       "      <td>2.934</td>\n",
       "      <td>3.014</td>\n",
       "      <td>0.856</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>984</td>\n",
       "      <td>2.934</td>\n",
       "      <td>3.014</td>\n",
       "      <td>0.856</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>985</td>\n",
       "      <td>2.934</td>\n",
       "      <td>3.014</td>\n",
       "      <td>0.856</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>986</td>\n",
       "      <td>2.934</td>\n",
       "      <td>3.014</td>\n",
       "      <td>0.856</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>987</td>\n",
       "      <td>2.934</td>\n",
       "      <td>3.014</td>\n",
       "      <td>0.856</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>988</td>\n",
       "      <td>2.934</td>\n",
       "      <td>3.014</td>\n",
       "      <td>0.856</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>989</td>\n",
       "      <td>2.934</td>\n",
       "      <td>3.014</td>\n",
       "      <td>0.856</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>990</td>\n",
       "      <td>2.934</td>\n",
       "      <td>3.014</td>\n",
       "      <td>0.856</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>991</td>\n",
       "      <td>2.934</td>\n",
       "      <td>3.014</td>\n",
       "      <td>0.856</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>992</td>\n",
       "      <td>2.934</td>\n",
       "      <td>3.014</td>\n",
       "      <td>0.856</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>993</td>\n",
       "      <td>2.934</td>\n",
       "      <td>3.014</td>\n",
       "      <td>0.856</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>994</td>\n",
       "      <td>2.934</td>\n",
       "      <td>3.014</td>\n",
       "      <td>0.856</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>995</td>\n",
       "      <td>2.934</td>\n",
       "      <td>3.014</td>\n",
       "      <td>0.856</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>996</td>\n",
       "      <td>2.934</td>\n",
       "      <td>3.014</td>\n",
       "      <td>0.856</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>997</td>\n",
       "      <td>2.934</td>\n",
       "      <td>3.014</td>\n",
       "      <td>0.856</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>998</td>\n",
       "      <td>2.934</td>\n",
       "      <td>3.014</td>\n",
       "      <td>0.856</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>999</td>\n",
       "      <td>2.934</td>\n",
       "      <td>3.014</td>\n",
       "      <td>0.856</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>2.934</td>\n",
       "      <td>3.014</td>\n",
       "      <td>0.856</td>\n",
       "      <td>0.444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    " \n",
    "X_train = train[feature_for_nn]\n",
    "X_valid = valid[feature_for_nn]\n",
    "\n",
    "trainset  = TensorDataset(torch.from_numpy(X_train.copy().to_numpy()).float(), torch.from_numpy(y_train.to_numpy()).float())\n",
    "validset  = TensorDataset(torch.from_numpy(X_valid.copy().to_numpy()).float(), torch.from_numpy(y_valid.to_numpy()).float())\n",
    "trainloader = DataLoader(trainset, batch_size = 1024, shuffle=True)\n",
    "\n",
    "mlp_no_class_balancing = train_net(NeuralNetwork_No_Class_Balancing, len(feature_for_nn), trainloader, validset, num_epochs = 1000, lr = 3e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cd4b9df3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC score:  0.79466530334015\n",
      "(True Negatives):  3674\n",
      "(False Positives):  6106\n",
      "(False Negatives):  139\n",
      "(True Positives):  1211\n",
      "Total subscribed Transactions:  1350\n",
      "total loss from loss matrix: 8747\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 500x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lfp = 1\n",
    "lfn = 19\n",
    "tau = lfp/(lfp+lfn)\n",
    "\n",
    "# y_pred = decision_tree.predict(X_valid[feature_for_dt])\n",
    "X_test = test[feature_for_nn]\n",
    "\n",
    "testset  = TensorDataset(torch.from_numpy(X_test.copy().to_numpy()).float(), torch.from_numpy(y_test.to_numpy()).float())\n",
    "\n",
    "y_prob = predict(mlp_no_class_balancing, testset[:][0]).numpy()\n",
    "\n",
    "y_prob[y_prob < 1e-5] = 1e-5 # Log-loss returns NaN if too close to zero or one\n",
    "y_prob[y_prob > 1- 1e-5] =  1- 1e-5\n",
    "\n",
    "print('AUC score: ', roc_auc_score(y_test, y_prob))\n",
    "\n",
    "y_pred = (y_prob > tau).astype(int)\n",
    "\n",
    "plot_cm(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "967141fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel() \n",
    "\n",
    "columns=['Cross-entropy', 'Error Rate', 'AUC', 'Sensitivity', 'Specificity', 'Precision', 'f1-score']\n",
    "\n",
    "results = pd.DataFrame(0.0, columns=columns, index=['mlp'])\n",
    "\n",
    "results.iloc[:,0] =  log_loss(y_test, y_prob)   # Cross entropy\n",
    "results.iloc[:,1] =   1 - accuracy_score(y_test, y_pred)   # Error rate\n",
    "results.iloc[:,2] =  roc_auc_score(y_test, y_prob)   # AUC\n",
    "results.iloc[:,3] =  tp/(tp+fn)   # Sensitivity \n",
    "results.iloc[:,4] =  tn/(tn+fp)   # Specificity\t\n",
    "results.iloc[:,5] =  precision_score(y_test, y_pred)   # Precision\n",
    "results.iloc[:,6] =  f1_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "34128caf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cross-entropy</th>\n",
       "      <th>Error Rate</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>Precision</th>\n",
       "      <th>f1-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>0.29399</td>\n",
       "      <td>0.5611</td>\n",
       "      <td>0.79467</td>\n",
       "      <td>0.89704</td>\n",
       "      <td>0.37566</td>\n",
       "      <td>0.1655</td>\n",
       "      <td>0.27945</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Cross-entropy  Error Rate      AUC  Sensitivity  Specificity  Precision  \\\n",
       "mlp        0.29399      0.5611  0.79467      0.89704      0.37566     0.1655   \n",
       "\n",
       "     f1-score  \n",
       "mlp   0.27945  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(results.sort_values(by=['AUC'], ascending = [0]).round(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee2516b9",
   "metadata": {},
   "source": [
    "# class weight approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6dd379ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import WeightedRandomSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e531804e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2555"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column = train['y']\n",
    "total = train['y'].count()\n",
    "zero_count = column[column==0].count()\n",
    "one_count = total - zero_count\n",
    "one_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "014c3c1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zero weight: 0.5701152579582875, one_weight: 4.0655577299412915\n"
     ]
    }
   ],
   "source": [
    "zero_weight = (1/zero_count) * (total / 2.0)\n",
    "one_weight = (1/one_count) * (total / 2.0)\n",
    "\n",
    "print(f'zero weight: {zero_weight}, one_weight: {one_weight}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0797e1a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    18220\n",
       "1     2555\n",
       "Name: y, dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_counts = train.y.value_counts()\n",
    "class_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5e2a03b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5.48847420417124e-05,\n",
       " 5.48847420417124e-05,\n",
       " 0.0003913894324853229,\n",
       " 0.0003913894324853229,\n",
       " 5.48847420417124e-05]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_weights = [1/class_counts[i] for i in train.y.values]\n",
    "sample_weights[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "76d44c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = WeightedRandomSampler(weights=sample_weights, num_samples=len(y_train), replacement=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d547421b",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = DataLoader(trainset, batch_size = 1024, sampler=sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0e0e0714",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch index 0, 0/1: 512/512\n",
      "batch index 1, 0/1: 527/497\n",
      "batch index 2, 0/1: 511/513\n",
      "batch index 3, 0/1: 519/505\n",
      "batch index 4, 0/1: 521/503\n",
      "batch index 5, 0/1: 494/530\n",
      "batch index 6, 0/1: 503/521\n",
      "batch index 7, 0/1: 528/496\n",
      "batch index 8, 0/1: 513/511\n",
      "batch index 9, 0/1: 520/504\n",
      "batch index 10, 0/1: 509/515\n",
      "batch index 11, 0/1: 512/512\n",
      "batch index 12, 0/1: 508/516\n",
      "batch index 13, 0/1: 517/507\n",
      "batch index 14, 0/1: 539/485\n",
      "batch index 15, 0/1: 504/520\n",
      "batch index 16, 0/1: 510/514\n",
      "batch index 17, 0/1: 529/495\n",
      "batch index 18, 0/1: 511/513\n",
      "batch index 19, 0/1: 497/527\n",
      "batch index 20, 0/1: 149/146\n"
     ]
    }
   ],
   "source": [
    "for i, (data, target) in enumerate(trainloader):\n",
    "    print(\"batch index {}, 0/1: {}/{}\".format(\n",
    "        i,\n",
    "        len(np.where(target.numpy() == 0)[0]),\n",
    "        len(np.where(target.numpy() == 1)[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "74a1bff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "trainloader = DataLoader(trainset, batch_size = 1024, shuffle=True)\n",
    "def train_with_class_weight(model, input_size, trainloader, validset, trial=None, num_epochs = 5 , lr = 1e-3):\n",
    "    \n",
    "    # Get device\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    if trial == None:\n",
    "        # Instantiate model and move to device\n",
    "        net = model(input_size).to(device)\n",
    "    else:\n",
    "        net = model(input_size, trial).to(device)\n",
    "    \n",
    "    # Loss function\n",
    "    loss_fn = nn.BCELoss() # binary cross-entropy loss, assumes that the output of the network is a probability\n",
    "    \n",
    "    # Instantiate optimiser\n",
    "    # Adam is a variant of SGD that often works well for training neural networks\n",
    "    # https://pytorch.org/docs/stable/generated/torch.optim.Adam.html\n",
    "    optimiser = torch.optim.Adam(net.parameters(), lr = lr) \n",
    "    \n",
    "    # Addding a learning rate scheduler to improve training\n",
    "    # Adam + OneCycleLR is a good default for many problems\n",
    "    # Learn more: https://sgugger.github.io/the-1cycle-policy.html\n",
    "    scheduler = torch.optim.lr_scheduler.OneCycleLR(optimiser, max_lr = lr, \n",
    "                                                   steps_per_epoch=len(trainloader), epochs = num_epochs,\n",
    "                                                   three_phase=True)\n",
    "    # Number of training samples\n",
    "    num_samples = len(trainloader.dataset)\n",
    "    \n",
    "    # Initialise table to track training\n",
    "    table =  init_training_table(num_epochs)\n",
    "    \n",
    "    # Training loop\n",
    "    print('Running first epoch')\n",
    "    for epoch in range(num_epochs):\n",
    "        \n",
    "        # Make sure that the model is on training mode\n",
    "        net.train()\n",
    "        \n",
    "        # Initialise timer\n",
    "        epoch_start = time.time()\n",
    "        \n",
    "        # Initialise metric\n",
    "        train_loss = 0.0\n",
    "        \n",
    "        # Iterate over minibatches\n",
    "        for X, y in trainloader:\n",
    "\n",
    "            # Move minibatch to device\n",
    "            X_g = X.to(device)\n",
    "            y_g = y.to(device)\n",
    "\n",
    "            # Reset the gradient\n",
    "            optimiser.zero_grad()\n",
    "\n",
    "            # Compute predictions\n",
    "            output = net(X_g)\n",
    "            \n",
    "#             print(output)\n",
    "#             print(y_g)\n",
    "            # Evaluate cost function\n",
    "            loss = loss_fn(output, y_g)\n",
    "\n",
    "            # Compute gradient \n",
    "            loss.backward()\n",
    "\n",
    "            # Update parameters\n",
    "            optimiser.step()\n",
    "            \n",
    "            # Update scheduler\n",
    "            scheduler.step()\n",
    "            \n",
    "            # Keep track of the training loss\n",
    "            l = loss.cpu().detach().numpy()\n",
    "            train_loss +=  l*(len(y)/num_samples)\n",
    "  \n",
    "        # Epoch length\n",
    "        duration = time.time() - epoch_start \n",
    "        \n",
    "        # Display metrics\n",
    "        if trial == None:\n",
    "            table.iloc[epoch, 1] = np.round(10*train_loss, 3)\n",
    "            table =  update_training_table(table, net, validset, epoch, duration)\n",
    "    \n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "afe9b609",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "126cc3cf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train loss</th>\n",
       "      <th>valid loss</th>\n",
       "      <th>valid recall</th>\n",
       "      <th>valid average precision</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>161.350</td>\n",
       "      <td>88.245</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.085</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>65.127</td>\n",
       "      <td>39.750</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.086</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>25.860</td>\n",
       "      <td>12.355</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.088</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>6.747</td>\n",
       "      <td>3.819</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.208</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>3.746</td>\n",
       "      <td>3.861</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.213</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>3.870</td>\n",
       "      <td>3.887</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.364</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>3.753</td>\n",
       "      <td>3.713</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.400</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>3.700</td>\n",
       "      <td>3.714</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.402</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>3.669</td>\n",
       "      <td>3.688</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.405</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>3.650</td>\n",
       "      <td>3.664</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.404</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>3.628</td>\n",
       "      <td>3.643</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.404</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>3.605</td>\n",
       "      <td>3.620</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.404</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>3.580</td>\n",
       "      <td>3.593</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.403</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>3.553</td>\n",
       "      <td>3.567</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.403</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>3.525</td>\n",
       "      <td>3.539</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.402</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>3.499</td>\n",
       "      <td>3.514</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.402</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>3.474</td>\n",
       "      <td>3.485</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.398</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>3.412</td>\n",
       "      <td>3.411</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.393</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>3.390</td>\n",
       "      <td>3.407</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.393</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>3.387</td>\n",
       "      <td>3.407</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.396</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>3.383</td>\n",
       "      <td>3.404</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.398</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>3.382</td>\n",
       "      <td>3.401</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.401</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>3.379</td>\n",
       "      <td>3.398</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.402</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>3.375</td>\n",
       "      <td>3.393</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.403</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>3.370</td>\n",
       "      <td>3.390</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.405</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>3.371</td>\n",
       "      <td>3.384</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.402</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>3.360</td>\n",
       "      <td>3.388</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.385</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>3.363</td>\n",
       "      <td>3.385</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.411</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>3.361</td>\n",
       "      <td>3.374</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.411</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>3.358</td>\n",
       "      <td>3.369</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.411</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>3.350</td>\n",
       "      <td>3.388</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.395</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>3.334</td>\n",
       "      <td>3.357</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.399</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>3.319</td>\n",
       "      <td>3.337</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.402</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>3.302</td>\n",
       "      <td>3.346</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.405</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>3.294</td>\n",
       "      <td>3.304</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.407</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>3.284</td>\n",
       "      <td>3.285</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.409</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>3.271</td>\n",
       "      <td>3.369</td>\n",
       "      <td>0.964</td>\n",
       "      <td>0.413</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>3.300</td>\n",
       "      <td>3.282</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.414</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>3.233</td>\n",
       "      <td>3.331</td>\n",
       "      <td>0.904</td>\n",
       "      <td>0.415</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>3.228</td>\n",
       "      <td>3.299</td>\n",
       "      <td>0.888</td>\n",
       "      <td>0.417</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>3.233</td>\n",
       "      <td>3.271</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.418</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>3.198</td>\n",
       "      <td>3.191</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.420</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>3.152</td>\n",
       "      <td>3.183</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.421</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>3.262</td>\n",
       "      <td>4.151</td>\n",
       "      <td>0.611</td>\n",
       "      <td>0.276</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>3.743</td>\n",
       "      <td>3.513</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.430</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>3.407</td>\n",
       "      <td>3.410</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.413</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>3.287</td>\n",
       "      <td>3.368</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.385</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>3.261</td>\n",
       "      <td>3.625</td>\n",
       "      <td>0.671</td>\n",
       "      <td>0.424</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>3.280</td>\n",
       "      <td>3.459</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.384</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>3.232</td>\n",
       "      <td>3.226</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.393</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>3.258</td>\n",
       "      <td>3.430</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.385</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>3.208</td>\n",
       "      <td>3.377</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.386</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>3.185</td>\n",
       "      <td>3.181</td>\n",
       "      <td>0.936</td>\n",
       "      <td>0.417</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>3.187</td>\n",
       "      <td>3.381</td>\n",
       "      <td>0.699</td>\n",
       "      <td>0.422</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>3.248</td>\n",
       "      <td>3.184</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.395</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>3.192</td>\n",
       "      <td>3.268</td>\n",
       "      <td>0.727</td>\n",
       "      <td>0.424</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>3.149</td>\n",
       "      <td>3.144</td>\n",
       "      <td>0.935</td>\n",
       "      <td>0.416</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>3.135</td>\n",
       "      <td>3.441</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.395</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>3.219</td>\n",
       "      <td>3.338</td>\n",
       "      <td>0.699</td>\n",
       "      <td>0.423</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>3.170</td>\n",
       "      <td>3.190</td>\n",
       "      <td>0.781</td>\n",
       "      <td>0.424</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61</td>\n",
       "      <td>3.112</td>\n",
       "      <td>3.289</td>\n",
       "      <td>0.712</td>\n",
       "      <td>0.425</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62</td>\n",
       "      <td>3.137</td>\n",
       "      <td>3.252</td>\n",
       "      <td>0.719</td>\n",
       "      <td>0.427</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>63</td>\n",
       "      <td>3.123</td>\n",
       "      <td>3.126</td>\n",
       "      <td>0.961</td>\n",
       "      <td>0.426</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>3.241</td>\n",
       "      <td>3.305</td>\n",
       "      <td>0.707</td>\n",
       "      <td>0.425</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65</td>\n",
       "      <td>3.205</td>\n",
       "      <td>3.134</td>\n",
       "      <td>0.983</td>\n",
       "      <td>0.405</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66</td>\n",
       "      <td>3.098</td>\n",
       "      <td>3.130</td>\n",
       "      <td>0.873</td>\n",
       "      <td>0.428</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>67</td>\n",
       "      <td>3.079</td>\n",
       "      <td>3.224</td>\n",
       "      <td>0.724</td>\n",
       "      <td>0.425</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68</td>\n",
       "      <td>3.147</td>\n",
       "      <td>3.113</td>\n",
       "      <td>0.882</td>\n",
       "      <td>0.426</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69</td>\n",
       "      <td>3.076</td>\n",
       "      <td>3.444</td>\n",
       "      <td>0.682</td>\n",
       "      <td>0.433</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>3.110</td>\n",
       "      <td>3.168</td>\n",
       "      <td>0.995</td>\n",
       "      <td>0.417</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>71</td>\n",
       "      <td>3.095</td>\n",
       "      <td>3.468</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.405</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72</td>\n",
       "      <td>3.127</td>\n",
       "      <td>3.276</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.415</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>73</td>\n",
       "      <td>3.204</td>\n",
       "      <td>3.154</td>\n",
       "      <td>0.775</td>\n",
       "      <td>0.427</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>74</td>\n",
       "      <td>3.100</td>\n",
       "      <td>3.136</td>\n",
       "      <td>0.984</td>\n",
       "      <td>0.420</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>3.073</td>\n",
       "      <td>3.312</td>\n",
       "      <td>0.696</td>\n",
       "      <td>0.433</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>76</td>\n",
       "      <td>3.084</td>\n",
       "      <td>3.122</td>\n",
       "      <td>0.967</td>\n",
       "      <td>0.429</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>77</td>\n",
       "      <td>3.137</td>\n",
       "      <td>3.134</td>\n",
       "      <td>0.792</td>\n",
       "      <td>0.430</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78</td>\n",
       "      <td>3.058</td>\n",
       "      <td>3.096</td>\n",
       "      <td>0.882</td>\n",
       "      <td>0.430</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>79</td>\n",
       "      <td>3.087</td>\n",
       "      <td>3.146</td>\n",
       "      <td>0.984</td>\n",
       "      <td>0.426</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>3.065</td>\n",
       "      <td>3.094</td>\n",
       "      <td>0.870</td>\n",
       "      <td>0.430</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>81</td>\n",
       "      <td>3.066</td>\n",
       "      <td>3.095</td>\n",
       "      <td>0.857</td>\n",
       "      <td>0.432</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>82</td>\n",
       "      <td>3.043</td>\n",
       "      <td>3.092</td>\n",
       "      <td>0.868</td>\n",
       "      <td>0.431</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>83</td>\n",
       "      <td>3.042</td>\n",
       "      <td>3.091</td>\n",
       "      <td>0.867</td>\n",
       "      <td>0.433</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>84</td>\n",
       "      <td>3.050</td>\n",
       "      <td>3.089</td>\n",
       "      <td>0.876</td>\n",
       "      <td>0.431</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85</td>\n",
       "      <td>3.053</td>\n",
       "      <td>3.090</td>\n",
       "      <td>0.850</td>\n",
       "      <td>0.434</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>86</td>\n",
       "      <td>3.037</td>\n",
       "      <td>3.149</td>\n",
       "      <td>0.971</td>\n",
       "      <td>0.429</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>87</td>\n",
       "      <td>3.102</td>\n",
       "      <td>3.179</td>\n",
       "      <td>0.721</td>\n",
       "      <td>0.433</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>88</td>\n",
       "      <td>3.077</td>\n",
       "      <td>3.104</td>\n",
       "      <td>0.941</td>\n",
       "      <td>0.429</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>89</td>\n",
       "      <td>3.083</td>\n",
       "      <td>3.116</td>\n",
       "      <td>0.952</td>\n",
       "      <td>0.429</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>3.048</td>\n",
       "      <td>3.140</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.431</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>91</td>\n",
       "      <td>3.053</td>\n",
       "      <td>3.088</td>\n",
       "      <td>0.904</td>\n",
       "      <td>0.431</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>92</td>\n",
       "      <td>3.042</td>\n",
       "      <td>3.114</td>\n",
       "      <td>0.947</td>\n",
       "      <td>0.429</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>93</td>\n",
       "      <td>3.066</td>\n",
       "      <td>3.083</td>\n",
       "      <td>0.895</td>\n",
       "      <td>0.434</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>94</td>\n",
       "      <td>3.059</td>\n",
       "      <td>3.086</td>\n",
       "      <td>0.907</td>\n",
       "      <td>0.432</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95</td>\n",
       "      <td>3.039</td>\n",
       "      <td>3.082</td>\n",
       "      <td>0.864</td>\n",
       "      <td>0.434</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>3.034</td>\n",
       "      <td>3.118</td>\n",
       "      <td>0.786</td>\n",
       "      <td>0.432</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>97</td>\n",
       "      <td>3.034</td>\n",
       "      <td>3.092</td>\n",
       "      <td>0.828</td>\n",
       "      <td>0.432</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98</td>\n",
       "      <td>3.036</td>\n",
       "      <td>3.098</td>\n",
       "      <td>0.816</td>\n",
       "      <td>0.434</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>99</td>\n",
       "      <td>3.037</td>\n",
       "      <td>3.079</td>\n",
       "      <td>0.876</td>\n",
       "      <td>0.434</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>3.043</td>\n",
       "      <td>3.094</td>\n",
       "      <td>0.927</td>\n",
       "      <td>0.431</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>101</td>\n",
       "      <td>3.030</td>\n",
       "      <td>3.079</td>\n",
       "      <td>0.868</td>\n",
       "      <td>0.436</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>102</td>\n",
       "      <td>3.025</td>\n",
       "      <td>3.079</td>\n",
       "      <td>0.868</td>\n",
       "      <td>0.436</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>103</td>\n",
       "      <td>3.029</td>\n",
       "      <td>3.082</td>\n",
       "      <td>0.901</td>\n",
       "      <td>0.434</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>104</td>\n",
       "      <td>3.029</td>\n",
       "      <td>3.087</td>\n",
       "      <td>0.834</td>\n",
       "      <td>0.435</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>105</td>\n",
       "      <td>3.035</td>\n",
       "      <td>3.082</td>\n",
       "      <td>0.901</td>\n",
       "      <td>0.435</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>106</td>\n",
       "      <td>3.045</td>\n",
       "      <td>3.085</td>\n",
       "      <td>0.836</td>\n",
       "      <td>0.438</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>107</td>\n",
       "      <td>3.028</td>\n",
       "      <td>3.078</td>\n",
       "      <td>0.885</td>\n",
       "      <td>0.435</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>108</td>\n",
       "      <td>3.024</td>\n",
       "      <td>3.077</td>\n",
       "      <td>0.868</td>\n",
       "      <td>0.434</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>109</td>\n",
       "      <td>3.024</td>\n",
       "      <td>3.077</td>\n",
       "      <td>0.868</td>\n",
       "      <td>0.434</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>3.023</td>\n",
       "      <td>3.078</td>\n",
       "      <td>0.864</td>\n",
       "      <td>0.436</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>111</td>\n",
       "      <td>3.022</td>\n",
       "      <td>3.077</td>\n",
       "      <td>0.871</td>\n",
       "      <td>0.435</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>112</td>\n",
       "      <td>3.025</td>\n",
       "      <td>3.078</td>\n",
       "      <td>0.895</td>\n",
       "      <td>0.436</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>113</td>\n",
       "      <td>3.024</td>\n",
       "      <td>3.078</td>\n",
       "      <td>0.891</td>\n",
       "      <td>0.435</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>114</td>\n",
       "      <td>3.022</td>\n",
       "      <td>3.081</td>\n",
       "      <td>0.845</td>\n",
       "      <td>0.439</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>115</td>\n",
       "      <td>3.022</td>\n",
       "      <td>3.081</td>\n",
       "      <td>0.845</td>\n",
       "      <td>0.439</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>116</td>\n",
       "      <td>3.027</td>\n",
       "      <td>3.077</td>\n",
       "      <td>0.885</td>\n",
       "      <td>0.436</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>117</td>\n",
       "      <td>3.021</td>\n",
       "      <td>3.077</td>\n",
       "      <td>0.864</td>\n",
       "      <td>0.438</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>118</td>\n",
       "      <td>3.022</td>\n",
       "      <td>3.078</td>\n",
       "      <td>0.857</td>\n",
       "      <td>0.437</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>119</td>\n",
       "      <td>3.021</td>\n",
       "      <td>3.076</td>\n",
       "      <td>0.871</td>\n",
       "      <td>0.438</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>3.021</td>\n",
       "      <td>3.076</td>\n",
       "      <td>0.876</td>\n",
       "      <td>0.437</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>121</td>\n",
       "      <td>3.022</td>\n",
       "      <td>3.077</td>\n",
       "      <td>0.890</td>\n",
       "      <td>0.435</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>122</td>\n",
       "      <td>3.026</td>\n",
       "      <td>3.080</td>\n",
       "      <td>0.845</td>\n",
       "      <td>0.439</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>123</td>\n",
       "      <td>3.025</td>\n",
       "      <td>3.083</td>\n",
       "      <td>0.840</td>\n",
       "      <td>0.439</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>124</td>\n",
       "      <td>3.024</td>\n",
       "      <td>3.078</td>\n",
       "      <td>0.895</td>\n",
       "      <td>0.435</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>3.025</td>\n",
       "      <td>3.077</td>\n",
       "      <td>0.890</td>\n",
       "      <td>0.435</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>126</td>\n",
       "      <td>3.025</td>\n",
       "      <td>3.082</td>\n",
       "      <td>0.842</td>\n",
       "      <td>0.439</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>127</td>\n",
       "      <td>3.023</td>\n",
       "      <td>3.079</td>\n",
       "      <td>0.847</td>\n",
       "      <td>0.439</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>128</td>\n",
       "      <td>3.023</td>\n",
       "      <td>3.080</td>\n",
       "      <td>0.901</td>\n",
       "      <td>0.436</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>129</td>\n",
       "      <td>3.024</td>\n",
       "      <td>3.083</td>\n",
       "      <td>0.834</td>\n",
       "      <td>0.438</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>3.022</td>\n",
       "      <td>3.076</td>\n",
       "      <td>0.862</td>\n",
       "      <td>0.437</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>131</td>\n",
       "      <td>3.021</td>\n",
       "      <td>3.076</td>\n",
       "      <td>0.885</td>\n",
       "      <td>0.437</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>132</td>\n",
       "      <td>3.024</td>\n",
       "      <td>3.076</td>\n",
       "      <td>0.860</td>\n",
       "      <td>0.437</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>133</td>\n",
       "      <td>3.025</td>\n",
       "      <td>3.088</td>\n",
       "      <td>0.825</td>\n",
       "      <td>0.435</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>134</td>\n",
       "      <td>3.025</td>\n",
       "      <td>3.076</td>\n",
       "      <td>0.865</td>\n",
       "      <td>0.437</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>135</td>\n",
       "      <td>3.023</td>\n",
       "      <td>3.076</td>\n",
       "      <td>0.885</td>\n",
       "      <td>0.436</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>136</td>\n",
       "      <td>3.021</td>\n",
       "      <td>3.076</td>\n",
       "      <td>0.865</td>\n",
       "      <td>0.438</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>137</td>\n",
       "      <td>3.021</td>\n",
       "      <td>3.076</td>\n",
       "      <td>0.865</td>\n",
       "      <td>0.438</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>138</td>\n",
       "      <td>3.022</td>\n",
       "      <td>3.077</td>\n",
       "      <td>0.856</td>\n",
       "      <td>0.438</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>139</td>\n",
       "      <td>3.021</td>\n",
       "      <td>3.080</td>\n",
       "      <td>0.845</td>\n",
       "      <td>0.439</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>3.022</td>\n",
       "      <td>3.076</td>\n",
       "      <td>0.860</td>\n",
       "      <td>0.438</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>141</td>\n",
       "      <td>3.020</td>\n",
       "      <td>3.075</td>\n",
       "      <td>0.881</td>\n",
       "      <td>0.437</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>142</td>\n",
       "      <td>3.023</td>\n",
       "      <td>3.082</td>\n",
       "      <td>0.836</td>\n",
       "      <td>0.439</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>143</td>\n",
       "      <td>3.021</td>\n",
       "      <td>3.075</td>\n",
       "      <td>0.873</td>\n",
       "      <td>0.437</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>144</td>\n",
       "      <td>3.023</td>\n",
       "      <td>3.077</td>\n",
       "      <td>0.896</td>\n",
       "      <td>0.437</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>145</td>\n",
       "      <td>3.027</td>\n",
       "      <td>3.076</td>\n",
       "      <td>0.862</td>\n",
       "      <td>0.438</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>146</td>\n",
       "      <td>3.025</td>\n",
       "      <td>3.085</td>\n",
       "      <td>0.831</td>\n",
       "      <td>0.439</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>147</td>\n",
       "      <td>3.023</td>\n",
       "      <td>3.076</td>\n",
       "      <td>0.862</td>\n",
       "      <td>0.438</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>148</td>\n",
       "      <td>3.021</td>\n",
       "      <td>3.083</td>\n",
       "      <td>0.834</td>\n",
       "      <td>0.439</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>149</td>\n",
       "      <td>3.023</td>\n",
       "      <td>3.078</td>\n",
       "      <td>0.899</td>\n",
       "      <td>0.437</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>3.022</td>\n",
       "      <td>3.078</td>\n",
       "      <td>0.847</td>\n",
       "      <td>0.438</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>151</td>\n",
       "      <td>3.021</td>\n",
       "      <td>3.076</td>\n",
       "      <td>0.856</td>\n",
       "      <td>0.438</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>152</td>\n",
       "      <td>3.021</td>\n",
       "      <td>3.076</td>\n",
       "      <td>0.856</td>\n",
       "      <td>0.438</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>153</td>\n",
       "      <td>3.021</td>\n",
       "      <td>3.075</td>\n",
       "      <td>0.888</td>\n",
       "      <td>0.435</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>154</td>\n",
       "      <td>3.021</td>\n",
       "      <td>3.077</td>\n",
       "      <td>0.850</td>\n",
       "      <td>0.437</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>155</td>\n",
       "      <td>3.021</td>\n",
       "      <td>3.077</td>\n",
       "      <td>0.851</td>\n",
       "      <td>0.438</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>156</td>\n",
       "      <td>3.022</td>\n",
       "      <td>3.076</td>\n",
       "      <td>0.893</td>\n",
       "      <td>0.437</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>157</td>\n",
       "      <td>3.021</td>\n",
       "      <td>3.078</td>\n",
       "      <td>0.845</td>\n",
       "      <td>0.438</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>158</td>\n",
       "      <td>3.019</td>\n",
       "      <td>3.075</td>\n",
       "      <td>0.882</td>\n",
       "      <td>0.435</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>159</td>\n",
       "      <td>3.019</td>\n",
       "      <td>3.077</td>\n",
       "      <td>0.850</td>\n",
       "      <td>0.438</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>3.020</td>\n",
       "      <td>3.075</td>\n",
       "      <td>0.888</td>\n",
       "      <td>0.436</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>161</td>\n",
       "      <td>3.020</td>\n",
       "      <td>3.079</td>\n",
       "      <td>0.845</td>\n",
       "      <td>0.438</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>162</td>\n",
       "      <td>3.019</td>\n",
       "      <td>3.075</td>\n",
       "      <td>0.887</td>\n",
       "      <td>0.435</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>163</td>\n",
       "      <td>3.022</td>\n",
       "      <td>3.079</td>\n",
       "      <td>0.842</td>\n",
       "      <td>0.439</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>164</td>\n",
       "      <td>3.021</td>\n",
       "      <td>3.074</td>\n",
       "      <td>0.874</td>\n",
       "      <td>0.437</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>165</td>\n",
       "      <td>3.020</td>\n",
       "      <td>3.075</td>\n",
       "      <td>0.856</td>\n",
       "      <td>0.438</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>166</td>\n",
       "      <td>3.019</td>\n",
       "      <td>3.074</td>\n",
       "      <td>0.878</td>\n",
       "      <td>0.436</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>167</td>\n",
       "      <td>3.019</td>\n",
       "      <td>3.078</td>\n",
       "      <td>0.845</td>\n",
       "      <td>0.439</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>168</td>\n",
       "      <td>3.021</td>\n",
       "      <td>3.074</td>\n",
       "      <td>0.864</td>\n",
       "      <td>0.438</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>169</td>\n",
       "      <td>3.020</td>\n",
       "      <td>3.076</td>\n",
       "      <td>0.856</td>\n",
       "      <td>0.438</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>3.019</td>\n",
       "      <td>3.075</td>\n",
       "      <td>0.862</td>\n",
       "      <td>0.438</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>171</td>\n",
       "      <td>3.019</td>\n",
       "      <td>3.075</td>\n",
       "      <td>0.862</td>\n",
       "      <td>0.438</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>172</td>\n",
       "      <td>3.019</td>\n",
       "      <td>3.075</td>\n",
       "      <td>0.862</td>\n",
       "      <td>0.438</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>173</td>\n",
       "      <td>3.019</td>\n",
       "      <td>3.075</td>\n",
       "      <td>0.860</td>\n",
       "      <td>0.438</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>174</td>\n",
       "      <td>3.019</td>\n",
       "      <td>3.074</td>\n",
       "      <td>0.871</td>\n",
       "      <td>0.437</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>3.019</td>\n",
       "      <td>3.074</td>\n",
       "      <td>0.864</td>\n",
       "      <td>0.438</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>176</td>\n",
       "      <td>3.019</td>\n",
       "      <td>3.074</td>\n",
       "      <td>0.864</td>\n",
       "      <td>0.438</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>177</td>\n",
       "      <td>3.019</td>\n",
       "      <td>3.074</td>\n",
       "      <td>0.870</td>\n",
       "      <td>0.438</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>178</td>\n",
       "      <td>3.019</td>\n",
       "      <td>3.075</td>\n",
       "      <td>0.856</td>\n",
       "      <td>0.438</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>179</td>\n",
       "      <td>3.019</td>\n",
       "      <td>3.074</td>\n",
       "      <td>0.871</td>\n",
       "      <td>0.438</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>3.019</td>\n",
       "      <td>3.076</td>\n",
       "      <td>0.854</td>\n",
       "      <td>0.438</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>181</td>\n",
       "      <td>3.019</td>\n",
       "      <td>3.074</td>\n",
       "      <td>0.870</td>\n",
       "      <td>0.438</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>182</td>\n",
       "      <td>3.019</td>\n",
       "      <td>3.074</td>\n",
       "      <td>0.870</td>\n",
       "      <td>0.438</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>183</td>\n",
       "      <td>3.018</td>\n",
       "      <td>3.075</td>\n",
       "      <td>0.857</td>\n",
       "      <td>0.438</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>184</td>\n",
       "      <td>3.019</td>\n",
       "      <td>3.074</td>\n",
       "      <td>0.864</td>\n",
       "      <td>0.438</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>185</td>\n",
       "      <td>3.018</td>\n",
       "      <td>3.074</td>\n",
       "      <td>0.865</td>\n",
       "      <td>0.438</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>186</td>\n",
       "      <td>3.018</td>\n",
       "      <td>3.075</td>\n",
       "      <td>0.862</td>\n",
       "      <td>0.438</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>187</td>\n",
       "      <td>3.018</td>\n",
       "      <td>3.074</td>\n",
       "      <td>0.864</td>\n",
       "      <td>0.438</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>188</td>\n",
       "      <td>3.018</td>\n",
       "      <td>3.074</td>\n",
       "      <td>0.865</td>\n",
       "      <td>0.438</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>189</td>\n",
       "      <td>3.018</td>\n",
       "      <td>3.074</td>\n",
       "      <td>0.864</td>\n",
       "      <td>0.438</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>3.019</td>\n",
       "      <td>3.074</td>\n",
       "      <td>0.870</td>\n",
       "      <td>0.438</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>191</td>\n",
       "      <td>3.018</td>\n",
       "      <td>3.074</td>\n",
       "      <td>0.862</td>\n",
       "      <td>0.438</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>192</td>\n",
       "      <td>3.019</td>\n",
       "      <td>3.075</td>\n",
       "      <td>0.862</td>\n",
       "      <td>0.438</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>193</td>\n",
       "      <td>3.019</td>\n",
       "      <td>3.074</td>\n",
       "      <td>0.865</td>\n",
       "      <td>0.438</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>194</td>\n",
       "      <td>3.018</td>\n",
       "      <td>3.074</td>\n",
       "      <td>0.864</td>\n",
       "      <td>0.438</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>195</td>\n",
       "      <td>3.018</td>\n",
       "      <td>3.074</td>\n",
       "      <td>0.862</td>\n",
       "      <td>0.438</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>196</td>\n",
       "      <td>3.018</td>\n",
       "      <td>3.074</td>\n",
       "      <td>0.862</td>\n",
       "      <td>0.438</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>197</td>\n",
       "      <td>3.018</td>\n",
       "      <td>3.074</td>\n",
       "      <td>0.862</td>\n",
       "      <td>0.438</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>198</td>\n",
       "      <td>3.018</td>\n",
       "      <td>3.074</td>\n",
       "      <td>0.862</td>\n",
       "      <td>0.438</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>199</td>\n",
       "      <td>3.018</td>\n",
       "      <td>3.074</td>\n",
       "      <td>0.862</td>\n",
       "      <td>0.438</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>3.018</td>\n",
       "      <td>3.074</td>\n",
       "      <td>0.862</td>\n",
       "      <td>0.438</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    " mlp_with_class_weights = train_with_class_weight(NeuralNetwork_No_Class_Balancing, len(feature_for_nn), trainloader, validset, num_epochs =200, lr = 3e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "29b3d761",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC score:  0.5\n",
      "(True Negatives):  0\n",
      "(False Positives):  4549\n",
      "(False Negatives):  0\n",
      "(True Positives):  645\n",
      "Total subscribed Transactions:  645\n",
      "total loss from loss matrix: 4549\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 500x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lfp = 1\n",
    "lfn = 19\n",
    "tau = lfp/(lfp+lfn)\n",
    "\n",
    "# y_pred = decision_tree.predict(X_valid[feature_for_dt])\n",
    "\n",
    "y_prob = predict(mlp_with_class_weights, validset[:][0]).numpy()\n",
    "\n",
    "y_prob[y_prob < 1e-5] = 1e-5 # Log-loss returns NaN if too close to zero or one\n",
    "y_prob[y_prob > 1- 1e-5] =  1- 1e-5\n",
    "\n",
    "print('AUC score: ', roc_auc_score(y_valid, y_prob))\n",
    "\n",
    "y_pred = (y_prob > tau).astype(int)\n",
    "# y_pred = decision_tree.predict(valid[feature_for_dt])\n",
    "\n",
    "plot_cm(y_valid, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "41167ddb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:18:25,396]\u001b[0m A new study created in memory with name: no-name-79c0ea8c-8d5f-4449-a717-4a7376e7ac0c\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:18:29,404]\u001b[0m Trial 0 finished with value: 0.7370252598322147 and parameters: {'num_layers': 2, 'activation_func_0': 'relu', 'num_neurons_0': 7, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 1}. Best is trial 0 with value: 0.7370252598322147.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:18:33,608]\u001b[0m Trial 1 finished with value: 0.5 and parameters: {'num_layers': 5, 'activation_func_0': 'relu', 'num_neurons_0': 13, 'activation_func_1': 'sigmoid', 'num_neurons_1': 6, 'activation_func_2': 'sigmoid', 'num_neurons_2': 8, 'activation_func_3': 'sigmoid', 'num_neurons_3': 7, 'activation_func_4': 'tanh', 'num_neurons_4': 13}. Best is trial 0 with value: 0.7370252598322147.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:18:37,464]\u001b[0m Trial 2 finished with value: 0.5 and parameters: {'num_layers': 1, 'activation_func_0': 'relu', 'num_neurons_0': 2}. Best is trial 0 with value: 0.7370252598322147.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:18:41,702]\u001b[0m Trial 3 finished with value: 0.5947403041131794 and parameters: {'num_layers': 5, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 22, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 36, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 2, 'activation_func_3': 'sigmoid', 'num_neurons_3': 15, 'activation_func_4': 'sigmoid', 'num_neurons_4': 3}. Best is trial 0 with value: 0.7370252598322147.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:18:45,927]\u001b[0m Trial 4 finished with value: 0.5946639605603753 and parameters: {'num_layers': 5, 'activation_func_0': 'sigmoid', 'num_neurons_0': 29, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 5, 'activation_func_2': 'relu', 'num_neurons_2': 13, 'activation_func_3': 'sigmoid', 'num_neurons_3': 19, 'activation_func_4': 'tanh', 'num_neurons_4': 31}. Best is trial 0 with value: 0.7370252598322147.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:18:50,024]\u001b[0m Trial 5 finished with value: 0.5 and parameters: {'num_layers': 3, 'activation_func_0': 'relu', 'num_neurons_0': 2, 'activation_func_1': 'sigmoid', 'num_neurons_1': 10, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 12}. Best is trial 0 with value: 0.7370252598322147.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:18:53,962]\u001b[0m Trial 6 finished with value: 0.5 and parameters: {'num_layers': 1, 'activation_func_0': 'relu', 'num_neurons_0': 33}. Best is trial 0 with value: 0.7370252598322147.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:18:57,996]\u001b[0m Trial 7 finished with value: 0.5 and parameters: {'num_layers': 1, 'activation_func_0': 'sigmoid', 'num_neurons_0': 13}. Best is trial 0 with value: 0.7370252598322147.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:19:01,827]\u001b[0m Trial 8 finished with value: 0.4055940397497704 and parameters: {'num_layers': 1, 'activation_func_0': 'sigmoid', 'num_neurons_0': 1}. Best is trial 0 with value: 0.7370252598322147.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:19:06,015]\u001b[0m Trial 9 finished with value: 0.5944059602502296 and parameters: {'num_layers': 3, 'activation_func_0': 'relu', 'num_neurons_0': 38, 'activation_func_1': 'tanh', 'num_neurons_1': 39, 'activation_func_2': 'relu', 'num_neurons_2': 12}. Best is trial 0 with value: 0.7370252598322147.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:19:09,973]\u001b[0m Trial 10 finished with value: 0.5944059602502296 and parameters: {'num_layers': 2, 'activation_func_0': 'tanh', 'num_neurons_0': 13, 'activation_func_1': 'relu', 'num_neurons_1': 21}. Best is trial 0 with value: 0.7370252598322147.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:19:14,380]\u001b[0m Trial 11 finished with value: 0.5944059602502296 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 22, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 37, 'activation_func_2': 'tanh', 'num_neurons_2': 35, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 38}. Best is trial 0 with value: 0.7370252598322147.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:19:18,700]\u001b[0m Trial 12 finished with value: 0.7505447146574509 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 22, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 25, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 28, 'activation_func_3': 'relu', 'num_neurons_3': 3}. Best is trial 12 with value: 0.7505447146574509.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:19:22,994]\u001b[0m Trial 13 finished with value: 0.7525637289735712 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 17, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 23, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 31, 'activation_func_3': 'relu', 'num_neurons_3': 1}. Best is trial 13 with value: 0.7525637289735712.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:19:27,112]\u001b[0m Trial 14 finished with value: 0.7565170639769196 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 28, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 24, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 32, 'activation_func_3': 'relu', 'num_neurons_3': 2}. Best is trial 14 with value: 0.7565170639769196.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:19:31,297]\u001b[0m Trial 15 finished with value: 0.5 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 28, 'activation_func_1': 'relu', 'num_neurons_1': 27, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 39, 'activation_func_3': 'relu', 'num_neurons_3': 1}. Best is trial 14 with value: 0.7565170639769196.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:19:35,679]\u001b[0m Trial 16 finished with value: 0.5943691517515562 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 17, 'activation_func_1': 'tanh', 'num_neurons_1': 13, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 26, 'activation_func_3': 'relu', 'num_neurons_3': 11}. Best is trial 14 with value: 0.7565170639769196.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:19:39,803]\u001b[0m Trial 17 finished with value: 0.5944059602502296 and parameters: {'num_layers': 3, 'activation_func_0': 'tanh', 'num_neurons_0': 28, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 29, 'activation_func_2': 'sigmoid', 'num_neurons_2': 29}. Best is trial 14 with value: 0.7565170639769196.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:19:44,287]\u001b[0m Trial 18 finished with value: 0.5 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 40, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 18, 'activation_func_2': 'tanh', 'num_neurons_2': 20, 'activation_func_3': 'tanh', 'num_neurons_3': 27}. Best is trial 14 with value: 0.7565170639769196.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:19:48,492]\u001b[0m Trial 19 finished with value: 0.5396173620235132 and parameters: {'num_layers': 2, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 34, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 32}. Best is trial 14 with value: 0.7565170639769196.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:19:52,896]\u001b[0m Trial 20 finished with value: 0.5 and parameters: {'num_layers': 5, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 18, 'activation_func_1': 'tanh', 'num_neurons_1': 18, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 33, 'activation_func_3': 'relu', 'num_neurons_3': 27, 'activation_func_4': 'relu', 'num_neurons_4': 39}. Best is trial 14 with value: 0.7565170639769196.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:19:57,107]\u001b[0m Trial 21 finished with value: 0.5 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 25, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 24, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 25, 'activation_func_3': 'relu', 'num_neurons_3': 1}. Best is trial 14 with value: 0.7565170639769196.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:20:01,449]\u001b[0m Trial 22 finished with value: 0.7573094691566935 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 18, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 23, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 31, 'activation_func_3': 'relu', 'num_neurons_3': 6}. Best is trial 22 with value: 0.7573094691566935.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:20:05,774]\u001b[0m Trial 23 finished with value: 0.7514487382012573 and parameters: {'num_layers': 3, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 18, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 21, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 40}. Best is trial 22 with value: 0.7573094691566935.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:20:10,165]\u001b[0m Trial 24 finished with value: 0.5 and parameters: {'num_layers': 4, 'activation_func_0': 'tanh', 'num_neurons_0': 8, 'activation_func_1': 'relu', 'num_neurons_1': 15, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 34, 'activation_func_3': 'relu', 'num_neurons_3': 9}. Best is trial 22 with value: 0.7573094691566935.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:20:14,313]\u001b[0m Trial 25 finished with value: 0.5913873225395819 and parameters: {'num_layers': 3, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 25, 'activation_func_1': 'sigmoid', 'num_neurons_1': 31, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 21}. Best is trial 22 with value: 0.7573094691566935.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:20:18,730]\u001b[0m Trial 26 finished with value: 0.5 and parameters: {'num_layers': 5, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 16, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 24, 'activation_func_2': 'tanh', 'num_neurons_2': 32, 'activation_func_3': 'relu', 'num_neurons_3': 7, 'activation_func_4': 'leakyrelu', 'num_neurons_4': 19}. Best is trial 22 with value: 0.7573094691566935.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:20:22,961]\u001b[0m Trial 27 finished with value: 0.5545019690842693 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 8, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 18, 'activation_func_2': 'sigmoid', 'num_neurons_2': 22, 'activation_func_3': 'tanh', 'num_neurons_3': 5}. Best is trial 22 with value: 0.7573094691566935.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:20:27,009]\u001b[0m Trial 28 finished with value: 0.5 and parameters: {'num_layers': 3, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 31, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 32, 'activation_func_2': 'relu', 'num_neurons_2': 37}. Best is trial 22 with value: 0.7573094691566935.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:20:31,244]\u001b[0m Trial 29 finished with value: 0.5944059602502296 and parameters: {'num_layers': 4, 'activation_func_0': 'sigmoid', 'num_neurons_0': 25, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 28, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 30, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 13}. Best is trial 22 with value: 0.7573094691566935.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:20:35,613]\u001b[0m Trial 30 finished with value: 0.5944059602502296 and parameters: {'num_layers': 5, 'activation_func_0': 'tanh', 'num_neurons_0': 11, 'activation_func_1': 'relu', 'num_neurons_1': 23, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 24, 'activation_func_3': 'relu', 'num_neurons_3': 1, 'activation_func_4': 'leakyrelu', 'num_neurons_4': 1}. Best is trial 22 with value: 0.7573094691566935.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:20:39,872]\u001b[0m Trial 31 finished with value: 0.5 and parameters: {'num_layers': 3, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 20, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 21, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 40}. Best is trial 22 with value: 0.7573094691566935.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:20:43,910]\u001b[0m Trial 32 finished with value: 0.7523410034746542 and parameters: {'num_layers': 3, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 15, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 20, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 37}. Best is trial 22 with value: 0.7573094691566935.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:20:47,878]\u001b[0m Trial 33 finished with value: 0.758059271907447 and parameters: {'num_layers': 2, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 14, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 15}. Best is trial 33 with value: 0.758059271907447.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:20:51,884]\u001b[0m Trial 34 finished with value: 0.7539421731669452 and parameters: {'num_layers': 2, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 10, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 15}. Best is trial 33 with value: 0.758059271907447.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:20:56,001]\u001b[0m Trial 35 finished with value: 0.5 and parameters: {'num_layers': 2, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 10, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 14}. Best is trial 33 with value: 0.758059271907447.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:21:00,001]\u001b[0m Trial 36 finished with value: 0.5946455563110387 and parameters: {'num_layers': 2, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 5, 'activation_func_1': 'sigmoid', 'num_neurons_1': 10}. Best is trial 33 with value: 0.758059271907447.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:21:04,003]\u001b[0m Trial 37 finished with value: 0.5 and parameters: {'num_layers': 2, 'activation_func_0': 'relu', 'num_neurons_0': 5, 'activation_func_1': 'tanh', 'num_neurons_1': 11}. Best is trial 33 with value: 0.758059271907447.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:21:07,947]\u001b[0m Trial 38 finished with value: 0.5 and parameters: {'num_layers': 1, 'activation_func_0': 'sigmoid', 'num_neurons_0': 14}. Best is trial 33 with value: 0.758059271907447.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:21:11,904]\u001b[0m Trial 39 finished with value: 0.7496003040109336 and parameters: {'num_layers': 2, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 10, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 8}. Best is trial 33 with value: 0.758059271907447.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:21:15,840]\u001b[0m Trial 40 finished with value: 0.7674936650188047 and parameters: {'num_layers': 1, 'activation_func_0': 'relu', 'num_neurons_0': 12}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:21:19,692]\u001b[0m Trial 41 finished with value: 0.5 and parameters: {'num_layers': 1, 'activation_func_0': 'relu', 'num_neurons_0': 12}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:21:23,700]\u001b[0m Trial 42 finished with value: 0.5512757723394357 and parameters: {'num_layers': 1, 'activation_func_0': 'relu', 'num_neurons_0': 5}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:21:27,787]\u001b[0m Trial 43 finished with value: 0.5 and parameters: {'num_layers': 1, 'activation_func_0': 'relu', 'num_neurons_0': 20}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:21:32,041]\u001b[0m Trial 44 finished with value: 0.5024165801837358 and parameters: {'num_layers': 2, 'activation_func_0': 'relu', 'num_neurons_0': 14, 'activation_func_1': 'sigmoid', 'num_neurons_1': 16}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:21:35,909]\u001b[0m Trial 45 finished with value: 0.5 and parameters: {'num_layers': 1, 'activation_func_0': 'relu', 'num_neurons_0': 9}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:21:39,888]\u001b[0m Trial 46 finished with value: 0.5944059602502296 and parameters: {'num_layers': 2, 'activation_func_0': 'sigmoid', 'num_neurons_0': 12, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 7}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:21:44,252]\u001b[0m Trial 47 finished with value: 0.47964950129596595 and parameters: {'num_layers': 3, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 23, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 2, 'activation_func_2': 'tanh', 'num_neurons_2': 17}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:21:48,314]\u001b[0m Trial 48 finished with value: 0.5 and parameters: {'num_layers': 1, 'activation_func_0': 'tanh', 'num_neurons_0': 3}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:21:52,509]\u001b[0m Trial 49 finished with value: 0.743571378665726 and parameters: {'num_layers': 2, 'activation_func_0': 'relu', 'num_neurons_0': 7, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 12}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:21:57,093]\u001b[0m Trial 50 finished with value: 0.5 and parameters: {'num_layers': 5, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 35, 'activation_func_1': 'tanh', 'num_neurons_1': 4, 'activation_func_2': 'relu', 'num_neurons_2': 28, 'activation_func_3': 'tanh', 'num_neurons_3': 20, 'activation_func_4': 'sigmoid', 'num_neurons_4': 29}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:22:01,494]\u001b[0m Trial 51 finished with value: 0.5 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 18, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 26, 'activation_func_2': 'sigmoid', 'num_neurons_2': 31, 'activation_func_3': 'relu', 'num_neurons_3': 6}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:22:06,007]\u001b[0m Trial 52 finished with value: 0.48298799804369646 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 16, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 16, 'activation_func_2': 'sigmoid', 'num_neurons_2': 36, 'activation_func_3': 'relu', 'num_neurons_3': 16}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:22:10,580]\u001b[0m Trial 53 finished with value: 0.7536083405331439 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 19, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 23, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 17, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 11}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:22:14,746]\u001b[0m Trial 54 finished with value: 0.7557294302691964 and parameters: {'num_layers': 3, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 19, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 19, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 3}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:22:18,998]\u001b[0m Trial 55 finished with value: 0.7560451994730932 and parameters: {'num_layers': 3, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 14, 'activation_func_1': 'relu', 'num_neurons_1': 19, 'activation_func_2': 'relu', 'num_neurons_2': 7}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:22:23,206]\u001b[0m Trial 56 finished with value: 0.5 and parameters: {'num_layers': 3, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 23, 'activation_func_1': 'relu', 'num_neurons_1': 19, 'activation_func_2': 'relu', 'num_neurons_2': 2}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:22:27,339]\u001b[0m Trial 57 finished with value: 0.5 and parameters: {'num_layers': 3, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 15, 'activation_func_1': 'relu', 'num_neurons_1': 26, 'activation_func_2': 'relu', 'num_neurons_2': 5}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:22:31,519]\u001b[0m Trial 58 finished with value: 0.5 and parameters: {'num_layers': 3, 'activation_func_0': 'sigmoid', 'num_neurons_0': 21, 'activation_func_1': 'relu', 'num_neurons_1': 22, 'activation_func_2': 'relu', 'num_neurons_2': 8}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:22:35,684]\u001b[0m Trial 59 finished with value: 0.5 and parameters: {'num_layers': 3, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 13, 'activation_func_1': 'relu', 'num_neurons_1': 17, 'activation_func_2': 'relu', 'num_neurons_2': 8}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:22:39,876]\u001b[0m Trial 60 finished with value: 0.5 and parameters: {'num_layers': 3, 'activation_func_0': 'tanh', 'num_neurons_0': 30, 'activation_func_1': 'sigmoid', 'num_neurons_1': 30, 'activation_func_2': 'relu', 'num_neurons_2': 2}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:22:44,185]\u001b[0m Trial 61 finished with value: 0.5947442235366491 and parameters: {'num_layers': 2, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 16, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 20}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:22:48,291]\u001b[0m Trial 62 finished with value: 0.7513708609610086 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 11, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 14, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 5, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 24}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:22:52,538]\u001b[0m Trial 63 finished with value: 0.5944059602502296 and parameters: {'num_layers': 3, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 14, 'activation_func_1': 'relu', 'num_neurons_1': 19, 'activation_func_2': 'tanh', 'num_neurons_2': 14}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:22:56,713]\u001b[0m Trial 64 finished with value: 0.5 and parameters: {'num_layers': 2, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 19, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 16}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:23:00,796]\u001b[0m Trial 65 finished with value: 0.5 and parameters: {'num_layers': 2, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 15, 'activation_func_1': 'tanh', 'num_neurons_1': 13}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:23:05,095]\u001b[0m Trial 66 finished with value: 0.7508059527522022 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 26, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 22, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 10, 'activation_func_3': 'sigmoid', 'num_neurons_3': 40}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:23:09,145]\u001b[0m Trial 67 finished with value: 0.5 and parameters: {'num_layers': 1, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 17}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:23:13,513]\u001b[0m Trial 68 finished with value: 0.5518817492898176 and parameters: {'num_layers': 5, 'activation_func_0': 'relu', 'num_neurons_0': 12, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 25, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 4, 'activation_func_3': 'tanh', 'num_neurons_3': 15, 'activation_func_4': 'relu', 'num_neurons_4': 12}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:23:17,776]\u001b[0m Trial 69 finished with value: 0.5 and parameters: {'num_layers': 3, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 9, 'activation_func_1': 'relu', 'num_neurons_1': 35, 'activation_func_2': 'relu', 'num_neurons_2': 1}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:23:21,974]\u001b[0m Trial 70 finished with value: 0.53148183176812 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 22, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 18, 'activation_func_2': 'sigmoid', 'num_neurons_2': 10, 'activation_func_3': 'relu', 'num_neurons_3': 34}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:23:26,066]\u001b[0m Trial 71 finished with value: 0.7600571554187733 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 19, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 24, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 16, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 10}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:23:30,518]\u001b[0m Trial 72 finished with value: 0.7527099405099681 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 19, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 28, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 15, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 9}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:23:34,749]\u001b[0m Trial 73 finished with value: 0.7436671489261631 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 17, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 24, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 6, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 4}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:23:39,047]\u001b[0m Trial 74 finished with value: 0.7470811371781174 and parameters: {'num_layers': 5, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 21, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 22, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 12, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 9, 'activation_func_4': 'leakyrelu', 'num_neurons_4': 39}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:23:43,347]\u001b[0m Trial 75 finished with value: 0.5149900906750099 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 13, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 19, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 18, 'activation_func_3': 'sigmoid', 'num_neurons_3': 5}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:23:47,654]\u001b[0m Trial 76 finished with value: 0.5 and parameters: {'num_layers': 3, 'activation_func_0': 'tanh', 'num_neurons_0': 11, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 17, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 23}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:23:51,792]\u001b[0m Trial 77 finished with value: 0.5944059602502296 and parameters: {'num_layers': 2, 'activation_func_0': 'sigmoid', 'num_neurons_0': 15, 'activation_func_1': 'sigmoid', 'num_neurons_1': 21}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:23:56,082]\u001b[0m Trial 78 finished with value: 0.7369455080850891 and parameters: {'num_layers': 3, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 18, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 15, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 7}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:24:00,288]\u001b[0m Trial 79 finished with value: 0.5 and parameters: {'num_layers': 1, 'activation_func_0': 'relu', 'num_neurons_0': 26}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:24:04,891]\u001b[0m Trial 80 finished with value: 0.5944059602502296 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 24, 'activation_func_1': 'tanh', 'num_neurons_1': 25, 'activation_func_2': 'tanh', 'num_neurons_2': 3, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 17}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:24:09,299]\u001b[0m Trial 81 finished with value: 0.7461508705380346 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 19, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 23, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 18, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 12}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:24:13,528]\u001b[0m Trial 82 finished with value: 0.7466206901252681 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 20, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 27, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 26, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 9}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:24:17,887]\u001b[0m Trial 83 finished with value: 0.7444016148024696 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 37, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 20, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 11, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 13}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:24:22,072]\u001b[0m Trial 84 finished with value: 0.5944993447746417 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 17, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 22, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 16, 'activation_func_3': 'sigmoid', 'num_neurons_3': 7}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:24:26,399]\u001b[0m Trial 85 finished with value: 0.741627344624681 and parameters: {'num_layers': 5, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 16, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 24, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 19, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 18, 'activation_func_4': 'relu', 'num_neurons_4': 27}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:24:30,788]\u001b[0m Trial 86 finished with value: 0.7577934327503616 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 10, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 17, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 21, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 11}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:24:35,092]\u001b[0m Trial 87 finished with value: 0.5 and parameters: {'num_layers': 3, 'activation_func_0': 'relu', 'num_neurons_0': 9, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 14, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 33}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:24:38,926]\u001b[0m Trial 88 finished with value: 0.7442448378636757 and parameters: {'num_layers': 1, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 6}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:24:43,149]\u001b[0m Trial 89 finished with value: 0.5 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 10, 'activation_func_1': 'relu', 'num_neurons_1': 17, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 29, 'activation_func_3': 'sigmoid', 'num_neurons_3': 3}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:24:47,259]\u001b[0m Trial 90 finished with value: 0.7562715035760479 and parameters: {'num_layers': 3, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 14, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 11, 'activation_func_2': 'relu', 'num_neurons_2': 28}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:24:51,397]\u001b[0m Trial 91 finished with value: 0.6781648918494737 and parameters: {'num_layers': 3, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 12, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 9, 'activation_func_2': 'relu', 'num_neurons_2': 34}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:24:55,449]\u001b[0m Trial 92 finished with value: 0.75904952276759 and parameters: {'num_layers': 3, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 14, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 12, 'activation_func_2': 'relu', 'num_neurons_2': 26}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:24:59,563]\u001b[0m Trial 93 finished with value: 0.7505181307417423 and parameters: {'num_layers': 3, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 14, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 11, 'activation_func_2': 'relu', 'num_neurons_2': 28}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:25:03,660]\u001b[0m Trial 94 finished with value: 0.7545962056572618 and parameters: {'num_layers': 3, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 11, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 12, 'activation_func_2': 'relu', 'num_neurons_2': 26}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:25:07,996]\u001b[0m Trial 95 finished with value: 0.5944059602502296 and parameters: {'num_layers': 3, 'activation_func_0': 'tanh', 'num_neurons_0': 32, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 10, 'activation_func_2': 'relu', 'num_neurons_2': 21}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:25:12,063]\u001b[0m Trial 96 finished with value: 0.7581722535492084 and parameters: {'num_layers': 3, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 14, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 6, 'activation_func_2': 'relu', 'num_neurons_2': 30}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:25:16,227]\u001b[0m Trial 97 finished with value: 0.5 and parameters: {'num_layers': 3, 'activation_func_0': 'sigmoid', 'num_neurons_0': 13, 'activation_func_1': 'sigmoid', 'num_neurons_1': 5, 'activation_func_2': 'relu', 'num_neurons_2': 31}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:25:20,522]\u001b[0m Trial 98 finished with value: 0.7488854352519763 and parameters: {'num_layers': 4, 'activation_func_0': 'relu', 'num_neurons_0': 14, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 7, 'activation_func_2': 'relu', 'num_neurons_2': 27, 'activation_func_3': 'relu', 'num_neurons_3': 3}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:25:24,600]\u001b[0m Trial 99 finished with value: 0.7488511828990443 and parameters: {'num_layers': 3, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 15, 'activation_func_1': 'relu', 'num_neurons_1': 4, 'activation_func_2': 'relu', 'num_neurons_2': 30}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:25:28,657]\u001b[0m Trial 100 finished with value: 0.7488971935223858 and parameters: {'num_layers': 3, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 8, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 9, 'activation_func_2': 'relu', 'num_neurons_2': 25}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:25:32,788]\u001b[0m Trial 101 finished with value: 0.7581172112109142 and parameters: {'num_layers': 3, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 12, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 2, 'activation_func_2': 'relu', 'num_neurons_2': 32}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:25:36,949]\u001b[0m Trial 102 finished with value: 0.7508218008557975 and parameters: {'num_layers': 3, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 12, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 2, 'activation_func_2': 'relu', 'num_neurons_2': 32}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:25:41,304]\u001b[0m Trial 103 finished with value: 0.758283871913241 and parameters: {'num_layers': 3, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 13, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 1, 'activation_func_2': 'relu', 'num_neurons_2': 29}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:25:45,533]\u001b[0m Trial 104 finished with value: 0.7573542869120226 and parameters: {'num_layers': 3, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 13, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 6, 'activation_func_2': 'relu', 'num_neurons_2': 29}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:25:49,750]\u001b[0m Trial 105 finished with value: 0.7568297658059271 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 11, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 2, 'activation_func_2': 'relu', 'num_neurons_2': 30, 'activation_func_3': 'relu', 'num_neurons_3': 14}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:25:53,837]\u001b[0m Trial 106 finished with value: 0.7631327099745918 and parameters: {'num_layers': 3, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 11, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 2, 'activation_func_2': 'relu', 'num_neurons_2': 29}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:25:58,232]\u001b[0m Trial 107 finished with value: 0.5 and parameters: {'num_layers': 3, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 13, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 1, 'activation_func_2': 'relu', 'num_neurons_2': 23}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:26:02,442]\u001b[0m Trial 108 finished with value: 0.7520976584000914 and parameters: {'num_layers': 3, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 9, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 4, 'activation_func_2': 'relu', 'num_neurons_2': 29}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:26:06,635]\u001b[0m Trial 109 finished with value: 0.5 and parameters: {'num_layers': 3, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 10, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 3, 'activation_func_2': 'relu', 'num_neurons_2': 33}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:26:10,938]\u001b[0m Trial 110 finished with value: 0.5 and parameters: {'num_layers': 3, 'activation_func_0': 'relu', 'num_neurons_0': 7, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 6, 'activation_func_2': 'relu', 'num_neurons_2': 35}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:26:15,300]\u001b[0m Trial 111 finished with value: 0.7606174625652455 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 11, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 1, 'activation_func_2': 'relu', 'num_neurons_2': 30, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 15}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:26:19,473]\u001b[0m Trial 112 finished with value: 0.7243832446350761 and parameters: {'num_layers': 3, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 12, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 3, 'activation_func_2': 'relu', 'num_neurons_2': 27}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:26:23,786]\u001b[0m Trial 113 finished with value: 0.755654961223269 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 16, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 1, 'activation_func_2': 'relu', 'num_neurons_2': 31, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 20}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:26:27,906]\u001b[0m Trial 114 finished with value: 0.7396309948007995 and parameters: {'num_layers': 3, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 13, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 1, 'activation_func_2': 'sigmoid', 'num_neurons_2': 30}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:26:31,952]\u001b[0m Trial 115 finished with value: 0.5944059602502296 and parameters: {'num_layers': 2, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 10, 'activation_func_1': 'tanh', 'num_neurons_1': 6}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:26:36,201]\u001b[0m Trial 116 finished with value: 0.7528276936237797 and parameters: {'num_layers': 3, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 11, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 3, 'activation_func_2': 'relu', 'num_neurons_2': 27}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:26:40,741]\u001b[0m Trial 117 finished with value: 0.7568163034383568 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 15, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 5, 'activation_func_2': 'relu', 'num_neurons_2': 32, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 11}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:26:45,080]\u001b[0m Trial 118 finished with value: 0.5 and parameters: {'num_layers': 3, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 13, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 7, 'activation_func_2': 'tanh', 'num_neurons_2': 29}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:26:49,380]\u001b[0m Trial 119 finished with value: 0.5 and parameters: {'num_layers': 4, 'activation_func_0': 'tanh', 'num_neurons_0': 11, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 5, 'activation_func_2': 'relu', 'num_neurons_2': 24, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 22}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:26:53,460]\u001b[0m Trial 120 finished with value: 0.5944059602502296 and parameters: {'num_layers': 3, 'activation_func_0': 'sigmoid', 'num_neurons_0': 12, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 2, 'activation_func_2': 'relu', 'num_neurons_2': 34}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:26:57,763]\u001b[0m Trial 121 finished with value: 0.7396841626322166 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 8, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 2, 'activation_func_2': 'relu', 'num_neurons_2': 32, 'activation_func_3': 'relu', 'num_neurons_3': 15}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:27:02,056]\u001b[0m Trial 122 finished with value: 0.7537501214169227 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 11, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 3, 'activation_func_2': 'relu', 'num_neurons_2': 30, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 14}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:27:06,205]\u001b[0m Trial 123 finished with value: 0.7490515847251547 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 9, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 1, 'activation_func_2': 'relu', 'num_neurons_2': 28, 'activation_func_3': 'tanh', 'num_neurons_3': 18}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:27:10,411]\u001b[0m Trial 124 finished with value: 0.7594714572246052 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 13, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 2, 'activation_func_2': 'relu', 'num_neurons_2': 31, 'activation_func_3': 'relu', 'num_neurons_3': 10}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:27:14,765]\u001b[0m Trial 125 finished with value: 0.7380976481755084 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 17, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 4, 'activation_func_2': 'relu', 'num_neurons_2': 31, 'activation_func_3': 'relu', 'num_neurons_3': 8}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:27:19,051]\u001b[0m Trial 126 finished with value: 0.5 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 15, 'activation_func_1': 'sigmoid', 'num_neurons_1': 1, 'activation_func_2': 'relu', 'num_neurons_2': 35, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 10}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:27:23,104]\u001b[0m Trial 127 finished with value: 0.7079530214494709 and parameters: {'num_layers': 3, 'activation_func_0': 'relu', 'num_neurons_0': 12, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 3, 'activation_func_2': 'sigmoid', 'num_neurons_2': 33}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:27:27,351]\u001b[0m Trial 128 finished with value: 0.5 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 10, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 8, 'activation_func_2': 'relu', 'num_neurons_2': 29, 'activation_func_3': 'relu', 'num_neurons_3': 7}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:27:31,733]\u001b[0m Trial 129 finished with value: 0.7607413504288361 and parameters: {'num_layers': 2, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 13, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 4}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:27:35,683]\u001b[0m Trial 130 finished with value: 0.5 and parameters: {'num_layers': 2, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 13, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 6}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:27:39,561]\u001b[0m Trial 131 finished with value: 0.5 and parameters: {'num_layers': 1, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 14}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:27:43,551]\u001b[0m Trial 132 finished with value: 0.5 and parameters: {'num_layers': 2, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 12, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 4}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:27:47,671]\u001b[0m Trial 133 finished with value: 0.7361972390217801 and parameters: {'num_layers': 3, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 16, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 2, 'activation_func_2': 'tanh', 'num_neurons_2': 25}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:27:51,864]\u001b[0m Trial 134 finished with value: 0.5 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 14, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 5, 'activation_func_2': 'relu', 'num_neurons_2': 27, 'activation_func_3': 'tanh', 'num_neurons_3': 11}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:27:55,960]\u001b[0m Trial 135 finished with value: 0.6145180557614673 and parameters: {'num_layers': 3, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 18, 'activation_func_1': 'tanh', 'num_neurons_1': 4, 'activation_func_2': 'relu', 'num_neurons_2': 38}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:27:59,958]\u001b[0m Trial 136 finished with value: 0.7479251765018634 and parameters: {'num_layers': 2, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 13, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 2}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:28:03,913]\u001b[0m Trial 137 finished with value: 0.5 and parameters: {'num_layers': 1, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 15}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:28:08,032]\u001b[0m Trial 138 finished with value: 0.7576398935961732 and parameters: {'num_layers': 3, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 12, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 3, 'activation_func_2': 'relu', 'num_neurons_2': 20}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:28:12,163]\u001b[0m Trial 139 finished with value: 0.7358973179214786 and parameters: {'num_layers': 3, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 11, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 3, 'activation_func_2': 'relu', 'num_neurons_2': 19}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:28:16,200]\u001b[0m Trial 140 finished with value: 0.5 and parameters: {'num_layers': 3, 'activation_func_0': 'relu', 'num_neurons_0': 10, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 1, 'activation_func_2': 'relu', 'num_neurons_2': 14}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:28:20,376]\u001b[0m Trial 141 finished with value: 0.7291639188099949 and parameters: {'num_layers': 3, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 12, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 6, 'activation_func_2': 'relu', 'num_neurons_2': 21}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:28:24,480]\u001b[0m Trial 142 finished with value: 0.7405498439899049 and parameters: {'num_layers': 3, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 13, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 3, 'activation_func_2': 'relu', 'num_neurons_2': 31}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:28:28,565]\u001b[0m Trial 143 finished with value: 0.5947912566182874 and parameters: {'num_layers': 3, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 14, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 5, 'activation_func_2': 'relu', 'num_neurons_2': 23}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:28:32,750]\u001b[0m Trial 144 finished with value: 0.7431741536175427 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 9, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 13, 'activation_func_2': 'relu', 'num_neurons_2': 16, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 5}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:28:37,211]\u001b[0m Trial 145 finished with value: 0.763190138048911 and parameters: {'num_layers': 3, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 11, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 8, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 20}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:28:41,404]\u001b[0m Trial 146 finished with value: 0.7204730232898959 and parameters: {'num_layers': 3, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 11, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 8, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 22}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:28:45,555]\u001b[0m Trial 147 finished with value: 0.7513500709756468 and parameters: {'num_layers': 3, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 10, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 7, 'activation_func_2': 'relu', 'num_neurons_2': 20}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:28:49,620]\u001b[0m Trial 148 finished with value: 0.6541255340214478 and parameters: {'num_layers': 3, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 12, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 15, 'activation_func_2': 'sigmoid', 'num_neurons_2': 18}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:28:53,814]\u001b[0m Trial 149 finished with value: 0.5 and parameters: {'num_layers': 3, 'activation_func_0': 'tanh', 'num_neurons_0': 8, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 4, 'activation_func_2': 'relu', 'num_neurons_2': 26}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:28:57,932]\u001b[0m Trial 150 finished with value: 0.5 and parameters: {'num_layers': 3, 'activation_func_0': 'sigmoid', 'num_neurons_0': 13, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 9, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 29}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:29:01,945]\u001b[0m Trial 151 finished with value: 0.7400650283476563 and parameters: {'num_layers': 2, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 14, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 39}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:29:06,272]\u001b[0m Trial 152 finished with value: 0.7414191039516309 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 15, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 2, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 19, 'activation_func_3': 'relu', 'num_neurons_3': 13}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:29:10,462]\u001b[0m Trial 153 finished with value: 0.5 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 11, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 1, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 32, 'activation_func_3': 'sigmoid', 'num_neurons_3': 22}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:29:14,641]\u001b[0m Trial 154 finished with value: 0.5 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 13, 'activation_func_1': 'sigmoid', 'num_neurons_1': 3, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 30, 'activation_func_3': 'relu', 'num_neurons_3': 34}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:29:18,915]\u001b[0m Trial 155 finished with value: 0.6664993243254758 and parameters: {'num_layers': 5, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 12, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 5, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 28, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 16, 'activation_func_4': 'sigmoid', 'num_neurons_4': 9}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:29:22,956]\u001b[0m Trial 156 finished with value: 0.5442581298215299 and parameters: {'num_layers': 1, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 16}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:29:26,878]\u001b[0m Trial 157 finished with value: 0.5 and parameters: {'num_layers': 2, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 9, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 12}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:29:30,978]\u001b[0m Trial 158 finished with value: 0.7535916403809679 and parameters: {'num_layers': 3, 'activation_func_0': 'relu', 'num_neurons_0': 10, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 26, 'activation_func_2': 'relu', 'num_neurons_2': 31}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:29:35,068]\u001b[0m Trial 159 finished with value: 0.5944201042566644 and parameters: {'num_layers': 3, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 12, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 6, 'activation_func_2': 'tanh', 'num_neurons_2': 24}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:29:39,284]\u001b[0m Trial 160 finished with value: 0.744539987491927 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 13, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 10, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 22, 'activation_func_3': 'relu', 'num_neurons_3': 6}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:29:43,527]\u001b[0m Trial 161 finished with value: 0.7594494743712307 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 11, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 2, 'activation_func_2': 'relu', 'num_neurons_2': 30, 'activation_func_3': 'relu', 'num_neurons_3': 14}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:29:47,765]\u001b[0m Trial 162 finished with value: 0.7555876493854172 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 11, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 1, 'activation_func_2': 'relu', 'num_neurons_2': 29, 'activation_func_3': 'relu', 'num_neurons_3': 12}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:29:51,925]\u001b[0m Trial 163 finished with value: 0.7586430955947383 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 14, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 2, 'activation_func_2': 'relu', 'num_neurons_2': 33, 'activation_func_3': 'relu', 'num_neurons_3': 10}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:29:56,127]\u001b[0m Trial 164 finished with value: 0.7388593796063876 and parameters: {'num_layers': 3, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 14, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 2, 'activation_func_2': 'relu', 'num_neurons_2': 33}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:30:00,571]\u001b[0m Trial 165 finished with value: 0.7509056424361091 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 11, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 4, 'activation_func_2': 'relu', 'num_neurons_2': 20, 'activation_func_3': 'relu', 'num_neurons_3': 10}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:30:04,725]\u001b[0m Trial 166 finished with value: 0.5 and parameters: {'num_layers': 3, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 13, 'activation_func_1': 'tanh', 'num_neurons_1': 2, 'activation_func_2': 'relu', 'num_neurons_2': 17}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:30:08,931]\u001b[0m Trial 167 finished with value: 0.7523612822308677 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 12, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 3, 'activation_func_2': 'relu', 'num_neurons_2': 30, 'activation_func_3': 'relu', 'num_neurons_3': 16}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:30:13,345]\u001b[0m Trial 168 finished with value: 0.7563412011499248 and parameters: {'num_layers': 3, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 14, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 1, 'activation_func_2': 'relu', 'num_neurons_2': 34}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:30:17,747]\u001b[0m Trial 169 finished with value: 0.5825536236774076 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 15, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 7, 'activation_func_2': 'relu', 'num_neurons_2': 32, 'activation_func_3': 'tanh', 'num_neurons_3': 12}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:30:21,969]\u001b[0m Trial 170 finished with value: 0.5 and parameters: {'num_layers': 3, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 12, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 4, 'activation_func_2': 'relu', 'num_neurons_2': 36}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:30:26,368]\u001b[0m Trial 171 finished with value: 0.750216164724848 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 10, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 23, 'activation_func_2': 'relu', 'num_neurons_2': 31, 'activation_func_3': 'relu', 'num_neurons_3': 8}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:30:30,856]\u001b[0m Trial 172 finished with value: 0.7147818500019596 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 17, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 2, 'activation_func_2': 'relu', 'num_neurons_2': 28, 'activation_func_3': 'relu', 'num_neurons_3': 10}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:30:35,189]\u001b[0m Trial 173 finished with value: 0.7332847665642505 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 21, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 3, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 33, 'activation_func_3': 'relu', 'num_neurons_3': 14}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:30:39,551]\u001b[0m Trial 174 finished with value: 0.7565376835525653 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 13, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 5, 'activation_func_2': 'relu', 'num_neurons_2': 29, 'activation_func_3': 'relu', 'num_neurons_3': 8}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:30:43,949]\u001b[0m Trial 175 finished with value: 0.7356086438624385 and parameters: {'num_layers': 4, 'activation_func_0': 'relu', 'num_neurons_0': 10, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 1, 'activation_func_2': 'relu', 'num_neurons_2': 30, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 6}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:30:48,279]\u001b[0m Trial 176 finished with value: 0.7528375773873122 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 14, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 16, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 31, 'activation_func_3': 'relu', 'num_neurons_3': 12}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:30:52,430]\u001b[0m Trial 177 finished with value: 0.46654942478200334 and parameters: {'num_layers': 2, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 20, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 2}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:30:56,883]\u001b[0m Trial 178 finished with value: 0.7589765874091078 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 12, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 3, 'activation_func_2': 'relu', 'num_neurons_2': 32, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 17}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:31:01,334]\u001b[0m Trial 179 finished with value: 0.7432545870035326 and parameters: {'num_layers': 3, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 12, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 4, 'activation_func_2': 'relu', 'num_neurons_2': 32}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:31:05,616]\u001b[0m Trial 180 finished with value: 0.5 and parameters: {'num_layers': 3, 'activation_func_0': 'tanh', 'num_neurons_0': 11, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 3, 'activation_func_2': 'relu', 'num_neurons_2': 34}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:31:09,992]\u001b[0m Trial 181 finished with value: 0.7583019353431455 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 13, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 2, 'activation_func_2': 'relu', 'num_neurons_2': 27, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 18}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:31:14,317]\u001b[0m Trial 182 finished with value: 0.5 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 13, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 2, 'activation_func_2': 'relu', 'num_neurons_2': 27, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 21}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:31:18,686]\u001b[0m Trial 183 finished with value: 0.7541761457071237 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 12, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 1, 'activation_func_2': 'relu', 'num_neurons_2': 26, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 18}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:31:22,891]\u001b[0m Trial 184 finished with value: 0.7540892367519226 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 11, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 3, 'activation_func_2': 'relu', 'num_neurons_2': 13, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 17}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:31:27,379]\u001b[0m Trial 185 finished with value: 0.7560465627508218 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 14, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 4, 'activation_func_2': 'relu', 'num_neurons_2': 28, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 19}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:31:31,612]\u001b[0m Trial 186 finished with value: 0.5 and parameters: {'num_layers': 3, 'activation_func_0': 'sigmoid', 'num_neurons_0': 12, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 2, 'activation_func_2': 'relu', 'num_neurons_2': 30}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:31:35,959]\u001b[0m Trial 187 finished with value: 0.7589355186675324 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 13, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 14, 'activation_func_2': 'relu', 'num_neurons_2': 29, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 15}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:31:40,464]\u001b[0m Trial 188 finished with value: 0.5944059602502296 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 15, 'activation_func_1': 'sigmoid', 'num_neurons_1': 16, 'activation_func_2': 'relu', 'num_neurons_2': 27, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 16}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:31:44,563]\u001b[0m Trial 189 finished with value: 0.5 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 14, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 14, 'activation_func_2': 'relu', 'num_neurons_2': 32, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 13}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:31:48,823]\u001b[0m Trial 190 finished with value: 0.46122923344597416 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 11, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 13, 'activation_func_2': 'sigmoid', 'num_neurons_2': 30, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 15}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:31:53,261]\u001b[0m Trial 191 finished with value: 0.761907464115974 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 13, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 15, 'activation_func_2': 'relu', 'num_neurons_2': 31, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 25}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:31:57,567]\u001b[0m Trial 192 finished with value: 0.7484370872889688 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 13, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 16, 'activation_func_2': 'relu', 'num_neurons_2': 31, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 25}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:32:01,914]\u001b[0m Trial 193 finished with value: 0.7564719054021584 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 12, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 15, 'activation_func_2': 'relu', 'num_neurons_2': 29, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 19}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:32:06,122]\u001b[0m Trial 194 finished with value: 0.7580028662914244 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 13, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 15, 'activation_func_2': 'relu', 'num_neurons_2': 33, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 29}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:32:10,189]\u001b[0m Trial 195 finished with value: 0.7379454722990487 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 15, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 14, 'activation_func_2': 'relu', 'num_neurons_2': 33, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 32}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:32:14,565]\u001b[0m Trial 196 finished with value: 0.7548991941324527 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 13, 'activation_func_1': 'relu', 'num_neurons_1': 14, 'activation_func_2': 'relu', 'num_neurons_2': 35, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 27}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:32:18,932]\u001b[0m Trial 197 finished with value: 0.7395129008675558 and parameters: {'num_layers': 4, 'activation_func_0': 'relu', 'num_neurons_0': 14, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 17, 'activation_func_2': 'relu', 'num_neurons_2': 31, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 28}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:32:23,398]\u001b[0m Trial 198 finished with value: 0.5736359128252057 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 9, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 18, 'activation_func_2': 'tanh', 'num_neurons_2': 32, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 30}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:32:27,744]\u001b[0m Trial 199 finished with value: 0.5944059602502296 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 10, 'activation_func_1': 'tanh', 'num_neurons_1': 15, 'activation_func_2': 'relu', 'num_neurons_2': 25, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 25}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:32:32,086]\u001b[0m Trial 200 finished with value: 0.7597996663377758 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 16, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 12, 'activation_func_2': 'relu', 'num_neurons_2': 30, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 14}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:32:36,480]\u001b[0m Trial 201 finished with value: 0.7597117349242785 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 16, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 12, 'activation_func_2': 'relu', 'num_neurons_2': 30, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 17}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:32:40,984]\u001b[0m Trial 202 finished with value: 0.7391170390971011 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 15, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 12, 'activation_func_2': 'relu', 'num_neurons_2': 33, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 17}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:32:45,333]\u001b[0m Trial 203 finished with value: 0.7595796673943161 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 16, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 12, 'activation_func_2': 'relu', 'num_neurons_2': 30, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 14}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:32:49,600]\u001b[0m Trial 204 finished with value: 0.7606689262995019 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 16, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 11, 'activation_func_2': 'relu', 'num_neurons_2': 30, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 15}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:32:53,912]\u001b[0m Trial 205 finished with value: 0.7536228253590106 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 16, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 11, 'activation_func_2': 'relu', 'num_neurons_2': 30, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 17}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:32:58,343]\u001b[0m Trial 206 finished with value: 0.7586989899816128 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 17, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 11, 'activation_func_2': 'relu', 'num_neurons_2': 29, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 14}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:33:02,597]\u001b[0m Trial 207 finished with value: 0.746100770081507 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 16, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 10, 'activation_func_2': 'relu', 'num_neurons_2': 28, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 14}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:33:06,854]\u001b[0m Trial 208 finished with value: 0.7505748771771972 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 18, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 11, 'activation_func_2': 'relu', 'num_neurons_2': 29, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 15}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:33:11,200]\u001b[0m Trial 209 finished with value: 0.7607873610521778 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 17, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 12, 'activation_func_2': 'relu', 'num_neurons_2': 30, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 15}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:33:15,622]\u001b[0m Trial 210 finished with value: 0.756087290672965 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 17, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 12, 'activation_func_2': 'relu', 'num_neurons_2': 30, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 15}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:33:19,948]\u001b[0m Trial 211 finished with value: 0.7545641686306386 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 18, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 13, 'activation_func_2': 'relu', 'num_neurons_2': 28, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 16}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:33:24,108]\u001b[0m Trial 212 finished with value: 0.7395023354651589 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 17, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 11, 'activation_func_2': 'relu', 'num_neurons_2': 31, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 14}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:33:28,313]\u001b[0m Trial 213 finished with value: 0.7566559478955253 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 16, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 12, 'activation_func_2': 'relu', 'num_neurons_2': 29, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 13}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:33:32,645]\u001b[0m Trial 214 finished with value: 0.7337528820543232 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 17, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 10, 'activation_func_2': 'relu', 'num_neurons_2': 30, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 18}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:33:37,145]\u001b[0m Trial 215 finished with value: 0.7547400314576336 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 19, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 13, 'activation_func_2': 'relu', 'num_neurons_2': 29, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 14}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:33:42,203]\u001b[0m Trial 216 finished with value: 0.7600859546607909 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 16, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 9, 'activation_func_2': 'relu', 'num_neurons_2': 28, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 15}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:33:46,787]\u001b[0m Trial 217 finished with value: 0.5 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 16, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 13, 'activation_func_2': 'relu', 'num_neurons_2': 27, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 15}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:33:51,274]\u001b[0m Trial 218 finished with value: 0.7533230746684252 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 16, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 9, 'activation_func_2': 'relu', 'num_neurons_2': 28, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 16}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:33:55,693]\u001b[0m Trial 219 finished with value: 0.7551706568101687 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 18, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 11, 'activation_func_2': 'relu', 'num_neurons_2': 31, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 12}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:34:00,052]\u001b[0m Trial 220 finished with value: 0.7384244940109504 and parameters: {'num_layers': 4, 'activation_func_0': 'relu', 'num_neurons_0': 17, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 12, 'activation_func_2': 'relu', 'num_neurons_2': 28, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 17}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:34:04,164]\u001b[0m Trial 221 finished with value: 0.6500932993195541 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 15, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 8, 'activation_func_2': 'relu', 'num_neurons_2': 29, 'activation_func_3': 'sigmoid', 'num_neurons_3': 13}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:34:08,577]\u001b[0m Trial 222 finished with value: 0.7633835530766623 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 16, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 10, 'activation_func_2': 'relu', 'num_neurons_2': 30, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 18}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:34:12,902]\u001b[0m Trial 223 finished with value: 0.7545004353968245 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 18, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 11, 'activation_func_2': 'relu', 'num_neurons_2': 30, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 19}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:34:17,216]\u001b[0m Trial 224 finished with value: 0.7365728220360213 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 17, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 10, 'activation_func_2': 'relu', 'num_neurons_2': 31, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 17}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:34:21,594]\u001b[0m Trial 225 finished with value: 0.7612365610637656 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 16, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 9, 'activation_func_2': 'relu', 'num_neurons_2': 29, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 15}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:34:26,032]\u001b[0m Trial 226 finished with value: 0.7597758089775246 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 16, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 9, 'activation_func_2': 'relu', 'num_neurons_2': 30, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 15}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:34:30,387]\u001b[0m Trial 227 finished with value: 0.5943948836186844 and parameters: {'num_layers': 4, 'activation_func_0': 'tanh', 'num_neurons_0': 16, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 10, 'activation_func_2': 'relu', 'num_neurons_2': 30, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 15}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:34:34,723]\u001b[0m Trial 228 finished with value: 0.5883709001552433 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 16, 'activation_func_1': 'sigmoid', 'num_neurons_1': 9, 'activation_func_2': 'relu', 'num_neurons_2': 29, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 14}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:34:38,972]\u001b[0m Trial 229 finished with value: 0.7493988797265264 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 15, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 9, 'activation_func_2': 'relu', 'num_neurons_2': 31, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 16}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:34:43,286]\u001b[0m Trial 230 finished with value: 0.5944059602502296 and parameters: {'num_layers': 4, 'activation_func_0': 'sigmoid', 'num_neurons_0': 17, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 8, 'activation_func_2': 'relu', 'num_neurons_2': 32, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 15}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:34:47,852]\u001b[0m Trial 231 finished with value: 0.7422844444898871 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 16, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 12, 'activation_func_2': 'relu', 'num_neurons_2': 30, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 16}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:34:52,181]\u001b[0m Trial 232 finished with value: 0.759144611389163 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 19, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 10, 'activation_func_2': 'relu', 'num_neurons_2': 28, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 13}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:34:56,456]\u001b[0m Trial 233 finished with value: 0.7304196680077911 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 19, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 11, 'activation_func_2': 'relu', 'num_neurons_2': 28, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 13}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:35:00,922]\u001b[0m Trial 234 finished with value: 0.7557969125167641 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 17, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 9, 'activation_func_2': 'relu', 'num_neurons_2': 30, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 11}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:35:05,119]\u001b[0m Trial 235 finished with value: 0.7624135809727327 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 20, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 10, 'activation_func_2': 'relu', 'num_neurons_2': 29, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 14}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:35:09,311]\u001b[0m Trial 236 finished with value: 0.7572997558028769 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 20, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 10, 'activation_func_2': 'relu', 'num_neurons_2': 29, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 14}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:35:13,527]\u001b[0m Trial 237 finished with value: 0.7560695680624927 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 21, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 10, 'activation_func_2': 'relu', 'num_neurons_2': 29, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 15}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:35:17,723]\u001b[0m Trial 238 finished with value: 0.7061039056202828 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 19, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 11, 'activation_func_2': 'relu', 'num_neurons_2': 28, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 13}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:35:21,922]\u001b[0m Trial 239 finished with value: 0.7535284183763021 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 18, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 8, 'activation_func_2': 'relu', 'num_neurons_2': 31, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 12}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:35:26,244]\u001b[0m Trial 240 finished with value: 0.5310929567960248 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 20, 'activation_func_1': 'relu', 'num_neurons_1': 13, 'activation_func_2': 'sigmoid', 'num_neurons_2': 29, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 14}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:35:30,759]\u001b[0m Trial 241 finished with value: 0.7604259220443712 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 15, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 11, 'activation_func_2': 'relu', 'num_neurons_2': 30, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 10}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:35:34,947]\u001b[0m Trial 242 finished with value: 0.756413966098691 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 15, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 11, 'activation_func_2': 'relu', 'num_neurons_2': 30, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 16}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:35:39,115]\u001b[0m Trial 243 finished with value: 0.7530660968165761 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 16, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 9, 'activation_func_2': 'relu', 'num_neurons_2': 31, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 13}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:35:43,380]\u001b[0m Trial 244 finished with value: 0.5 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 17, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 12, 'activation_func_2': 'relu', 'num_neurons_2': 30, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 15}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:35:47,730]\u001b[0m Trial 245 finished with value: 0.5 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 16, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 10, 'activation_func_2': 'relu', 'num_neurons_2': 29, 'activation_func_3': 'tanh', 'num_neurons_3': 9}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:35:52,266]\u001b[0m Trial 246 finished with value: 0.5 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 15, 'activation_func_1': 'tanh', 'num_neurons_1': 12, 'activation_func_2': 'tanh', 'num_neurons_2': 31, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 11}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:35:56,678]\u001b[0m Trial 247 finished with value: 0.7376804851905436 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 22, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 10, 'activation_func_2': 'relu', 'num_neurons_2': 30, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 17}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:36:01,060]\u001b[0m Trial 248 finished with value: 0.7547628663595883 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 18, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 11, 'activation_func_2': 'relu', 'num_neurons_2': 28, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 14}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:36:05,390]\u001b[0m Trial 249 finished with value: 0.7440953885426732 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 16, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 9, 'activation_func_2': 'relu', 'num_neurons_2': 27, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 16}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:36:09,853]\u001b[0m Trial 250 finished with value: 0.7591613115413388 and parameters: {'num_layers': 4, 'activation_func_0': 'relu', 'num_neurons_0': 17, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 10, 'activation_func_2': 'relu', 'num_neurons_2': 29, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 15}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:36:14,126]\u001b[0m Trial 251 finished with value: 0.7542957733278121 and parameters: {'num_layers': 4, 'activation_func_0': 'relu', 'num_neurons_0': 19, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 8, 'activation_func_2': 'relu', 'num_neurons_2': 32, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 15}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:36:18,600]\u001b[0m Trial 252 finished with value: 0.5 and parameters: {'num_layers': 4, 'activation_func_0': 'relu', 'num_neurons_0': 15, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 9, 'activation_func_2': 'relu', 'num_neurons_2': 28, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 17}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:36:22,797]\u001b[0m Trial 253 finished with value: 0.5 and parameters: {'num_layers': 4, 'activation_func_0': 'relu', 'num_neurons_0': 18, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 10, 'activation_func_2': 'relu', 'num_neurons_2': 30, 'activation_func_3': 'sigmoid', 'num_neurons_3': 12}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:36:26,933]\u001b[0m Trial 254 finished with value: 0.738796498421154 and parameters: {'num_layers': 4, 'activation_func_0': 'relu', 'num_neurons_0': 15, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 12, 'activation_func_2': 'relu', 'num_neurons_2': 31, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 18}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:36:31,195]\u001b[0m Trial 255 finished with value: 0.7599859241574517 and parameters: {'num_layers': 4, 'activation_func_0': 'relu', 'num_neurons_0': 17, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 13, 'activation_func_2': 'relu', 'num_neurons_2': 30, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 10}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:36:35,444]\u001b[0m Trial 256 finished with value: 0.7556276956686961 and parameters: {'num_layers': 4, 'activation_func_0': 'relu', 'num_neurons_0': 17, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 13, 'activation_func_2': 'relu', 'num_neurons_2': 15, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 10}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:36:39,736]\u001b[0m Trial 257 finished with value: 0.7572421573188417 and parameters: {'num_layers': 4, 'activation_func_0': 'relu', 'num_neurons_0': 16, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 11, 'activation_func_2': 'relu', 'num_neurons_2': 32, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 20}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:36:44,100]\u001b[0m Trial 258 finished with value: 0.7577198157530151 and parameters: {'num_layers': 4, 'activation_func_0': 'relu', 'num_neurons_0': 18, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 10, 'activation_func_2': 'relu', 'num_neurons_2': 30, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 10}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:36:48,363]\u001b[0m Trial 259 finished with value: 0.7594319221704745 and parameters: {'num_layers': 4, 'activation_func_0': 'relu', 'num_neurons_0': 20, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 12, 'activation_func_2': 'relu', 'num_neurons_2': 31, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 11}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:36:52,785]\u001b[0m Trial 260 finished with value: 0.7550883489173018 and parameters: {'num_layers': 4, 'activation_func_0': 'relu', 'num_neurons_0': 20, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 12, 'activation_func_2': 'relu', 'num_neurons_2': 31, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 12}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:36:57,134]\u001b[0m Trial 261 finished with value: 0.5 and parameters: {'num_layers': 4, 'activation_func_0': 'relu', 'num_neurons_0': 21, 'activation_func_1': 'sigmoid', 'num_neurons_1': 13, 'activation_func_2': 'relu', 'num_neurons_2': 29, 'activation_func_3': 'tanh', 'num_neurons_3': 9}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:37:01,076]\u001b[0m Trial 262 finished with value: 0.5 and parameters: {'num_layers': 1, 'activation_func_0': 'relu', 'num_neurons_0': 19}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:37:05,312]\u001b[0m Trial 263 finished with value: 0.7408207954384727 and parameters: {'num_layers': 4, 'activation_func_0': 'relu', 'num_neurons_0': 19, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 12, 'activation_func_2': 'relu', 'num_neurons_2': 30, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 11}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:37:09,640]\u001b[0m Trial 264 finished with value: 0.738522990826845 and parameters: {'num_layers': 4, 'activation_func_0': 'relu', 'num_neurons_0': 16, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 11, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 26, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 13}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:37:13,964]\u001b[0m Trial 265 finished with value: 0.7533396044108851 and parameters: {'num_layers': 4, 'activation_func_0': 'relu', 'num_neurons_0': 22, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 9, 'activation_func_2': 'relu', 'num_neurons_2': 28, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 8}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:37:18,279]\u001b[0m Trial 266 finished with value: 0.5 and parameters: {'num_layers': 5, 'activation_func_0': 'relu', 'num_neurons_0': 17, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 35, 'activation_func_2': 'sigmoid', 'num_neurons_2': 31, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 11, 'activation_func_4': 'tanh', 'num_neurons_4': 20}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:37:22,529]\u001b[0m Trial 267 finished with value: 0.5 and parameters: {'num_layers': 4, 'activation_func_0': 'tanh', 'num_neurons_0': 20, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 8, 'activation_func_2': 'relu', 'num_neurons_2': 30, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 10}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:37:26,891]\u001b[0m Trial 268 finished with value: 0.7497064692640516 and parameters: {'num_layers': 4, 'activation_func_0': 'relu', 'num_neurons_0': 16, 'activation_func_1': 'relu', 'num_neurons_1': 10, 'activation_func_2': 'relu', 'num_neurons_2': 29, 'activation_func_3': 'relu', 'num_neurons_3': 14}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:37:31,550]\u001b[0m Trial 269 finished with value: 0.7583032986208742 and parameters: {'num_layers': 4, 'activation_func_0': 'relu', 'num_neurons_0': 15, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 11, 'activation_func_2': 'relu', 'num_neurons_2': 27, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 13}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:37:35,818]\u001b[0m Trial 270 finished with value: 0.594341034148403 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 17, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 13, 'activation_func_2': 'tanh', 'num_neurons_2': 30, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 8}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:37:40,144]\u001b[0m Trial 271 finished with value: 0.5944059602502296 and parameters: {'num_layers': 4, 'activation_func_0': 'sigmoid', 'num_neurons_0': 18, 'activation_func_1': 'tanh', 'num_neurons_1': 7, 'activation_func_2': 'relu', 'num_neurons_2': 31, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 23}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:37:44,471]\u001b[0m Trial 272 finished with value: 0.7569996642928594 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 19, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 12, 'activation_func_2': 'relu', 'num_neurons_2': 29, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 12}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:37:48,784]\u001b[0m Trial 273 finished with value: 0.5247547378161314 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 21, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 10, 'activation_func_2': 'relu', 'num_neurons_2': 28, 'activation_func_3': 'sigmoid', 'num_neurons_3': 16}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:37:52,705]\u001b[0m Trial 274 finished with value: 0.5547867237198395 and parameters: {'num_layers': 1, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 15}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:37:57,259]\u001b[0m Trial 275 finished with value: 0.7551653741089702 and parameters: {'num_layers': 4, 'activation_func_0': 'relu', 'num_neurons_0': 18, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 29, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 32, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 9}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:38:01,634]\u001b[0m Trial 276 finished with value: 0.7544501645305809 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 14, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 12, 'activation_func_2': 'relu', 'num_neurons_2': 30, 'activation_func_3': 'relu', 'num_neurons_3': 14}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:38:05,971]\u001b[0m Trial 277 finished with value: 0.7411951855847014 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 17, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 14, 'activation_func_2': 'relu', 'num_neurons_2': 11, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 15}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:38:10,298]\u001b[0m Trial 278 finished with value: 0.7624616365126674 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 16, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 9, 'activation_func_2': 'relu', 'num_neurons_2': 16, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 15}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:38:14,489]\u001b[0m Trial 279 finished with value: 0.7565013862830403 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 16, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 9, 'activation_func_2': 'relu', 'num_neurons_2': 15, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 15}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:38:18,762]\u001b[0m Trial 280 finished with value: 0.7560031082732214 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 17, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 9, 'activation_func_2': 'relu', 'num_neurons_2': 31, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 14}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:38:23,004]\u001b[0m Trial 281 finished with value: 0.7613495427055268 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 18, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 8, 'activation_func_2': 'relu', 'num_neurons_2': 29, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 13}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:38:27,285]\u001b[0m Trial 282 finished with value: 0.7570797568594171 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 17, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 7, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 16, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 16}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:38:31,534]\u001b[0m Trial 283 finished with value: 0.7542356186980358 and parameters: {'num_layers': 4, 'activation_func_0': 'relu', 'num_neurons_0': 16, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 8, 'activation_func_2': 'relu', 'num_neurons_2': 17, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 15}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:38:35,876]\u001b[0m Trial 284 finished with value: 0.7371961807774431 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 18, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 8, 'activation_func_2': 'relu', 'num_neurons_2': 13, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 10}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:38:40,232]\u001b[0m Trial 285 finished with value: 0.7573962077021783 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 16, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 8, 'activation_func_2': 'relu', 'num_neurons_2': 16, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 13}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:38:44,708]\u001b[0m Trial 286 finished with value: 0.5 and parameters: {'num_layers': 4, 'activation_func_0': 'tanh', 'num_neurons_0': 17, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 9, 'activation_func_2': 'relu', 'num_neurons_2': 18, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 16}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:38:48,856]\u001b[0m Trial 287 finished with value: 0.7292545767789497 and parameters: {'num_layers': 2, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 15, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 11}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:38:53,100]\u001b[0m Trial 288 finished with value: 0.5944059602502296 and parameters: {'num_layers': 4, 'activation_func_0': 'sigmoid', 'num_neurons_0': 18, 'activation_func_1': 'sigmoid', 'num_neurons_1': 10, 'activation_func_2': 'sigmoid', 'num_neurons_2': 30, 'activation_func_3': 'relu', 'num_neurons_3': 14}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:38:57,577]\u001b[0m Trial 289 finished with value: 0.7575209476143491 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 20, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 21, 'activation_func_2': 'relu', 'num_neurons_2': 31, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 11}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:39:01,919]\u001b[0m Trial 290 finished with value: 0.7492806153835668 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 11, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 9, 'activation_func_2': 'relu', 'num_neurons_2': 29, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 12}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:39:06,189]\u001b[0m Trial 291 finished with value: 0.5441676422622913 and parameters: {'num_layers': 4, 'activation_func_0': 'relu', 'num_neurons_0': 16, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 7, 'activation_func_2': 'relu', 'num_neurons_2': 32, 'activation_func_3': 'tanh', 'num_neurons_3': 14}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:39:10,660]\u001b[0m Trial 292 finished with value: 0.742347836904269 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 17, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 11, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 29, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 15}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:39:15,187]\u001b[0m Trial 293 finished with value: 0.7381094064459179 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 15, 'activation_func_1': 'relu', 'num_neurons_1': 10, 'activation_func_2': 'relu', 'num_neurons_2': 30, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 9}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:39:19,485]\u001b[0m Trial 294 finished with value: 0.7577907061949044 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 16, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 13, 'activation_func_2': 'relu', 'num_neurons_2': 31, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 12}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:39:23,705]\u001b[0m Trial 295 finished with value: 0.5942338464369885 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 18, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 11, 'activation_func_2': 'tanh', 'num_neurons_2': 29, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 37}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:39:27,902]\u001b[0m Trial 296 finished with value: 0.7552101918642993 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 17, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 12, 'activation_func_2': 'relu', 'num_neurons_2': 30, 'activation_func_3': 'relu', 'num_neurons_3': 16}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:39:32,198]\u001b[0m Trial 297 finished with value: 0.7600329572390899 and parameters: {'num_layers': 4, 'activation_func_0': 'relu', 'num_neurons_0': 14, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 10, 'activation_func_2': 'relu', 'num_neurons_2': 31, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 19}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:39:36,466]\u001b[0m Trial 298 finished with value: 0.635832391819652 and parameters: {'num_layers': 5, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 15, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 32, 'activation_func_2': 'relu', 'num_neurons_2': 32, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 19, 'activation_func_4': 'sigmoid', 'num_neurons_4': 25}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:39:40,849]\u001b[0m Trial 299 finished with value: 0.5 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 14, 'activation_func_1': 'tanh', 'num_neurons_1': 14, 'activation_func_2': 'relu', 'num_neurons_2': 31, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 20}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:39:45,845]\u001b[0m Trial 300 finished with value: 0.7399948195446312 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 40, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 7, 'activation_func_2': 'relu', 'num_neurons_2': 32, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 21}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:39:50,299]\u001b[0m Trial 301 finished with value: 0.5 and parameters: {'num_layers': 1, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 14}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:39:54,512]\u001b[0m Trial 302 finished with value: 0.7394795005632041 and parameters: {'num_layers': 2, 'activation_func_0': 'relu', 'num_neurons_0': 11, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 11}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:39:58,739]\u001b[0m Trial 303 finished with value: 0.5549777530115657 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 15, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 9, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 17, 'activation_func_3': 'sigmoid', 'num_neurons_3': 17}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:40:02,955]\u001b[0m Trial 304 finished with value: 0.7557474936991007 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 14, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 8, 'activation_func_2': 'relu', 'num_neurons_2': 30, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 18}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:40:07,176]\u001b[0m Trial 305 finished with value: 0.7575863849453239 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 2, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 27, 'activation_func_2': 'relu', 'num_neurons_2': 14, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 11}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:40:11,370]\u001b[0m Trial 306 finished with value: 0.7611818595449039 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 15, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 13, 'activation_func_2': 'relu', 'num_neurons_2': 31, 'activation_func_3': 'relu', 'num_neurons_3': 18}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:40:15,618]\u001b[0m Trial 307 finished with value: 0.7359820115503706 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 15, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 13, 'activation_func_2': 'relu', 'num_neurons_2': 30, 'activation_func_3': 'relu', 'num_neurons_3': 18}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:40:19,870]\u001b[0m Trial 308 finished with value: 0.7475269289953836 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 14, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 1, 'activation_func_2': 'relu', 'num_neurons_2': 33, 'activation_func_3': 'relu', 'num_neurons_3': 17}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:40:24,055]\u001b[0m Trial 309 finished with value: 0.7596452751350071 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 16, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 9, 'activation_func_2': 'relu', 'num_neurons_2': 31, 'activation_func_3': 'relu', 'num_neurons_3': 19}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:40:28,261]\u001b[0m Trial 310 finished with value: 0.7601399745407884 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 16, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 9, 'activation_func_2': 'relu', 'num_neurons_2': 31, 'activation_func_3': 'relu', 'num_neurons_3': 18}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:40:32,479]\u001b[0m Trial 311 finished with value: 0.7548386986832442 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 16, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 8, 'activation_func_2': 'relu', 'num_neurons_2': 32, 'activation_func_3': 'relu', 'num_neurons_3': 19}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:40:36,570]\u001b[0m Trial 312 finished with value: 0.7544036426780908 and parameters: {'num_layers': 2, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 16, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 9}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:40:40,782]\u001b[0m Trial 313 finished with value: 0.7581129509680123 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 16, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 7, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 31, 'activation_func_3': 'relu', 'num_neurons_3': 19}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:40:44,976]\u001b[0m Trial 314 finished with value: 0.7555426612203722 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 15, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 9, 'activation_func_2': 'relu', 'num_neurons_2': 29, 'activation_func_3': 'relu', 'num_neurons_3': 21}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:40:49,176]\u001b[0m Trial 315 finished with value: 0.7625151451635167 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 16, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 10, 'activation_func_2': 'relu', 'num_neurons_2': 30, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 20}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:40:53,463]\u001b[0m Trial 316 finished with value: 0.5 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 15, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 10, 'activation_func_2': 'relu', 'num_neurons_2': 19, 'activation_func_3': 'tanh', 'num_neurons_3': 20}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:40:57,670]\u001b[0m Trial 317 finished with value: 0.5944059602502296 and parameters: {'num_layers': 4, 'activation_func_0': 'tanh', 'num_neurons_0': 16, 'activation_func_1': 'sigmoid', 'num_neurons_1': 8, 'activation_func_2': 'sigmoid', 'num_neurons_2': 22, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 18}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:41:02,099]\u001b[0m Trial 318 finished with value: 0.7477614127647102 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 17, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 10, 'activation_func_2': 'relu', 'num_neurons_2': 31, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 22}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:41:06,501]\u001b[0m Trial 319 finished with value: 0.7581114172805676 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 15, 'activation_func_1': 'relu', 'num_neurons_1': 9, 'activation_func_2': 'relu', 'num_neurons_2': 33, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 20}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:41:10,708]\u001b[0m Trial 320 finished with value: 0.7509162078385061 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 17, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 9, 'activation_func_2': 'relu', 'num_neurons_2': 28, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 19}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:41:14,893]\u001b[0m Trial 321 finished with value: 0.5944059602502296 and parameters: {'num_layers': 4, 'activation_func_0': 'sigmoid', 'num_neurons_0': 16, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 8, 'activation_func_2': 'tanh', 'num_neurons_2': 32, 'activation_func_3': 'relu', 'num_neurons_3': 18}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:41:19,061]\u001b[0m Trial 322 finished with value: 0.75488931036892 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 18, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 10, 'activation_func_2': 'relu', 'num_neurons_2': 30, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 17}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:41:23,303]\u001b[0m Trial 323 finished with value: 0.5 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 14, 'activation_func_1': 'tanh', 'num_neurons_1': 11, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 9, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 21}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:41:27,557]\u001b[0m Trial 324 finished with value: 0.7578041685624747 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 15, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 6, 'activation_func_2': 'relu', 'num_neurons_2': 29, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 19}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:41:31,737]\u001b[0m Trial 325 finished with value: 0.7523730405012773 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 17, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 10, 'activation_func_2': 'relu', 'num_neurons_2': 31, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 18}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:41:35,940]\u001b[0m Trial 326 finished with value: 0.7630706808379386 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 29, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 9, 'activation_func_2': 'relu', 'num_neurons_2': 29, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 23}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:41:39,992]\u001b[0m Trial 327 finished with value: 0.5 and parameters: {'num_layers': 1, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 18}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:41:43,992]\u001b[0m Trial 328 finished with value: 0.7549387291865833 and parameters: {'num_layers': 2, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 33, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 24}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:41:48,161]\u001b[0m Trial 329 finished with value: 0.7498099079617123 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 14, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 10, 'activation_func_2': 'relu', 'num_neurons_2': 28, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 25}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:41:52,398]\u001b[0m Trial 330 finished with value: 0.7585466436954369 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 15, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 8, 'activation_func_2': 'relu', 'num_neurons_2': 18, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 24}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:41:56,649]\u001b[0m Trial 331 finished with value: 0.7550184809337088 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 16, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 11, 'activation_func_2': 'relu', 'num_neurons_2': 27, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 27}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:42:00,868]\u001b[0m Trial 332 finished with value: 0.7554375184255505 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 19, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 11, 'activation_func_2': 'relu', 'num_neurons_2': 29, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 23}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:42:05,044]\u001b[0m Trial 333 finished with value: 0.7412401737497465 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 13, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 14, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 15, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 23}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:42:09,387]\u001b[0m Trial 334 finished with value: 0.7575226517115099 and parameters: {'num_layers': 5, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 37, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 9, 'activation_func_2': 'relu', 'num_neurons_2': 29, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 17, 'activation_func_4': 'leakyrelu', 'num_neurons_4': 33}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:42:13,634]\u001b[0m Trial 335 finished with value: 0.756337452136171 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 35, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 7, 'activation_func_2': 'relu', 'num_neurons_2': 30, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 26}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:42:17,877]\u001b[0m Trial 336 finished with value: 0.7340669471610595 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 30, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 10, 'activation_func_2': 'relu', 'num_neurons_2': 28, 'activation_func_3': 'sigmoid', 'num_neurons_3': 16}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:42:22,147]\u001b[0m Trial 337 finished with value: 0.7466639741931526 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 28, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 13, 'activation_func_2': 'relu', 'num_neurons_2': 30, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 16}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:42:26,346]\u001b[0m Trial 338 finished with value: 0.5 and parameters: {'num_layers': 4, 'activation_func_0': 'tanh', 'num_neurons_0': 17, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 8, 'activation_func_2': 'relu', 'num_neurons_2': 16, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 17}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:42:30,564]\u001b[0m Trial 339 finished with value: 0.7584403080326028 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 15, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 11, 'activation_func_2': 'relu', 'num_neurons_2': 40, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 20}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:42:34,784]\u001b[0m Trial 340 finished with value: 0.5 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 17, 'activation_func_1': 'sigmoid', 'num_neurons_1': 12, 'activation_func_2': 'relu', 'num_neurons_2': 29, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 22}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:42:38,949]\u001b[0m Trial 341 finished with value: 0.7479940220271598 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 14, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 9, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 30, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 15}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:42:43,240]\u001b[0m Trial 342 finished with value: 0.5944059602502296 and parameters: {'num_layers': 4, 'activation_func_0': 'sigmoid', 'num_neurons_0': 12, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 25, 'activation_func_2': 'sigmoid', 'num_neurons_2': 32, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 26}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:42:47,485]\u001b[0m Trial 343 finished with value: 0.5944644107828452 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 18, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 10, 'activation_func_2': 'relu', 'num_neurons_2': 27, 'activation_func_3': 'tanh', 'num_neurons_3': 16}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:42:51,707]\u001b[0m Trial 344 finished with value: 0.755188038601209 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 25, 'activation_func_1': 'relu', 'num_neurons_1': 12, 'activation_func_2': 'relu', 'num_neurons_2': 28, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 24}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:42:56,279]\u001b[0m Trial 345 finished with value: 0.7492489191763758 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 4, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 14, 'activation_func_2': 'relu', 'num_neurons_2': 31, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 15}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:43:00,503]\u001b[0m Trial 346 finished with value: 0.7506658759655841 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 16, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 8, 'activation_func_2': 'relu', 'num_neurons_2': 30, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 17}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:43:04,873]\u001b[0m Trial 347 finished with value: 0.7567571712668769 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 28, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 11, 'activation_func_2': 'relu', 'num_neurons_2': 29, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 18}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:43:08,890]\u001b[0m Trial 348 finished with value: 0.5 and parameters: {'num_layers': 2, 'activation_func_0': 'relu', 'num_neurons_0': 14, 'activation_func_1': 'tanh', 'num_neurons_1': 7}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:43:13,223]\u001b[0m Trial 349 finished with value: 0.7361577039676495 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 10, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 13, 'activation_func_2': 'tanh', 'num_neurons_2': 31, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 13}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:43:17,489]\u001b[0m Trial 350 finished with value: 0.7399128524711965 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 15, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 9, 'activation_func_2': 'relu', 'num_neurons_2': 29, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 15}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:43:21,718]\u001b[0m Trial 351 finished with value: 0.759774445699796 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 19, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 9, 'activation_func_2': 'relu', 'num_neurons_2': 28, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 7}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:43:25,602]\u001b[0m Trial 352 finished with value: 0.5 and parameters: {'num_layers': 1, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 19}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:43:29,863]\u001b[0m Trial 353 finished with value: 0.5 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 19, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 8, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 27, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 8}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:43:34,071]\u001b[0m Trial 354 finished with value: 0.7567215556362161 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 21, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 9, 'activation_func_2': 'relu', 'num_neurons_2': 26, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 6}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:43:38,232]\u001b[0m Trial 355 finished with value: 0.7527896922570938 and parameters: {'num_layers': 4, 'activation_func_0': 'relu', 'num_neurons_0': 18, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 6, 'activation_func_2': 'relu', 'num_neurons_2': 28, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 7}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:43:42,442]\u001b[0m Trial 356 finished with value: 0.7587235289807284 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 20, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 10, 'activation_func_2': 'relu', 'num_neurons_2': 17, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 14}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:43:46,763]\u001b[0m Trial 357 finished with value: 0.5 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 13, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 10, 'activation_func_2': 'relu', 'num_neurons_2': 23, 'activation_func_3': 'sigmoid', 'num_neurons_3': 4}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:43:50,980]\u001b[0m Trial 358 finished with value: 0.7589295543274696 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 19, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 9, 'activation_func_2': 'relu', 'num_neurons_2': 34, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 13}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:43:55,187]\u001b[0m Trial 359 finished with value: 0.7555395938454826 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 12, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 8, 'activation_func_2': 'relu', 'num_neurons_2': 29, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 5}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:43:59,514]\u001b[0m Trial 360 finished with value: 0.750413669585785 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 18, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 7, 'activation_func_2': 'relu', 'num_neurons_2': 14, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 22}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:44:03,818]\u001b[0m Trial 361 finished with value: 0.7625763222515896 and parameters: {'num_layers': 4, 'activation_func_0': 'relu', 'num_neurons_0': 17, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 9, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 28, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 14}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:44:08,061]\u001b[0m Trial 362 finished with value: 0.7605625906366679 and parameters: {'num_layers': 4, 'activation_func_0': 'relu', 'num_neurons_0': 17, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 11, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 32, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 13}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:44:12,347]\u001b[0m Trial 363 finished with value: 0.7579135716001983 and parameters: {'num_layers': 4, 'activation_func_0': 'relu', 'num_neurons_0': 17, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 11, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 33, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 13}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:44:16,393]\u001b[0m Trial 364 finished with value: 0.49345354034705646 and parameters: {'num_layers': 2, 'activation_func_0': 'relu', 'num_neurons_0': 24, 'activation_func_1': 'sigmoid', 'num_neurons_1': 11}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:44:20,739]\u001b[0m Trial 365 finished with value: 0.5 and parameters: {'num_layers': 4, 'activation_func_0': 'tanh', 'num_neurons_0': 23, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 10, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 32, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 12}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:44:25,087]\u001b[0m Trial 366 finished with value: 0.5 and parameters: {'num_layers': 4, 'activation_func_0': 'relu', 'num_neurons_0': 17, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 12, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 33, 'activation_func_3': 'tanh', 'num_neurons_3': 14}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:44:29,411]\u001b[0m Trial 367 finished with value: 0.7484607742395041 and parameters: {'num_layers': 4, 'activation_func_0': 'relu', 'num_neurons_0': 18, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 20, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 34, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 13}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:44:33,526]\u001b[0m Trial 368 finished with value: 0.7564115803626661 and parameters: {'num_layers': 1, 'activation_func_0': 'relu', 'num_neurons_0': 16}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:44:37,960]\u001b[0m Trial 369 finished with value: 0.759530589396085 and parameters: {'num_layers': 4, 'activation_func_0': 'relu', 'num_neurons_0': 11, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 10, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 32, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 14}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:44:42,459]\u001b[0m Trial 370 finished with value: 0.7340279233360769 and parameters: {'num_layers': 4, 'activation_func_0': 'relu', 'num_neurons_0': 38, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 22, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 31, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 12}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:44:47,135]\u001b[0m Trial 371 finished with value: 0.5433537654582914 and parameters: {'num_layers': 5, 'activation_func_0': 'relu', 'num_neurons_0': 17, 'activation_func_1': 'relu', 'num_neurons_1': 11, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 27, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 21, 'activation_func_4': 'tanh', 'num_neurons_4': 8}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:44:51,605]\u001b[0m Trial 372 finished with value: 0.7525238531000084 and parameters: {'num_layers': 4, 'activation_func_0': 'relu', 'num_neurons_0': 10, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 10, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 30, 'activation_func_3': 'relu', 'num_neurons_3': 15}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:44:55,875]\u001b[0m Trial 373 finished with value: 0.753729501841277 and parameters: {'num_layers': 4, 'activation_func_0': 'relu', 'num_neurons_0': 13, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 12, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 24, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 10}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:45:00,137]\u001b[0m Trial 374 finished with value: 0.7561096143457715 and parameters: {'num_layers': 4, 'activation_func_0': 'relu', 'num_neurons_0': 12, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 13, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 25, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 16}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:45:04,398]\u001b[0m Trial 375 finished with value: 0.5 and parameters: {'num_layers': 4, 'activation_func_0': 'relu', 'num_neurons_0': 15, 'activation_func_1': 'tanh', 'num_neurons_1': 11, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 26, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 13}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:45:08,765]\u001b[0m Trial 376 finished with value: 0.7510015831062623 and parameters: {'num_layers': 4, 'activation_func_0': 'relu', 'num_neurons_0': 16, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 40, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 31, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 19}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:45:12,995]\u001b[0m Trial 377 finished with value: 0.47838693570952645 and parameters: {'num_layers': 4, 'activation_func_0': 'relu', 'num_neurons_0': 18, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 9, 'activation_func_2': 'sigmoid', 'num_neurons_2': 28, 'activation_func_3': 'sigmoid', 'num_neurons_3': 20}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:45:17,331]\u001b[0m Trial 378 finished with value: 0.7590819006136453 and parameters: {'num_layers': 4, 'activation_func_0': 'relu', 'num_neurons_0': 17, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 8, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 38, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 14}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:45:21,783]\u001b[0m Trial 379 finished with value: 0.572239405201927 and parameters: {'num_layers': 4, 'activation_func_0': 'relu', 'num_neurons_0': 14, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 10, 'activation_func_2': 'tanh', 'num_neurons_2': 29, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 23}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:45:26,095]\u001b[0m Trial 380 finished with value: 0.5 and parameters: {'num_layers': 4, 'activation_func_0': 'sigmoid', 'num_neurons_0': 16, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 12, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 32, 'activation_func_3': 'relu', 'num_neurons_3': 26}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:45:30,468]\u001b[0m Trial 381 finished with value: 0.7600494869815498 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 17, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 7, 'activation_func_2': 'relu', 'num_neurons_2': 20, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 11}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:45:34,542]\u001b[0m Trial 382 finished with value: 0.7417795205011408 and parameters: {'num_layers': 2, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 32, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 6}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:45:38,881]\u001b[0m Trial 383 finished with value: 0.7574635195400301 and parameters: {'num_layers': 4, 'activation_func_0': 'relu', 'num_neurons_0': 18, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 7, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 22, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 9}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:45:43,274]\u001b[0m Trial 384 finished with value: 0.7381259361883777 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 17, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 5, 'activation_func_2': 'relu', 'num_neurons_2': 20, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 11}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:45:47,559]\u001b[0m Trial 385 finished with value: 0.7556067352736183 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 26, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 7, 'activation_func_2': 'relu', 'num_neurons_2': 21, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 10}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:45:51,822]\u001b[0m Trial 386 finished with value: 0.7555464102341259 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 11, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 8, 'activation_func_2': 'relu', 'num_neurons_2': 20, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 11}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:45:56,149]\u001b[0m Trial 387 finished with value: 0.5 and parameters: {'num_layers': 4, 'activation_func_0': 'tanh', 'num_neurons_0': 17, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 9, 'activation_func_2': 'relu', 'num_neurons_2': 19, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 9}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:46:00,455]\u001b[0m Trial 388 finished with value: 0.7488944669669285 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 15, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 8, 'activation_func_2': 'relu', 'num_neurons_2': 21, 'activation_func_3': 'relu', 'num_neurons_3': 12}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:46:04,728]\u001b[0m Trial 389 finished with value: 0.7466818672133411 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 9, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 26, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 16, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 11}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:46:09,007]\u001b[0m Trial 390 finished with value: 0.5 and parameters: {'num_layers': 4, 'activation_func_0': 'sigmoid', 'num_neurons_0': 14, 'activation_func_1': 'sigmoid', 'num_neurons_1': 15, 'activation_func_2': 'relu', 'num_neurons_2': 15, 'activation_func_3': 'tanh', 'num_neurons_3': 18}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:46:13,300]\u001b[0m Trial 391 finished with value: 0.7354046634322903 and parameters: {'num_layers': 4, 'activation_func_0': 'relu', 'num_neurons_0': 13, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 8, 'activation_func_2': 'relu', 'num_neurons_2': 19, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 12}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:46:17,590]\u001b[0m Trial 392 finished with value: 0.7561842538014147 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 18, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 9, 'activation_func_2': 'relu', 'num_neurons_2': 19, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 25}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:46:21,814]\u001b[0m Trial 393 finished with value: 0.5182210588918937 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 17, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 10, 'activation_func_2': 'sigmoid', 'num_neurons_2': 30, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 10}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:46:25,854]\u001b[0m Trial 394 finished with value: 0.5 and parameters: {'num_layers': 2, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 15, 'activation_func_1': 'relu', 'num_neurons_1': 7}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:46:29,766]\u001b[0m Trial 395 finished with value: 0.5 and parameters: {'num_layers': 1, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 12}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:46:33,954]\u001b[0m Trial 396 finished with value: 0.758161176917663 and parameters: {'num_layers': 4, 'activation_func_0': 'relu', 'num_neurons_0': 16, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 5, 'activation_func_2': 'relu', 'num_neurons_2': 21, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 24}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:46:38,155]\u001b[0m Trial 397 finished with value: 0.7562428747437464 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 17, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 6, 'activation_func_2': 'relu', 'num_neurons_2': 18, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 21}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:46:42,372]\u001b[0m Trial 398 finished with value: 0.7483401241605191 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 14, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 9, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 28, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 16}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:46:46,538]\u001b[0m Trial 399 finished with value: 0.5 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 19, 'activation_func_1': 'tanh', 'num_neurons_1': 10, 'activation_func_2': 'relu', 'num_neurons_2': 31, 'activation_func_3': 'relu', 'num_neurons_3': 20}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:46:50,712]\u001b[0m Trial 400 finished with value: 0.7540357281010734 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 13, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 29, 'activation_func_2': 'relu', 'num_neurons_2': 33, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 15}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:46:54,809]\u001b[0m Trial 401 finished with value: 0.5944059602502296 and parameters: {'num_layers': 4, 'activation_func_0': 'relu', 'num_neurons_0': 11, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 11, 'activation_func_2': 'tanh', 'num_neurons_2': 27, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 13}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:46:59,022]\u001b[0m Trial 402 finished with value: 0.7550072338924476 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 18, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 9, 'activation_func_2': 'relu', 'num_neurons_2': 29, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 17}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:47:03,188]\u001b[0m Trial 403 finished with value: 0.5447910010037134 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 16, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 8, 'activation_func_2': 'relu', 'num_neurons_2': 32, 'activation_func_3': 'sigmoid', 'num_neurons_3': 14}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:47:07,344]\u001b[0m Trial 404 finished with value: 0.5 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 20, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 7, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 30, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 19}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:47:11,556]\u001b[0m Trial 405 finished with value: 0.7476429780120343 and parameters: {'num_layers': 4, 'activation_func_0': 'relu', 'num_neurons_0': 15, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 10, 'activation_func_2': 'relu', 'num_neurons_2': 31, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 18}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:47:15,787]\u001b[0m Trial 406 finished with value: 0.7497521390679611 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 12, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 31, 'activation_func_2': 'relu', 'num_neurons_2': 29, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 10}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:47:19,898]\u001b[0m Trial 407 finished with value: 0.7594527121558362 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 17, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 25, 'activation_func_2': 'relu', 'num_neurons_2': 28, 'activation_func_3': 'relu', 'num_neurons_3': 15}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:47:24,061]\u001b[0m Trial 408 finished with value: 0.7471460632799438 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 16, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 1, 'activation_func_2': 'relu', 'num_neurons_2': 30, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 12}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:47:28,208]\u001b[0m Trial 409 finished with value: 0.7565030903802011 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 15, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 11, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 31, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 29}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:47:32,431]\u001b[0m Trial 410 finished with value: 0.7579900855627184 and parameters: {'num_layers': 4, 'activation_func_0': 'relu', 'num_neurons_0': 19, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 9, 'activation_func_2': 'relu', 'num_neurons_2': 18, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 16}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:47:36,295]\u001b[0m Trial 411 finished with value: 0.7485609751525594 and parameters: {'num_layers': 1, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 18}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:47:40,465]\u001b[0m Trial 412 finished with value: 0.5944059602502296 and parameters: {'num_layers': 4, 'activation_func_0': 'tanh', 'num_neurons_0': 10, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 10, 'activation_func_2': 'relu', 'num_neurons_2': 29, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 13}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:47:44,583]\u001b[0m Trial 413 finished with value: 0.726564659410621 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 17, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 8, 'activation_func_2': 'relu', 'num_neurons_2': 32, 'activation_func_3': 'tanh', 'num_neurons_3': 9}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:47:48,839]\u001b[0m Trial 414 finished with value: 0.5 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 14, 'activation_func_1': 'sigmoid', 'num_neurons_1': 13, 'activation_func_2': 'relu', 'num_neurons_2': 13, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 11}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:47:52,917]\u001b[0m Trial 415 finished with value: 0.7628145550346699 and parameters: {'num_layers': 2, 'activation_func_0': 'relu', 'num_neurons_0': 16, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 19}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:47:56,912]\u001b[0m Trial 416 finished with value: 0.5944059602502296 and parameters: {'num_layers': 2, 'activation_func_0': 'sigmoid', 'num_neurons_0': 15, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 22}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:48:00,926]\u001b[0m Trial 417 finished with value: 0.6931350445877021 and parameters: {'num_layers': 2, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 13, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 19}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:48:04,773]\u001b[0m Trial 418 finished with value: 0.5 and parameters: {'num_layers': 1, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 16}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:48:08,781]\u001b[0m Trial 419 finished with value: 0.5 and parameters: {'num_layers': 2, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 15, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 18}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:48:12,747]\u001b[0m Trial 420 finished with value: 0.7155488641340375 and parameters: {'num_layers': 2, 'activation_func_0': 'relu', 'num_neurons_0': 11, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 23}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:48:16,619]\u001b[0m Trial 421 finished with value: 0.7439186736670977 and parameters: {'num_layers': 1, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 16}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:48:20,642]\u001b[0m Trial 422 finished with value: 0.5 and parameters: {'num_layers': 2, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 14, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 16}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:48:24,946]\u001b[0m Trial 423 finished with value: 0.757141104357206 and parameters: {'num_layers': 5, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 12, 'activation_func_1': 'relu', 'num_neurons_1': 21, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 12, 'activation_func_3': 'relu', 'num_neurons_3': 17, 'activation_func_4': 'relu', 'num_neurons_4': 17}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:48:29,144]\u001b[0m Trial 424 finished with value: 0.5941810194250036 and parameters: {'num_layers': 4, 'activation_func_0': 'relu', 'num_neurons_0': 22, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 36, 'activation_func_2': 'sigmoid', 'num_neurons_2': 27, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 39}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:48:33,367]\u001b[0m Trial 425 finished with value: 0.7405752350376009 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 30, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 20, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 17, 'activation_func_3': 'relu', 'num_neurons_3': 14}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:48:37,552]\u001b[0m Trial 426 finished with value: 0.5944059602502296 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 16, 'activation_func_1': 'tanh', 'num_neurons_1': 9, 'activation_func_2': 'tanh', 'num_neurons_2': 34, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 16}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:48:41,784]\u001b[0m Trial 427 finished with value: 0.7437462190344245 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 14, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 10, 'activation_func_2': 'relu', 'num_neurons_2': 28, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 15}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:48:45,955]\u001b[0m Trial 428 finished with value: 0.7136937839647866 and parameters: {'num_layers': 4, 'activation_func_0': 'relu', 'num_neurons_0': 15, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 18, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 29, 'activation_func_3': 'sigmoid', 'num_neurons_3': 22}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:48:50,240]\u001b[0m Trial 429 finished with value: 0.7419427730091459 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 13, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 11, 'activation_func_2': 'relu', 'num_neurons_2': 20, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 19}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:48:54,226]\u001b[0m Trial 430 finished with value: 0.7558814357359399 and parameters: {'num_layers': 2, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 17, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 8}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:48:58,393]\u001b[0m Trial 431 finished with value: 0.7589293839177536 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 21, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 6, 'activation_func_2': 'relu', 'num_neurons_2': 26, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 17}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:49:02,559]\u001b[0m Trial 432 finished with value: 0.7504794477361921 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 18, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 9, 'activation_func_2': 'relu', 'num_neurons_2': 33, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 13}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:49:06,801]\u001b[0m Trial 433 finished with value: 0.7464482354925949 and parameters: {'num_layers': 4, 'activation_func_0': 'relu', 'num_neurons_0': 16, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 27, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 35, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 20}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:49:11,028]\u001b[0m Trial 434 finished with value: 0.7493523578740365 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 10, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 17, 'activation_func_2': 'relu', 'num_neurons_2': 32, 'activation_func_3': 'relu', 'num_neurons_3': 18}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:49:15,215]\u001b[0m Trial 435 finished with value: 0.7570714067833291 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 15, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 8, 'activation_func_2': 'relu', 'num_neurons_2': 30, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 16}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:49:19,093]\u001b[0m Trial 436 finished with value: 0.5944059602502296 and parameters: {'num_layers': 1, 'activation_func_0': 'tanh', 'num_neurons_0': 13}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:49:23,372]\u001b[0m Trial 437 finished with value: 0.7611932769958811 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 19, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 10, 'activation_func_2': 'relu', 'num_neurons_2': 24, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 14}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:49:27,552]\u001b[0m Trial 438 finished with value: 0.5 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 18, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 1, 'activation_func_2': 'relu', 'num_neurons_2': 23, 'activation_func_3': 'tanh', 'num_neurons_3': 14}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:49:31,746]\u001b[0m Trial 439 finished with value: 0.7311532818355171 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 20, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 11, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 26, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 15}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:49:35,949]\u001b[0m Trial 440 finished with value: 0.739786578871581 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 19, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 4, 'activation_func_2': 'relu', 'num_neurons_2': 28, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 13}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:49:39,884]\u001b[0m Trial 441 finished with value: 0.5 and parameters: {'num_layers': 1, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 20}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:49:44,128]\u001b[0m Trial 442 finished with value: 0.5 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 19, 'activation_func_1': 'sigmoid', 'num_neurons_1': 7, 'activation_func_2': 'relu', 'num_neurons_2': 22, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 12}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:49:48,414]\u001b[0m Trial 443 finished with value: 0.7575211180240653 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 18, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 10, 'activation_func_2': 'relu', 'num_neurons_2': 6, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 14}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:49:52,583]\u001b[0m Trial 444 finished with value: 0.7557577182820655 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 17, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 9, 'activation_func_2': 'relu', 'num_neurons_2': 25, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 15}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:49:56,831]\u001b[0m Trial 445 finished with value: 0.7589588647986354 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 18, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 10, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 27, 'activation_func_3': 'relu', 'num_neurons_3': 13}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:50:01,062]\u001b[0m Trial 446 finished with value: 0.5 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 19, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 7, 'activation_func_2': 'relu', 'num_neurons_2': 1, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 14}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:50:05,274]\u001b[0m Trial 447 finished with value: 0.5 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 9, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 11, 'activation_func_2': 'sigmoid', 'num_neurons_2': 21, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 14}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:50:09,534]\u001b[0m Trial 448 finished with value: 0.7561849354402791 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 34, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 8, 'activation_func_2': 'relu', 'num_neurons_2': 17, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 25}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:50:13,691]\u001b[0m Trial 449 finished with value: 0.5 and parameters: {'num_layers': 4, 'activation_func_0': 'sigmoid', 'num_neurons_0': 17, 'activation_func_1': 'relu', 'num_neurons_1': 9, 'activation_func_2': 'relu', 'num_neurons_2': 29, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 15}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:50:17,960]\u001b[0m Trial 450 finished with value: 0.43539852868251133 and parameters: {'num_layers': 5, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 11, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 12, 'activation_func_2': 'tanh', 'num_neurons_2': 25, 'activation_func_3': 'sigmoid', 'num_neurons_3': 12, 'activation_func_4': 'leakyrelu', 'num_neurons_4': 35}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:50:22,157]\u001b[0m Trial 451 finished with value: 0.7594912247516704 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 16, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 11, 'activation_func_2': 'relu', 'num_neurons_2': 24, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 16}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:50:26,448]\u001b[0m Trial 452 finished with value: 0.7345979438363658 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 17, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 19, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 27, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 16}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:50:30,465]\u001b[0m Trial 453 finished with value: 0.5 and parameters: {'num_layers': 2, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 27, 'activation_func_1': 'tanh', 'num_neurons_1': 3}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:50:34,691]\u001b[0m Trial 454 finished with value: 0.7485740967006975 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 20, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 10, 'activation_func_2': 'relu', 'num_neurons_2': 23, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 12}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:50:38,896]\u001b[0m Trial 455 finished with value: 0.5 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 17, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 9, 'activation_func_2': 'relu', 'num_neurons_2': 28, 'activation_func_3': 'relu', 'num_neurons_3': 24}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:50:43,114]\u001b[0m Trial 456 finished with value: 0.7580746087818944 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 19, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 8, 'activation_func_2': 'relu', 'num_neurons_2': 16, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 27}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:50:47,329]\u001b[0m Trial 457 finished with value: 0.7607481668174791 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 18, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 6, 'activation_func_2': 'relu', 'num_neurons_2': 20, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 13}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:50:51,575]\u001b[0m Trial 458 finished with value: 0.7397439764425608 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 18, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 3, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 31, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 13}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:50:55,675]\u001b[0m Trial 459 finished with value: 0.7574490347141632 and parameters: {'num_layers': 3, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 21, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 6, 'activation_func_2': 'relu', 'num_neurons_2': 24}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:50:59,943]\u001b[0m Trial 460 finished with value: 0.756265368826269 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 12, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 10, 'activation_func_2': 'relu', 'num_neurons_2': 14, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 15}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:51:03,939]\u001b[0m Trial 461 finished with value: 0.749648189141152 and parameters: {'num_layers': 2, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 20, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 5}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:51:08,061]\u001b[0m Trial 462 finished with value: 0.3215583627716117 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 11, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 4, 'activation_func_2': 'relu', 'num_neurons_2': 29, 'activation_func_3': 'tanh', 'num_neurons_3': 17}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:51:12,227]\u001b[0m Trial 463 finished with value: 0.7583731666044672 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 18, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 11, 'activation_func_2': 'relu', 'num_neurons_2': 30, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 13}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:51:16,642]\u001b[0m Trial 464 finished with value: 0.7330664717179515 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 19, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 14, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 15, 'activation_func_3': 'relu', 'num_neurons_3': 14}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:51:20,675]\u001b[0m Trial 465 finished with value: 0.5 and parameters: {'num_layers': 1, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 16}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:51:25,074]\u001b[0m Trial 466 finished with value: 0.5944059602502296 and parameters: {'num_layers': 4, 'activation_func_0': 'tanh', 'num_neurons_0': 18, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 12, 'activation_func_2': 'relu', 'num_neurons_2': 11, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 23}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:51:29,462]\u001b[0m Trial 467 finished with value: 0.5 and parameters: {'num_layers': 4, 'activation_func_0': 'sigmoid', 'num_neurons_0': 8, 'activation_func_1': 'sigmoid', 'num_neurons_1': 2, 'activation_func_2': 'relu', 'num_neurons_2': 28, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 16}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:51:33,655]\u001b[0m Trial 468 finished with value: 0.7581153367040374 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 16, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 5, 'activation_func_2': 'relu', 'num_neurons_2': 19, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 15}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:51:37,921]\u001b[0m Trial 469 finished with value: 0.7583188059050374 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 15, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 9, 'activation_func_2': 'leakyrelu', 'num_neurons_2': 30, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 17}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:51:42,152]\u001b[0m Trial 470 finished with value: 0.751789557633418 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 10, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 11, 'activation_func_2': 'relu', 'num_neurons_2': 29, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 22}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-23 16:51:46,366]\u001b[0m Trial 471 finished with value: 0.7258196281319175 and parameters: {'num_layers': 4, 'activation_func_0': 'leakyrelu', 'num_neurons_0': 19, 'activation_func_1': 'leakyrelu', 'num_neurons_1': 9, 'activation_func_2': 'sigmoid', 'num_neurons_2': 30, 'activation_func_3': 'leakyrelu', 'num_neurons_3': 15}. Best is trial 40 with value: 0.7674936650188047.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from optuna.samplers import TPESampler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "def objective(trial):\n",
    "       \n",
    "    model = train_net(NeuralNetworkBuilder, len(feature_for_nn), trainloader, validset, trial=trial, num_epochs = 20, lr = 5e-3)\n",
    "  \n",
    "    lfp = 1\n",
    "    lfn = 19\n",
    "    tau = lfp/(lfp+lfn)\n",
    "\n",
    "    # y_pred = decision_tree.predict(X_valid[feature_for_dt])\n",
    "\n",
    "    y_prob = predict(model, validset[:][0]).numpy()\n",
    "    roc = roc_auc_score(y_valid, y_prob)\n",
    "    \n",
    "    return roc\n",
    "\n",
    "sampler = TPESampler(seed=42) \n",
    "study = optuna.create_study(direction='maximize', sampler=sampler)\n",
    "study.optimize(objective, n_trials = 1000, timeout = 2000) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "66d2e61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5bc191bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'num_layers': 1, 'activation_func_0': 'relu', 'num_neurons_0': 12}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "33c950d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork_Class_Balancing(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size):\n",
    "        super(NeuralNetwork_Class_Balancing, self).__init__()\n",
    "        \n",
    "        self.feedforward = nn.Sequential(            \n",
    "            nn.Linear(input_size, 24),            \n",
    "            nn.LeakyReLU(),                       \n",
    "            nn.Linear(24, 13),\n",
    "            nn.LeakyReLU(),         \n",
    "            nn.Linear(13, 1),\n",
    "            nn.Sigmoid()\n",
    "        )                        \n",
    "\n",
    "\n",
    "    def forward(self, X):        \n",
    "        return self.feedforward(X).flatten() # returns a flat array as desired"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d60fb5a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train loss</th>\n",
       "      <th>valid loss</th>\n",
       "      <th>valid recall</th>\n",
       "      <th>valid average precision</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>22.237</td>\n",
       "      <td>6.102</td>\n",
       "      <td>0.203</td>\n",
       "      <td>0.240</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>6.689</td>\n",
       "      <td>7.033</td>\n",
       "      <td>0.203</td>\n",
       "      <td>0.242</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>6.139</td>\n",
       "      <td>5.439</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.235</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5.298</td>\n",
       "      <td>4.790</td>\n",
       "      <td>0.274</td>\n",
       "      <td>0.240</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>4.884</td>\n",
       "      <td>4.716</td>\n",
       "      <td>0.284</td>\n",
       "      <td>0.241</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>4.720</td>\n",
       "      <td>4.465</td>\n",
       "      <td>0.524</td>\n",
       "      <td>0.242</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>4.548</td>\n",
       "      <td>4.327</td>\n",
       "      <td>0.817</td>\n",
       "      <td>0.243</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>4.403</td>\n",
       "      <td>4.192</td>\n",
       "      <td>0.964</td>\n",
       "      <td>0.241</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>4.234</td>\n",
       "      <td>4.056</td>\n",
       "      <td>0.953</td>\n",
       "      <td>0.246</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>4.103</td>\n",
       "      <td>3.958</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.248</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>3.971</td>\n",
       "      <td>3.839</td>\n",
       "      <td>0.955</td>\n",
       "      <td>0.260</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>3.814</td>\n",
       "      <td>3.670</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.271</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>3.549</td>\n",
       "      <td>3.320</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.412</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>3.354</td>\n",
       "      <td>3.298</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.415</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>3.317</td>\n",
       "      <td>3.310</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.416</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>3.248</td>\n",
       "      <td>3.252</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.419</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>3.219</td>\n",
       "      <td>3.402</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.421</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>3.258</td>\n",
       "      <td>3.208</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.422</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>3.182</td>\n",
       "      <td>3.207</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.424</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>3.177</td>\n",
       "      <td>3.260</td>\n",
       "      <td>0.792</td>\n",
       "      <td>0.426</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>3.180</td>\n",
       "      <td>3.175</td>\n",
       "      <td>0.961</td>\n",
       "      <td>0.427</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>3.163</td>\n",
       "      <td>3.135</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.428</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>3.157</td>\n",
       "      <td>3.373</td>\n",
       "      <td>0.682</td>\n",
       "      <td>0.430</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>3.280</td>\n",
       "      <td>4.382</td>\n",
       "      <td>0.257</td>\n",
       "      <td>0.430</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>3.547</td>\n",
       "      <td>3.116</td>\n",
       "      <td>0.997</td>\n",
       "      <td>0.431</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>3.126</td>\n",
       "      <td>3.102</td>\n",
       "      <td>0.991</td>\n",
       "      <td>0.432</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>3.118</td>\n",
       "      <td>3.121</td>\n",
       "      <td>0.995</td>\n",
       "      <td>0.434</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>3.177</td>\n",
       "      <td>3.215</td>\n",
       "      <td>0.698</td>\n",
       "      <td>0.436</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>8.989</td>\n",
       "      <td>25.852</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.429</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>16.275</td>\n",
       "      <td>39.476</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.383</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>12.571</td>\n",
       "      <td>18.384</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.427</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>9.421</td>\n",
       "      <td>12.266</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.409</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>6.661</td>\n",
       "      <td>4.268</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.417</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>3.880</td>\n",
       "      <td>3.592</td>\n",
       "      <td>0.609</td>\n",
       "      <td>0.424</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>3.266</td>\n",
       "      <td>3.186</td>\n",
       "      <td>0.978</td>\n",
       "      <td>0.426</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>3.205</td>\n",
       "      <td>3.356</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.426</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>3.271</td>\n",
       "      <td>3.300</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.426</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>3.139</td>\n",
       "      <td>3.294</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.427</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>3.185</td>\n",
       "      <td>3.136</td>\n",
       "      <td>0.991</td>\n",
       "      <td>0.428</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>3.138</td>\n",
       "      <td>3.151</td>\n",
       "      <td>0.916</td>\n",
       "      <td>0.429</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>3.382</td>\n",
       "      <td>4.074</td>\n",
       "      <td>0.374</td>\n",
       "      <td>0.430</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>18.384</td>\n",
       "      <td>54.339</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.435</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>62.577</td>\n",
       "      <td>67.797</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.434</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>67.417</td>\n",
       "      <td>68.524</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.434</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>67.671</td>\n",
       "      <td>68.562</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.434</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>67.684</td>\n",
       "      <td>68.563</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.434</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>67.685</td>\n",
       "      <td>68.563</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.434</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>67.685</td>\n",
       "      <td>68.563</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.434</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>67.685</td>\n",
       "      <td>68.563</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.434</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>67.685</td>\n",
       "      <td>68.563</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.434</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>67.685</td>\n",
       "      <td>68.563</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.434</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>67.685</td>\n",
       "      <td>68.563</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.434</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>67.685</td>\n",
       "      <td>68.563</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.434</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>67.685</td>\n",
       "      <td>68.563</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.434</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>67.685</td>\n",
       "      <td>68.563</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.434</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>67.685</td>\n",
       "      <td>68.563</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.434</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>67.685</td>\n",
       "      <td>68.563</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.434</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>67.685</td>\n",
       "      <td>68.563</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.434</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>67.685</td>\n",
       "      <td>68.563</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.434</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>67.685</td>\n",
       "      <td>68.563</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.434</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61</td>\n",
       "      <td>67.685</td>\n",
       "      <td>68.563</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.434</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62</td>\n",
       "      <td>67.685</td>\n",
       "      <td>68.563</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.434</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>63</td>\n",
       "      <td>67.685</td>\n",
       "      <td>68.563</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.434</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>67.685</td>\n",
       "      <td>68.563</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.434</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65</td>\n",
       "      <td>67.685</td>\n",
       "      <td>68.563</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.434</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66</td>\n",
       "      <td>67.685</td>\n",
       "      <td>68.563</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.434</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>67</td>\n",
       "      <td>67.685</td>\n",
       "      <td>68.563</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.434</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68</td>\n",
       "      <td>67.685</td>\n",
       "      <td>68.563</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.434</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69</td>\n",
       "      <td>67.685</td>\n",
       "      <td>68.563</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.434</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>67.685</td>\n",
       "      <td>68.563</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.434</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>71</td>\n",
       "      <td>67.685</td>\n",
       "      <td>68.563</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.434</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72</td>\n",
       "      <td>67.685</td>\n",
       "      <td>68.563</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.434</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>73</td>\n",
       "      <td>67.685</td>\n",
       "      <td>68.563</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.434</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>74</td>\n",
       "      <td>67.685</td>\n",
       "      <td>68.563</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.434</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>67.685</td>\n",
       "      <td>68.563</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.434</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>76</td>\n",
       "      <td>67.685</td>\n",
       "      <td>68.563</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.434</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>77</td>\n",
       "      <td>67.685</td>\n",
       "      <td>68.563</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.434</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78</td>\n",
       "      <td>67.685</td>\n",
       "      <td>68.563</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.434</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>79</td>\n",
       "      <td>67.685</td>\n",
       "      <td>68.563</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.434</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>67.685</td>\n",
       "      <td>68.563</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.434</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>81</td>\n",
       "      <td>67.685</td>\n",
       "      <td>68.563</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.434</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>82</td>\n",
       "      <td>67.685</td>\n",
       "      <td>68.563</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.434</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>83</td>\n",
       "      <td>67.685</td>\n",
       "      <td>68.563</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.434</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>84</td>\n",
       "      <td>67.685</td>\n",
       "      <td>68.563</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.434</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85</td>\n",
       "      <td>67.685</td>\n",
       "      <td>68.563</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.434</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>86</td>\n",
       "      <td>67.685</td>\n",
       "      <td>68.563</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.434</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>87</td>\n",
       "      <td>67.685</td>\n",
       "      <td>68.563</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.434</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>88</td>\n",
       "      <td>67.685</td>\n",
       "      <td>68.563</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.434</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>89</td>\n",
       "      <td>67.685</td>\n",
       "      <td>68.563</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.434</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>67.685</td>\n",
       "      <td>68.563</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.434</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>91</td>\n",
       "      <td>67.685</td>\n",
       "      <td>68.563</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.434</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>92</td>\n",
       "      <td>67.685</td>\n",
       "      <td>68.563</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.434</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>93</td>\n",
       "      <td>67.685</td>\n",
       "      <td>68.563</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.434</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>94</td>\n",
       "      <td>67.685</td>\n",
       "      <td>68.563</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.434</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95</td>\n",
       "      <td>67.685</td>\n",
       "      <td>68.563</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.434</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>67.685</td>\n",
       "      <td>68.563</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.434</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>97</td>\n",
       "      <td>67.685</td>\n",
       "      <td>68.563</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.434</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98</td>\n",
       "      <td>67.685</td>\n",
       "      <td>68.563</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.434</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>99</td>\n",
       "      <td>67.685</td>\n",
       "      <td>68.563</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.434</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>67.685</td>\n",
       "      <td>68.563</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.434</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>101</td>\n",
       "      <td>67.685</td>\n",
       "      <td>68.563</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.434</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>102</td>\n",
       "      <td>67.685</td>\n",
       "      <td>68.563</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.434</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>103</td>\n",
       "      <td>67.685</td>\n",
       "      <td>68.563</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.434</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>104</td>\n",
       "      <td>67.685</td>\n",
       "      <td>68.563</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.434</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>105</td>\n",
       "      <td>67.685</td>\n",
       "      <td>68.563</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.434</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>106</td>\n",
       "      <td>67.685</td>\n",
       "      <td>68.563</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.434</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>107</td>\n",
       "      <td>67.685</td>\n",
       "      <td>68.563</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.434</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>108</td>\n",
       "      <td>67.685</td>\n",
       "      <td>68.563</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.434</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>109</td>\n",
       "      <td>67.685</td>\n",
       "      <td>68.563</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.434</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>67.685</td>\n",
       "      <td>68.563</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.434</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>111</td>\n",
       "      <td>67.685</td>\n",
       "      <td>68.563</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.434</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>112</td>\n",
       "      <td>67.685</td>\n",
       "      <td>68.563</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.434</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>113</td>\n",
       "      <td>67.685</td>\n",
       "      <td>68.563</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.434</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>114</td>\n",
       "      <td>67.685</td>\n",
       "      <td>68.563</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.434</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>115</td>\n",
       "      <td>67.685</td>\n",
       "      <td>68.563</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.434</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>116</td>\n",
       "      <td>67.685</td>\n",
       "      <td>68.563</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.434</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>117</td>\n",
       "      <td>67.685</td>\n",
       "      <td>68.563</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.434</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>118</td>\n",
       "      <td>67.685</td>\n",
       "      <td>68.563</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.434</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>119</td>\n",
       "      <td>67.685</td>\n",
       "      <td>68.563</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.434</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>67.685</td>\n",
       "      <td>68.563</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.434</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>121</td>\n",
       "      <td>67.685</td>\n",
       "      <td>68.563</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.434</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>122</td>\n",
       "      <td>67.685</td>\n",
       "      <td>68.563</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.434</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>123</td>\n",
       "      <td>67.685</td>\n",
       "      <td>68.563</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.434</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>124</td>\n",
       "      <td>67.685</td>\n",
       "      <td>68.563</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.434</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>67.685</td>\n",
       "      <td>68.563</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.434</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>126</td>\n",
       "      <td>67.685</td>\n",
       "      <td>68.563</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.434</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>127</td>\n",
       "      <td>67.685</td>\n",
       "      <td>68.563</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.434</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>128</td>\n",
       "      <td>67.685</td>\n",
       "      <td>68.563</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.434</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>129</td>\n",
       "      <td>67.685</td>\n",
       "      <td>68.563</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.434</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>67.685</td>\n",
       "      <td>68.563</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.434</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>131</td>\n",
       "      <td>67.685</td>\n",
       "      <td>68.563</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.434</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>132</td>\n",
       "      <td>67.685</td>\n",
       "      <td>68.563</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.434</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>133</td>\n",
       "      <td>67.685</td>\n",
       "      <td>68.563</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.434</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>134</td>\n",
       "      <td>67.685</td>\n",
       "      <td>68.563</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.434</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>135</td>\n",
       "      <td>67.685</td>\n",
       "      <td>68.563</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.434</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>136</td>\n",
       "      <td>67.685</td>\n",
       "      <td>68.563</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.434</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>137</td>\n",
       "      <td>67.685</td>\n",
       "      <td>68.563</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.434</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>138</td>\n",
       "      <td>67.685</td>\n",
       "      <td>68.563</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.434</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>139</td>\n",
       "      <td>67.685</td>\n",
       "      <td>68.563</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.434</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>67.685</td>\n",
       "      <td>68.563</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.434</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>141</td>\n",
       "      <td>67.685</td>\n",
       "      <td>68.563</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.434</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>142</td>\n",
       "      <td>67.685</td>\n",
       "      <td>68.563</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.434</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>143</td>\n",
       "      <td>67.685</td>\n",
       "      <td>68.563</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.434</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>144</td>\n",
       "      <td>67.685</td>\n",
       "      <td>68.563</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.434</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>145</td>\n",
       "      <td>67.685</td>\n",
       "      <td>68.563</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.434</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>146</td>\n",
       "      <td>67.685</td>\n",
       "      <td>68.563</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.434</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>147</td>\n",
       "      <td>67.685</td>\n",
       "      <td>68.563</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.434</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>148</td>\n",
       "      <td>67.685</td>\n",
       "      <td>68.563</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.434</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>149</td>\n",
       "      <td>67.685</td>\n",
       "      <td>68.563</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.434</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>67.685</td>\n",
       "      <td>68.563</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.434</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>151</td>\n",
       "      <td>67.685</td>\n",
       "      <td>68.563</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.434</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>152</td>\n",
       "      <td>67.685</td>\n",
       "      <td>68.563</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.434</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>153</td>\n",
       "      <td>67.685</td>\n",
       "      <td>68.563</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.434</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>154</td>\n",
       "      <td>67.685</td>\n",
       "      <td>68.563</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.434</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>155</td>\n",
       "      <td>67.685</td>\n",
       "      <td>68.563</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.434</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>156</td>\n",
       "      <td>67.685</td>\n",
       "      <td>68.563</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.434</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>157</td>\n",
       "      <td>67.685</td>\n",
       "      <td>68.563</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.434</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>158</td>\n",
       "      <td>67.685</td>\n",
       "      <td>68.563</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.434</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>159</td>\n",
       "      <td>67.685</td>\n",
       "      <td>68.563</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.434</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>67.685</td>\n",
       "      <td>68.563</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.434</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>161</td>\n",
       "      <td>67.685</td>\n",
       "      <td>68.563</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.434</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>162</td>\n",
       "      <td>67.685</td>\n",
       "      <td>68.563</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.434</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>163</td>\n",
       "      <td>67.685</td>\n",
       "      <td>68.563</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.434</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>164</td>\n",
       "      <td>67.685</td>\n",
       "      <td>68.563</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.434</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>165</td>\n",
       "      <td>67.685</td>\n",
       "      <td>68.563</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.434</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>166</td>\n",
       "      <td>67.685</td>\n",
       "      <td>68.563</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.434</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>167</td>\n",
       "      <td>67.685</td>\n",
       "      <td>68.563</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.434</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>168</td>\n",
       "      <td>67.685</td>\n",
       "      <td>68.563</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.434</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>169</td>\n",
       "      <td>67.685</td>\n",
       "      <td>68.563</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.434</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>67.685</td>\n",
       "      <td>68.563</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.434</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>171</td>\n",
       "      <td>67.685</td>\n",
       "      <td>68.563</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.434</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>172</td>\n",
       "      <td>67.685</td>\n",
       "      <td>68.563</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.434</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>173</td>\n",
       "      <td>67.685</td>\n",
       "      <td>68.563</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.434</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>174</td>\n",
       "      <td>67.685</td>\n",
       "      <td>68.563</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.434</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>67.685</td>\n",
       "      <td>68.563</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.434</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>176</td>\n",
       "      <td>67.685</td>\n",
       "      <td>68.563</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.434</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>177</td>\n",
       "      <td>67.685</td>\n",
       "      <td>68.563</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.434</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>178</td>\n",
       "      <td>67.685</td>\n",
       "      <td>68.563</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.434</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>179</td>\n",
       "      <td>67.685</td>\n",
       "      <td>68.563</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.434</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>67.685</td>\n",
       "      <td>68.563</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.434</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>181</td>\n",
       "      <td>67.685</td>\n",
       "      <td>68.563</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.434</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>182</td>\n",
       "      <td>67.685</td>\n",
       "      <td>68.563</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.434</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>183</td>\n",
       "      <td>67.685</td>\n",
       "      <td>68.563</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.434</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>184</td>\n",
       "      <td>67.685</td>\n",
       "      <td>68.563</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.434</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>185</td>\n",
       "      <td>67.685</td>\n",
       "      <td>68.563</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.434</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>186</td>\n",
       "      <td>67.685</td>\n",
       "      <td>68.563</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.434</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>187</td>\n",
       "      <td>67.685</td>\n",
       "      <td>68.563</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.434</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>188</td>\n",
       "      <td>67.685</td>\n",
       "      <td>68.563</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.434</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>189</td>\n",
       "      <td>67.685</td>\n",
       "      <td>68.563</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.434</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>67.685</td>\n",
       "      <td>68.563</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.434</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>191</td>\n",
       "      <td>67.685</td>\n",
       "      <td>68.563</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.434</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>192</td>\n",
       "      <td>67.685</td>\n",
       "      <td>68.563</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.434</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>193</td>\n",
       "      <td>67.685</td>\n",
       "      <td>68.563</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.434</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>194</td>\n",
       "      <td>67.685</td>\n",
       "      <td>68.563</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.434</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>195</td>\n",
       "      <td>67.685</td>\n",
       "      <td>68.563</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.434</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>196</td>\n",
       "      <td>67.685</td>\n",
       "      <td>68.563</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.434</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>197</td>\n",
       "      <td>67.685</td>\n",
       "      <td>68.563</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.434</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>198</td>\n",
       "      <td>67.685</td>\n",
       "      <td>68.563</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.434</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>199</td>\n",
       "      <td>67.685</td>\n",
       "      <td>68.563</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.434</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>67.685</td>\n",
       "      <td>68.563</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.434</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    " mlp_with_class_weights = train_with_class_weight(NeuralNetwork_Class_Balancing, len(feature_for_nn), trainloader, validset, num_epochs =200, lr = 3e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2cb9c187",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC score:  0.5\n",
      "(True Negatives):  4549\n",
      "(False Positives):  0\n",
      "(False Negatives):  645\n",
      "(True Positives):  0\n",
      "Total subscribed Transactions:  645\n",
      "total loss from loss matrix: 12255\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 500x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lfp = 1\n",
    "lfn = 19\n",
    "tau = lfp/(lfp+lfn)\n",
    "\n",
    "# y_pred = decision_tree.predict(X_valid[feature_for_dt])\n",
    "\n",
    "y_prob = predict(mlp_with_class_weights, validset[:][0]).numpy()\n",
    "\n",
    "y_prob[y_prob < 1e-5] = 1e-5 # Log-loss returns NaN if too close to zero or one\n",
    "y_prob[y_prob > 1- 1e-5] =  1- 1e-5\n",
    "\n",
    "print('AUC score: ', roc_auc_score(y_valid, y_prob))\n",
    "\n",
    "y_pred = (y_prob > tau).astype(int)\n",
    "# y_pred = decision_tree.predict(valid[feature_for_dt])\n",
    "\n",
    "plot_cm(y_valid, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff56745",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
